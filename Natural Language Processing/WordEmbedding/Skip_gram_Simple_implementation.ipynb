{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eR58EM-9SLjb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, Input, Dot, Activation, Reshape\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.decomposition import PCA # For dimensionality reduction\n",
        "import matplotlib.pyplot as plt # For plotting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Corpus\n",
        "corpus = [\n",
        "    \"natural language processing is fun and interesting\",\n",
        "    \"implementing skipgram in python is a good exercise\",\n",
        "    \"word embeddings capture semantic relationships\",\n",
        "    \"skipgram with negative sampling is efficient for large vocabularies\",\n",
        "    \"language models are powerful\",\n",
        "    \"python is a versatile programming language\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "vCw7BkGvSL65"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data Preparation\n",
        "\n",
        "# Tokenization and Vocabulary\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "sequences = tokenizer.texts_to_sequences(corpus)"
      ],
      "metadata": {
        "id": "ab49hCwDSL9h"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the sequences to easily pick target words\n",
        "flat_sequence = [word for sublist in sequences for word in sublist]"
      ],
      "metadata": {
        "id": "M1FkPIqMSMAQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Target-Context and Negative Samples\n",
        "def generate_skipgram_pairs(sequence, window_size, num_negative_samples, vocab_size):\n",
        "    positive_pairs = []\n",
        "    labels = []\n",
        "    for i, target_word_id in enumerate(sequence):\n",
        "        context_window_start = max(0, i - window_size)\n",
        "        context_window_end = min(len(sequence), i + window_size + 1)\n",
        "        for j in range(context_window_start, context_window_end):\n",
        "            if i != j:\n",
        "                context_word_id = sequence[j]\n",
        "                # Positive pair\n",
        "                positive_pairs.append([target_word_id, context_word_id])\n",
        "                labels.append(1)\n",
        "\n",
        "                # Negative samples\n",
        "                for _ in range(num_negative_samples):\n",
        "                    negative_word_id = random.randint(1, vocab_size - 1) # Exclude padding index 0\n",
        "                    while negative_word_id == target_word_id or negative_word_id in sequence[context_window_start:context_window_end]:\n",
        "                         negative_word_id = random.randint(1, vocab_size - 1)\n",
        "                    positive_pairs.append([target_word_id, negative_word_id])\n",
        "                    labels.append(0)\n",
        "    return np.array(positive_pairs), np.array(labels)"
      ],
      "metadata": {
        "id": "JDPgjhcVSMDQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "window_size = 2\n",
        "num_negative_samples = 4 # Number of negative samples per positive pair"
      ],
      "metadata": {
        "id": "kcQbQ8O4SXBY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training data\n",
        "X, y = generate_skipgram_pairs(flat_sequence, window_size, num_negative_samples, vocab_size)"
      ],
      "metadata": {
        "id": "QDZ9y3yySXEB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate target and context/negative words for model input\n",
        "X_target = X[:, 0]\n",
        "X_context = X[:, 1]"
      ],
      "metadata": {
        "id": "6p30JA0GSXMo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Model Architecture\n",
        "\n",
        "embed_size = 10  # Dimension of word embeddings\n",
        "\n",
        "# Input layers for target and context/negative words\n",
        "input_target = Input(shape=(1,))\n",
        "input_context = Input(shape=(1,))"
      ],
      "metadata": {
        "id": "ucNHq8UFSfTZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer for target words\n",
        "# Use separate embedding matrices for target and context for better performance\n",
        "embedding_layer_target = Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=1, name='target_embedding')\n",
        "embedding_target = embedding_layer_target(input_target)\n",
        "embedding_target = Reshape((embed_size,))(embedding_target) # Flatten the embedding"
      ],
      "metadata": {
        "id": "qOuikQXWSfWZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer for context/negative words\n",
        "embedding_layer_context = Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=1, name='context_embedding')\n",
        "embedding_context = embedding_layer_context(input_context)\n",
        "embedding_context = Reshape((embed_size,))(embedding_context) # Flatten the embedding\n"
      ],
      "metadata": {
        "id": "Dr-SDUBySfaS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the dot product of the target and context/negative embeddings\n",
        "dot_product = Dot(axes=-1)([embedding_target, embedding_context])"
      ],
      "metadata": {
        "id": "r38FXhPdSfc6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid activation to get the probability\n",
        "output = Activation('sigmoid')(dot_product)"
      ],
      "metadata": {
        "id": "da8bGH-VSl-B"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Model(inputs=[input_target, input_context], outputs=output)"
      ],
      "metadata": {
        "id": "IkBbNeTYSmA9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Training with Negative Sampling\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "rgUeJ5z7SmIp",
        "outputId": "60166cf7-846e-4260-b4dc-5206ff86e9b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ target_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m320\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ context_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m320\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ target_embedding… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ context_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_2 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dot_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ target_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ context_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ target_embedding… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ context_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "# We train on the generated pairs with binary labels (1 for positive, 0 for negative)\n",
        "model.fit([X_target, X_context], y, epochs=50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hNrMl8nSmLI",
        "outputId": "43a6296b-8925-41cc-f149-cff58f8bb711"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5145 - loss: 0.6931\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6768 - loss: 0.6925\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7579 - loss: 0.6918 \n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.6907 \n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.6882\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.6855\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8317 - loss: 0.6802\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8344 - loss: 0.6727\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8403 - loss: 0.6620 \n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.6518\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.6350 \n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.6190 \n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.6005 \n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.5829\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8261 - loss: 0.5711\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.5513\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.5410\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8002 - loss: 0.5326 \n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5120 \n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.4985\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.4972\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8343 - loss: 0.4657 \n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.4726\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4858 \n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4788 \n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.4483\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4416\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4574 \n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.4258\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8286 - loss: 0.4218\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.4286\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.4166\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8177 - loss: 0.4227 \n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.4217\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4087\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.4218\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.3955\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.3929\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4133\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8135 - loss: 0.4126\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8122 - loss: 0.4005\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8121 - loss: 0.4113\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 0.3884\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.3977\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8161 - loss: 0.4067\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8219 - loss: 0.3959\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8424 - loss: 0.3609\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8264 - loss: 0.3721\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.3548\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.3757\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d3fd63a6690>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get Word Embeddings\n",
        "# You can get the learned embeddings from the target embedding layer\n",
        "target_embedding_matrix = model.get_layer('target_embedding').get_weights()[0]"
      ],
      "metadata": {
        "id": "2oANS1meSmN6"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the embedding for a word\n",
        "def get_word_embedding(word, word_index, embedding_matrix):\n",
        "    if word in word_index:\n",
        "        return embedding_matrix[word_index[word]]\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "8pgtkoj4Stig"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage (Cosine Similarity) - Requires the function from the previous response\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "def calculate_cosine_similarity(word1, word2, word_index, embedding_matrix):\n",
        "    embedding1 = get_word_embedding(word1, word_index, embedding_matrix)\n",
        "    embedding2 = get_word_embedding(word2, word_index, embedding_matrix)\n",
        "\n",
        "    if embedding1 is not None and embedding2 is not None:\n",
        "        return 1 - cosine(embedding1, embedding2)\n",
        "    else:\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "48olUrmqStoB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word1 = 'python'\n",
        "word2 = 'skipgram'\n",
        "similarity = calculate_cosine_similarity(word1, word2, word_index, target_embedding_matrix)\n",
        "\n",
        "if similarity is not None:\n",
        "    print(f\"\\nCosine similarity between '{word1}' and '{word2}': {similarity}\")\n",
        "else:\n",
        "    print(f\"\\nOne or both words ('{word1}', '{word2}') not in vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm5yxRPzStqg",
        "outputId": "b77dd9ca-4a99-4b94-b6ed-e49340b6dd41"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cosine similarity between 'python' and 'skipgram': 0.767221987247467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "word3 = 'language'\n",
        "word4 = 'embeddings'\n",
        "similarity2 = calculate_cosine_similarity(word3, word4, word_index, target_embedding_matrix)\n",
        "\n",
        "if similarity2 is not None:\n",
        "     print(f\"Cosine similarity between '{word3}' and '{word4}': {similarity2}\")\n",
        "else:\n",
        "    print(f\"\\nOne or both words ('{word3}', '{word4}') not in vocabulary.\")\n",
        "\n",
        "# Note: Similar to CBOW, training on a small corpus will result in\n",
        "# less meaningful embeddings."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKU31CYGSMF4",
        "outputId": "5893985a-24d1-476c-d583-10a2b4191e65"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'language' and 'embeddings': 0.19705462455749512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Evaluation\n",
        "\n",
        "# Cosine Similarity Examples\n",
        "print(\"\\n--- Word Similarity Evaluation (Cosine Similarity) ---\")\n",
        "word_pairs = [('python', 'skipgram'), ('language', 'embeddings'), ('processing', 'python'), ('fun', 'exercise')]\n",
        "for word1, word2 in word_pairs:\n",
        "    similarity = calculate_cosine_similarity(word1, word2, word_index, target_embedding_matrix)\n",
        "    if similarity is not None:\n",
        "        print(f\"Cosine similarity between '{word1}' and '{word2}': {similarity:.4f}\")\n",
        "    else:\n",
        "        print(f\"One or both words ('{word1}', '{word2}') not in vocabulary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-2gvwPNT5KJ",
        "outputId": "e27e1d02-14ab-4c87-b6d3-b25b05475975"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Word Similarity Evaluation (Cosine Similarity) ---\n",
            "Cosine similarity between 'python' and 'skipgram': 0.7672\n",
            "Cosine similarity between 'language' and 'embeddings': 0.1971\n",
            "Cosine similarity between 'processing' and 'python': 0.7097\n",
            "Cosine similarity between 'fun' and 'exercise': 0.3012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Other Evaluation Methods ---\")\n",
        "print(\"Beyond cosine similarity and visualization, word embeddings can be evaluated using:\")\n",
        "print(\"Intrinsic Evaluation:\")\n",
        "print(\"- Word Similarity Benchmarks: Comparing embedding similarity to human ratings on datasets (e.g., MEN, WS-353).\")\n",
        "print(\"- Word Analogy Tasks: Testing if vector relationships hold for analogies (e.g., 'king' - 'man' + 'woman' ≈ 'queen').\")\n",
        "print(\"- Word Categorization/Clustering: Assessing if semantically similar words group together.\")\n",
        "print(\"\\nExtrinsic Evaluation:\")\n",
        "print(\"Evaluating embedding performance when used as features in downstream NLP tasks such as:\")\n",
        "print(\"- Text Classification (e.g., sentiment analysis)\")\n",
        "print(\"- Named Entity Recognition (NER)\")\n",
        "print(\"- Machine Translation\")\n",
        "print(\"The performance on these tasks indicates the practical utility of the embeddings.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-3y3JaEUCkR",
        "outputId": "c9d598cc-7ef1-45f4-8223-fe185a8b26ca"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Other Evaluation Methods ---\n",
            "Beyond cosine similarity and visualization, word embeddings can be evaluated using:\n",
            "Intrinsic Evaluation:\n",
            "- Word Similarity Benchmarks: Comparing embedding similarity to human ratings on datasets (e.g., MEN, WS-353).\n",
            "- Word Analogy Tasks: Testing if vector relationships hold for analogies (e.g., 'king' - 'man' + 'woman' ≈ 'queen').\n",
            "- Word Categorization/Clustering: Assessing if semantically similar words group together.\n",
            "\n",
            "Extrinsic Evaluation:\n",
            "Evaluating embedding performance when used as features in downstream NLP tasks such as:\n",
            "- Text Classification (e.g., sentiment analysis)\n",
            "- Named Entity Recognition (NER)\n",
            "- Machine Translation\n",
            "The performance on these tasks indicates the practical utility of the embeddings.\n"
          ]
        }
      ]
    }
  ]
}