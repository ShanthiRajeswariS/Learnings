{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbb4bf1f99dc434798870ab7444fb71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70c0f927fb03486f87ed270ad3026b90",
              "IPY_MODEL_fa38108993de47eb8f40ef15d05f01b0",
              "IPY_MODEL_5daaa94d5d2845d4ba8746ef6bb27b6a"
            ],
            "layout": "IPY_MODEL_0f6c9e1a00a7408d8667a3998ecfb9bb"
          }
        },
        "70c0f927fb03486f87ed270ad3026b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb590d7ae3fc49e68bee051d5f214fd3",
            "placeholder": "​",
            "style": "IPY_MODEL_4e7f1cd832e6427d8e7a8c3299ecb329",
            "value": "config.json: 100%"
          }
        },
        "fa38108993de47eb8f40ef15d05f01b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90926cc37abe404baee5e7098eebfeb0",
            "max": 473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4a07251a42848ae908c9d7aef17d915",
            "value": 473
          }
        },
        "5daaa94d5d2845d4ba8746ef6bb27b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dcd8e149df14e958058d3912e9c78ec",
            "placeholder": "​",
            "style": "IPY_MODEL_fd04b414623d462dbc8b7cedc72fc840",
            "value": " 473/473 [00:00&lt;00:00, 14.4kB/s]"
          }
        },
        "0f6c9e1a00a7408d8667a3998ecfb9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb590d7ae3fc49e68bee051d5f214fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7f1cd832e6427d8e7a8c3299ecb329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90926cc37abe404baee5e7098eebfeb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a07251a42848ae908c9d7aef17d915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dcd8e149df14e958058d3912e9c78ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd04b414623d462dbc8b7cedc72fc840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b20e3f983fb494491c7370cc04726b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d564f8f27d4c4ff8845cc8f142c26fc5",
              "IPY_MODEL_8a57d613ff9d4a1bbc5b869dac04fc2a",
              "IPY_MODEL_70c2c29434904467857bf0de4d8acbc5"
            ],
            "layout": "IPY_MODEL_352ac68173ee4c7087197255f5cb0ebc"
          }
        },
        "d564f8f27d4c4ff8845cc8f142c26fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe0d24e0fde4396b5f4c7d11a7d6e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac02955eed74c6a8e6fe99794aac2e2",
            "value": "model.safetensors: 100%"
          }
        },
        "8a57d613ff9d4a1bbc5b869dac04fc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef80e7aa851a47338607d25753ee0661",
            "max": 260782156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1aa162dd895e4778ae99d4846171e34c",
            "value": 260782156
          }
        },
        "70c2c29434904467857bf0de4d8acbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8b6073088d4cb4ab43f8c0b99d26ac",
            "placeholder": "​",
            "style": "IPY_MODEL_94274e5d5cf040ce855129065cf5fd71",
            "value": " 261M/261M [00:02&lt;00:00, 130MB/s]"
          }
        },
        "352ac68173ee4c7087197255f5cb0ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe0d24e0fde4396b5f4c7d11a7d6e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac02955eed74c6a8e6fe99794aac2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef80e7aa851a47338607d25753ee0661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa162dd895e4778ae99d4846171e34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e8b6073088d4cb4ab43f8c0b99d26ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94274e5d5cf040ce855129065cf5fd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebb53fe89bf1422cb3a0da9d44fe0043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da368d2353524998a21345ec4f12c776",
              "IPY_MODEL_8a74da7c1699453ca3ed1c0e4d081e50",
              "IPY_MODEL_31465c2b9b2c47aa9ceec31b28a89e89"
            ],
            "layout": "IPY_MODEL_bbbcd668ecb242889e826de6d7f7e67a"
          }
        },
        "da368d2353524998a21345ec4f12c776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3365f094b08149679131a3491882aa47",
            "placeholder": "​",
            "style": "IPY_MODEL_c46333cd8dfd48afa30bad458e870f4b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8a74da7c1699453ca3ed1c0e4d081e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44dc3a96967047d0952927da15d77ddf",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb65ba26b80d404e9781a8df45d82e31",
            "value": 49
          }
        },
        "31465c2b9b2c47aa9ceec31b28a89e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45824032ee61496896c29902b9713c26",
            "placeholder": "​",
            "style": "IPY_MODEL_aff29b18c5644764bbc3acae980b086e",
            "value": " 49.0/49.0 [00:00&lt;00:00, 1.55kB/s]"
          }
        },
        "bbbcd668ecb242889e826de6d7f7e67a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3365f094b08149679131a3491882aa47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46333cd8dfd48afa30bad458e870f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44dc3a96967047d0952927da15d77ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb65ba26b80d404e9781a8df45d82e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45824032ee61496896c29902b9713c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff29b18c5644764bbc3acae980b086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f50aea5720247c88034d28906f3870d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_070aa753767f4f70860d134e97035a90",
              "IPY_MODEL_51508f7d63b64f299d925f686a0573f2",
              "IPY_MODEL_36e89f96bb434eaeb5e8a856282f4fd9"
            ],
            "layout": "IPY_MODEL_a52fab7db15e40d68d896c036328854b"
          }
        },
        "070aa753767f4f70860d134e97035a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e9360e9f664e37838597e0067d5236",
            "placeholder": "​",
            "style": "IPY_MODEL_f49e7a58a9084ebc9da0ac5e2e07c25f",
            "value": "vocab.txt: 100%"
          }
        },
        "51508f7d63b64f299d925f686a0573f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_678545fae3184aec95d9873847fd3a76",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92f8672f431e49328f3fc474b0ce9338",
            "value": 213450
          }
        },
        "36e89f96bb434eaeb5e8a856282f4fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8ddc3a276db4e988a82c69f16758b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d80c1ba14e4dbd98a78547bad6840b",
            "value": " 213k/213k [00:00&lt;00:00, 2.66MB/s]"
          }
        },
        "a52fab7db15e40d68d896c036328854b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e9360e9f664e37838597e0067d5236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49e7a58a9084ebc9da0ac5e2e07c25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "678545fae3184aec95d9873847fd3a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f8672f431e49328f3fc474b0ce9338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8ddc3a276db4e988a82c69f16758b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d80c1ba14e4dbd98a78547bad6840b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8dc2fe703134127afdf8c9c8360cd3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdb392a9ee394b5ea16e25e0c8528fb8",
              "IPY_MODEL_3cf10dcb6f764d5596dc5481764914f4",
              "IPY_MODEL_5a16cb6928f54c2798ecec5c1ed274f7"
            ],
            "layout": "IPY_MODEL_606049900c164582b6162a28c134a4d6"
          }
        },
        "bdb392a9ee394b5ea16e25e0c8528fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41a59c82f0b94b7b98fbefad053accdd",
            "placeholder": "​",
            "style": "IPY_MODEL_fdeb887762a74ff5b9ad785a8c79eb39",
            "value": "tokenizer.json: 100%"
          }
        },
        "3cf10dcb6f764d5596dc5481764914f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835ea94b83024ccfb7d74637c00456e5",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cc6ff1d757c4775ab1a15cb353632ef",
            "value": 435797
          }
        },
        "5a16cb6928f54c2798ecec5c1ed274f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_777b0ca5940d4128bd91fc7f1835482d",
            "placeholder": "​",
            "style": "IPY_MODEL_376c50b33ce044eaa7a11438256895fc",
            "value": " 436k/436k [00:00&lt;00:00, 2.19MB/s]"
          }
        },
        "606049900c164582b6162a28c134a4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a59c82f0b94b7b98fbefad053accdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdeb887762a74ff5b9ad785a8c79eb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835ea94b83024ccfb7d74637c00456e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc6ff1d757c4775ab1a15cb353632ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "777b0ca5940d4128bd91fc7f1835482d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "376c50b33ce044eaa7a11438256895fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a0f51eefb724c2b8d077545a77d531f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eafe6efba474d71a95704951812b396",
              "IPY_MODEL_c30beb465bfb4119a6ce5ccad6e9f56f",
              "IPY_MODEL_6c5db4199745485b95ad2b7793a73254"
            ],
            "layout": "IPY_MODEL_178be97ac1ba440896ffe4ab1ec95c88"
          }
        },
        "8eafe6efba474d71a95704951812b396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91997dffee654a5cbfa8771a3ca7fb53",
            "placeholder": "​",
            "style": "IPY_MODEL_85d9a71da21045d1aaa268bb1d1ba022",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c30beb465bfb4119a6ce5ccad6e9f56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9533b6d64b7748249f75e4d2f88016dc",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ca349c1315c4c088399b4d344bbbb94",
            "value": 48
          }
        },
        "6c5db4199745485b95ad2b7793a73254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_678387969ac74d6eb61913311b025426",
            "placeholder": "​",
            "style": "IPY_MODEL_161da51a314b46cda07c7982d44108aa",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.41kB/s]"
          }
        },
        "178be97ac1ba440896ffe4ab1ec95c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91997dffee654a5cbfa8771a3ca7fb53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d9a71da21045d1aaa268bb1d1ba022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9533b6d64b7748249f75e4d2f88016dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca349c1315c4c088399b4d344bbbb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "678387969ac74d6eb61913311b025426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "161da51a314b46cda07c7982d44108aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d43a9179b0847ad8f2dd07f501e8f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3718082557eb4bf3859f570ddb235b29",
              "IPY_MODEL_4296c3dd79d847309e81eaab4dc24504",
              "IPY_MODEL_fe58f32dec6e4b27af4c5ebba61168d2"
            ],
            "layout": "IPY_MODEL_fb24d3e6d61c4f6baf39dd076a8121f4"
          }
        },
        "3718082557eb4bf3859f570ddb235b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bdce7c39b4b4f11b3450886cd776e29",
            "placeholder": "​",
            "style": "IPY_MODEL_63d615a7493746b0b5aac49e46a8be76",
            "value": "vocab.txt: 100%"
          }
        },
        "4296c3dd79d847309e81eaab4dc24504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec16caab6847428082e18772873fd17b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bc410e1597241dc93263ba4045720d9",
            "value": 231508
          }
        },
        "fe58f32dec6e4b27af4c5ebba61168d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2e6190c1d17408dab0890d8ad2ec273",
            "placeholder": "​",
            "style": "IPY_MODEL_baf8615862ad44c582490fb4477e6e6b",
            "value": " 232k/232k [00:00&lt;00:00, 4.81MB/s]"
          }
        },
        "fb24d3e6d61c4f6baf39dd076a8121f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bdce7c39b4b4f11b3450886cd776e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d615a7493746b0b5aac49e46a8be76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec16caab6847428082e18772873fd17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc410e1597241dc93263ba4045720d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2e6190c1d17408dab0890d8ad2ec273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf8615862ad44c582490fb4477e6e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "651cbb718c8344f58f9e425fe5955d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecc8141b6a024e75ac4889a5ac15ddc9",
              "IPY_MODEL_8728c89babcc4c3abed282c25f4a9e9b",
              "IPY_MODEL_9f2f9710a8b74d1daf30b3d6fc6ec43b"
            ],
            "layout": "IPY_MODEL_518212e1544540018b8d95b194f12b63"
          }
        },
        "ecc8141b6a024e75ac4889a5ac15ddc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9abd754786ec480e97ba6310666cb9b7",
            "placeholder": "​",
            "style": "IPY_MODEL_2c35adf2993d46cfbda586948eaef451",
            "value": "tokenizer.json: 100%"
          }
        },
        "8728c89babcc4c3abed282c25f4a9e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d115bdce45b4cdb81478548ba2cee11",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fe53a91ff6b43e783fc5234694abe3c",
            "value": 466062
          }
        },
        "9f2f9710a8b74d1daf30b3d6fc6ec43b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece01ea50e64453a9de0b83d0c99ae1f",
            "placeholder": "​",
            "style": "IPY_MODEL_1a6201620c1e45c484a42dc672a1ec85",
            "value": " 466k/466k [00:00&lt;00:00, 7.50MB/s]"
          }
        },
        "518212e1544540018b8d95b194f12b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9abd754786ec480e97ba6310666cb9b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c35adf2993d46cfbda586948eaef451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d115bdce45b4cdb81478548ba2cee11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fe53a91ff6b43e783fc5234694abe3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ece01ea50e64453a9de0b83d0c99ae1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6201620c1e45c484a42dc672a1ec85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55e3c7ca003848b9b0f47533aaf3289c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5aaa2cdbc4bf4c27aa472a0113e416e3",
              "IPY_MODEL_fee13418ef0e44119e98a9b697a94027",
              "IPY_MODEL_efbef76d769d460489c96c24b9a29da8"
            ],
            "layout": "IPY_MODEL_5064dd90267047d2b4d3530dd01994f5"
          }
        },
        "5aaa2cdbc4bf4c27aa472a0113e416e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84bdffa1aa114687ae1821fdf4ca518a",
            "placeholder": "​",
            "style": "IPY_MODEL_e688d80695704ccaac039498ba9dc0ad",
            "value": "config.json: 100%"
          }
        },
        "fee13418ef0e44119e98a9b697a94027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_631ddbbacd47431aa46ddd4ec26fb447",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfc2e1a433ea405d9ef6be5a02c7f6cb",
            "value": 570
          }
        },
        "efbef76d769d460489c96c24b9a29da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e936cf7942841c49fd99dc37b77d4a0",
            "placeholder": "​",
            "style": "IPY_MODEL_e7536e59a715467285078e3a2218aa45",
            "value": " 570/570 [00:00&lt;00:00, 51.6kB/s]"
          }
        },
        "5064dd90267047d2b4d3530dd01994f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84bdffa1aa114687ae1821fdf4ca518a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e688d80695704ccaac039498ba9dc0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "631ddbbacd47431aa46ddd4ec26fb447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc2e1a433ea405d9ef6be5a02c7f6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e936cf7942841c49fd99dc37b77d4a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7536e59a715467285078e3a2218aa45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cede57e90f4542e181ab6851c7c24a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_885dea78b42c4e70baf727ff9466508d",
              "IPY_MODEL_6e8eb45dc69b4a558dbd5af19efa6d3f",
              "IPY_MODEL_d155f7d556c94f52b95f10b5df73cca5"
            ],
            "layout": "IPY_MODEL_443e4601b495465ea75ad31077543257"
          }
        },
        "885dea78b42c4e70baf727ff9466508d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18cb025741164bfdaa4bfc61ffac5bae",
            "placeholder": "​",
            "style": "IPY_MODEL_45dcb191bfc0452b84e58a1e747fb8c2",
            "value": "model.safetensors: 100%"
          }
        },
        "6e8eb45dc69b4a558dbd5af19efa6d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e4bf2ef5c9f4b6397d9205e6704d30c",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2577e3bc34554c1b8f4b55dacc1c03d7",
            "value": 440449768
          }
        },
        "d155f7d556c94f52b95f10b5df73cca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_447a1a098f5847b28c96e1fc6e674290",
            "placeholder": "​",
            "style": "IPY_MODEL_9f76c8ef23bc4aa4b98c6e633a949d35",
            "value": " 440M/440M [00:02&lt;00:00, 185MB/s]"
          }
        },
        "443e4601b495465ea75ad31077543257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18cb025741164bfdaa4bfc61ffac5bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45dcb191bfc0452b84e58a1e747fb8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e4bf2ef5c9f4b6397d9205e6704d30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2577e3bc34554c1b8f4b55dacc1c03d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "447a1a098f5847b28c96e1fc6e674290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f76c8ef23bc4aa4b98c6e633a949d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Natural Language Processing**"
      ],
      "metadata": {
        "id": "uKRf12DSav-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing (NLP) is a field of artificial intelligence that enables computers to understand, interpret, and generate human language"
      ],
      "metadata": {
        "id": "ct6VYArKawA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1.Text Preprocessing"
      ],
      "metadata": {
        "id": "0eZi8uaNawDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text preprocessing transforms raw text into a clean format suitable for analysis"
      ],
      "metadata": {
        "id": "PVOdZYkpawF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ],
      "metadata": {
        "id": "VfFU6JT6a8Fp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_N5st24a8Il",
        "outputId": "53bade0c-ad3e-45e2-bd12-0ecb15ac57cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"Natural Language Processing (NLP) is fascinating! It helps computers understand human language.\""
      ],
      "metadata": {
        "id": "p5PZIKuja8Ls"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lowercasing"
      ],
      "metadata": {
        "id": "3hwteVCGcIE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercasing\n",
        "text = text.lower()\n",
        "print(\"Lowercase:\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrVBOv10a8OT",
        "outputId": "b07e05a3-95e0-40f5-ec23-f54b2c1de16c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase: natural language processing (nlp) is fascinating! it helps computers understand human language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove special characters and numbers"
      ],
      "metadata": {
        "id": "xTG2fy3dcKZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove special characters and numbers\n",
        "text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "print(\"Without special chars:\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOmKpKNjbGOh",
        "outputId": "571acf4d-785e-4fe9-817f-b85a81eb7c0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without special chars: natural language processing nlp is fascinating it helps computers understand human language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "-99dlyYscL9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlscboWCbGRh",
        "outputId": "914a1861-455c-4009-9e19-ec2564496d7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['natural', 'language', 'processing', 'nlp', 'is', 'fascinating', 'it', 'helps', 'computers', 'understand', 'human', 'language']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove stopwords"
      ],
      "metadata": {
        "id": "f9H0HGe4cRkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "print(\"Without stopwords:\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IFvHAa8bGUS",
        "outputId": "41f490a4-bc19-4c93-a1aa-50a58fe74882"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without stopwords: ['natural', 'language', 'processing', 'nlp', 'fascinating', 'helps', 'computers', 'understand', 'human', 'language']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TO1RJQz_bGW-",
        "outputId": "ed0520b3-0b1e-422e-9d52-3355aca41253"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " \"he'd\",\n",
              " \"he'll\",\n",
              " \"he's\",\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " \"i'd\",\n",
              " \"i'll\",\n",
              " \"i'm\",\n",
              " \"i've\",\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it'd\",\n",
              " \"it'll\",\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she'd\",\n",
              " \"she'll\",\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " \"they'd\",\n",
              " \"they'll\",\n",
              " \"they're\",\n",
              " \"they've\",\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " \"we'd\",\n",
              " \"we'll\",\n",
              " \"we're\",\n",
              " \"we've\",\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming"
      ],
      "metadata": {
        "id": "sFRG2nUbcTQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"Stemmed words:\", stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiWLvKhsa8RC",
        "outputId": "ca87fef4-f655-4bdc-836c-5bae8989debe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed words: ['natur', 'languag', 'process', 'nlp', 'fascin', 'help', 'comput', 'understand', 'human', 'languag']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization"
      ],
      "metadata": {
        "id": "Z18YPuxTcVgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"Lemmatized words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JgYA40ra8Tj",
        "outputId": "85939a31-8112-4a61-9429-6563cff2003a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized words: ['natural', 'language', 'processing', 'nlp', 'fascinating', 'help', 'computer', 'understand', 'human', 'language']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Text Representation"
      ],
      "metadata": {
        "id": "Gad2WBDDawIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting text to numerical formats is essential for machine learning models"
      ],
      "metadata": {
        "id": "Sg_gSSh-awLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD7pCfg4cXwC",
        "outputId": "be71ace7-51c5-4ec3-c47b-82e9b231b60c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs05KeO_ckmZ",
        "outputId": "96b3289e-a3fc-418a-a1c5-1fe7bb6e3499"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aIhrLOdJcBFC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset\n",
        "texts = [\n",
        "    \"Natural language processing helps computers understand human language\",\n",
        "    \"Machine learning models can process text data effectively\",\n",
        "    \"Text preprocessing is an essential step in NLP pipelines\",\n",
        "    \"Word embeddings capture semantic relationships between words\"\n",
        "]"
      ],
      "metadata": {
        "id": "vo3U_akpcBHz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words (BoW)"
      ],
      "metadata": {
        "id": "AKIickBSc4LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Bag of Words (BoW)\n",
        "cv = CountVectorizer()\n",
        "bow_matrix = cv.fit_transform(texts)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=cv.get_feature_names_out())\n",
        "print(\"Bag of Words Representation:\")\n",
        "print(bow_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4E6a5hlcBLL",
        "outputId": "1140dd29-3f0e-43c7-bc2d-4fed70047e7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Representation:\n",
            "   an  between  can  capture  computers  data  effectively  embeddings  \\\n",
            "0   0        0    0        0          1     0            0           0   \n",
            "1   0        0    1        0          0     1            1           0   \n",
            "2   1        0    0        0          0     0            0           0   \n",
            "3   0        1    0        1          0     0            0           1   \n",
            "\n",
            "   essential  helps  ...  preprocessing  process  processing  relationships  \\\n",
            "0          0      1  ...              0        0           1              0   \n",
            "1          0      0  ...              0        1           0              0   \n",
            "2          1      0  ...              1        0           0              0   \n",
            "3          0      0  ...              0        0           0              1   \n",
            "\n",
            "   semantic  step  text  understand  word  words  \n",
            "0         0     0     0           1     0      0  \n",
            "1         0     0     1           0     0      0  \n",
            "2         0     1     1           0     0      0  \n",
            "3         1     0     0           0     1      1  \n",
            "\n",
            "[4 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Representation"
      ],
      "metadata": {
        "id": "pm_ME7MvdNRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. TF-IDF Representation\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(texts)\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(tfidf_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INCJggsScBNa",
        "outputId": "eb8d66d8-4de9-407f-ec3c-571c03e18822"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Representation:\n",
            "        an   between       can   capture  computers      data  effectively  \\\n",
            "0  0.00000  0.000000  0.000000  0.000000   0.316228  0.000000     0.000000   \n",
            "1  0.00000  0.000000  0.362224  0.000000   0.000000  0.362224     0.362224   \n",
            "2  0.34057  0.000000  0.000000  0.000000   0.000000  0.000000     0.000000   \n",
            "3  0.00000  0.377964  0.000000  0.377964   0.000000  0.000000     0.000000   \n",
            "\n",
            "   embeddings  essential     helps  ...  preprocessing   process  processing  \\\n",
            "0    0.000000    0.00000  0.316228  ...        0.00000  0.000000    0.316228   \n",
            "1    0.000000    0.00000  0.000000  ...        0.00000  0.362224    0.000000   \n",
            "2    0.000000    0.34057  0.000000  ...        0.34057  0.000000    0.000000   \n",
            "3    0.377964    0.00000  0.000000  ...        0.00000  0.000000    0.000000   \n",
            "\n",
            "   relationships  semantic     step      text  understand      word     words  \n",
            "0       0.000000  0.000000  0.00000  0.000000    0.316228  0.000000  0.000000  \n",
            "1       0.000000  0.000000  0.00000  0.285582    0.000000  0.000000  0.000000  \n",
            "2       0.000000  0.000000  0.34057  0.268509    0.000000  0.000000  0.000000  \n",
            "3       0.377964  0.377964  0.00000  0.000000    0.000000  0.377964  0.377964  \n",
            "\n",
            "[4 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embeddings (Word2Vec)"
      ],
      "metadata": {
        "id": "Tj60zLEjdUsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Word Embeddings (Word2Vec)\n",
        "# Prepare data for Word2Vec\n",
        "tokenized_texts = [text.lower().split() for text in texts]"
      ],
      "metadata": {
        "id": "C2-q7XnrcBQD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WNWbdQ0ncBSU",
        "outputId": "8f0c1e42-8b7e-4ed3-c9ae-04591e119d38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  'helps',\n",
              "  'computers',\n",
              "  'understand',\n",
              "  'human',\n",
              "  'language'],\n",
              " ['machine',\n",
              "  'learning',\n",
              "  'models',\n",
              "  'can',\n",
              "  'process',\n",
              "  'text',\n",
              "  'data',\n",
              "  'effectively'],\n",
              " ['text',\n",
              "  'preprocessing',\n",
              "  'is',\n",
              "  'an',\n",
              "  'essential',\n",
              "  'step',\n",
              "  'in',\n",
              "  'nlp',\n",
              "  'pipelines'],\n",
              " ['word',\n",
              "  'embeddings',\n",
              "  'capture',\n",
              "  'semantic',\n",
              "  'relationships',\n",
              "  'between',\n",
              "  'words']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
        "w2v_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmjUjvFgcBVk",
        "outputId": "8986da61-4038-4eb1-e199-985bcf910d6d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7ea325b80050>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get vector for a word\n",
        "word = \"language\"\n",
        "if word in w2v_model.wv:\n",
        "    print(f\"\\nWord2Vec embedding for '{word}':\")\n",
        "    print(w2v_model.wv[word])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBd9LK7ocBYH",
        "outputId": "219d8d03-1209-4f08-aa57-133aa5cbf8fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec embedding for 'language':\n",
            "[-0.00536309  0.00236467  0.05104123  0.09010639 -0.0930436  -0.07117888\n",
            "  0.06459852  0.08974349 -0.05016188 -0.03763942]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Find similar words\n",
        "print(f\"\\nSimilar words to 'text':\")\n",
        "try:\n",
        "    similar_words = w2v_model.wv.most_similar(\"text\", topn=3)\n",
        "    for word, similarity in similar_words:\n",
        "        print(f\"{word}: {similarity:.4f}\")\n",
        "except KeyError:\n",
        "    print(\"Word not in vocabulary or not enough training data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzIPDdq_cBiK",
        "outputId": "68b34692-9b6e-4afe-b43b-ae761cbd4f66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Similar words to 'text':\n",
            "language: 0.5436\n",
            "pipelines: 0.4117\n",
            "embeddings: 0.4115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained word2vec embeddings\n",
        "word_vectors = api.load('word2vec-google-news-300')\n",
        "\n",
        "# Find similar words\n",
        "similar_words = word_vectors.most_similar('python')\n",
        "print(similar_words)\n",
        "\n",
        "# Word analogies\n",
        "result = word_vectors.most_similar(positive=['king', 'woman'], negative=['man'])\n",
        "print(f\"king - man + woman = {result[0][0]}\")  # Should output \"queen\"\n",
        "\n",
        "# Visualize embeddings\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Select a few words to visualize\n",
        "words = ['king', 'queen', 'man', 'woman', 'dog', 'cat', 'python', 'java']\n",
        "word_vectors_list = [word_vectors[word] for word in words]\n",
        "\n",
        "# Reduce to 2 dimensions for visualization\n",
        "pca = PCA(n_components=2)\n",
        "result = pca.fit_transform(word_vectors_list)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(result[:, 0], result[:, 1], alpha=0.5)\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
        "plt.title(\"Word Embeddings Visualization\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kXupEoW9Zg05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Text Classification"
      ],
      "metadata": {
        "id": "c8WQUm2NcBqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text classification assigns predefined categories to text documents"
      ],
      "metadata": {
        "id": "bM6rfEWbdpN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "CNeH45JGduVS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'text': [\n",
        "        \"I love this product, it's amazing!\",\n",
        "        \"Great service and excellent quality\",\n",
        "        \"Terrible experience, would not recommend\",\n",
        "        \"The worst purchase I've ever made\",\n",
        "        \"Absolutely fantastic customer support\",\n",
        "        \"Disappointed with the quality of the item\",\n",
        "        \"Very happy with my purchase\",\n",
        "        \"Product broke after one week\",\n",
        "        \"Exceeded all my expectations\",\n",
        "        \"Complete waste of money\"\n",
        "    ],\n",
        "    'sentiment': [1, 1, 0, 0, 1, 0, 1, 0, 1, 0]  # 1: positive, 0: negative\n",
        "}"
      ],
      "metadata": {
        "id": "C1-BGyQYduYN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "zQpFdd_udua_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "87_YxgN3dudk",
        "outputId": "3d0d232f-c7c4-494d-f29b-f52879134e22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       text  sentiment\n",
              "0        I love this product, it's amazing!          1\n",
              "1       Great service and excellent quality          1\n",
              "2  Terrible experience, would not recommend          0\n",
              "3         The worst purchase I've ever made          0\n",
              "4     Absolutely fantastic customer support          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0919897b-d1fe-46b8-89db-b5221fa645bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love this product, it's amazing!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great service and excellent quality</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Terrible experience, would not recommend</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The worst purchase I've ever made</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Absolutely fantastic customer support</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0919897b-d1fe-46b8-89db-b5221fa645bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0919897b-d1fe-46b8-89db-b5221fa645bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0919897b-d1fe-46b8-89db-b5221fa645bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acf8bedb-34be-4fa1-ae80-5154e3132096\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acf8bedb-34be-4fa1-ae80-5154e3132096')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acf8bedb-34be-4fa1-ae80-5154e3132096 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Exceeded all my expectations\",\n          \"Great service and excellent quality\",\n          \"Disappointed with the quality of the item\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['sentiment'], test_size=0.3, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "VcVjUny_duf8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "Jkx9135Kdukx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Naive Bayes Classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "nb_pred = nb_classifier.predict(X_test_tfidf)\n",
        "print(\"Naive Bayes Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, nb_pred):.4f}\")\n",
        "print(classification_report(y_test, nb_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXd5z-1vd7pB",
        "outputId": "5467e067-d389-4117-eb16-7092fc716bd0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Performance:\n",
            "Accuracy: 0.6667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.75      0.75      0.67         3\n",
            "weighted avg       0.83      0.67      0.67         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Logistic Regression\n",
        "lr_classifier = LogisticRegression(random_state=42)\n",
        "lr_classifier.fit(X_train_tfidf, y_train)\n",
        "lr_pred = lr_classifier.predict(X_test_tfidf)\n",
        "print(\"\\nLogistic Regression Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, lr_pred):.4f}\")\n",
        "print(classification_report(y_test, lr_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaTvofIbd7sF",
        "outputId": "4449eb08-753c-4f0f-dc9f-7415ef777cfb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Performance:\n",
            "Accuracy: 0.3333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Support Vector Machine\n",
        "svm_classifier = LinearSVC(random_state=42)\n",
        "svm_classifier.fit(X_train_tfidf, y_train)\n",
        "svm_pred = svm_classifier.predict(X_test_tfidf)\n",
        "print(\"\\nSVM Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, svm_pred):.4f}\")\n",
        "print(classification_report(y_test, svm_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLwCxnmbd7vO",
        "outputId": "43829953-03f9-40c6-8c7a-1321ac2f1971"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Performance:\n",
            "Accuracy: 0.6667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.75      0.75      0.67         3\n",
            "weighted avg       0.83      0.67      0.67         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify new texts\n",
        "new_texts = [\n",
        "    \"I'm really happy with this purchase\",\n",
        "    \"This product is horrible and disappointing\"\n",
        "]\n",
        "new_texts_tfidf = vectorizer.transform(new_texts)\n",
        "predictions = svm_classifier.predict(new_texts_tfidf)"
      ],
      "metadata": {
        "id": "ujnEEoupd7yK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNew Text Predictions:\")\n",
        "for text, pred in zip(new_texts, predictions):\n",
        "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
        "    print(f\"Text: '{text}' - Prediction: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy_fbydUd71k",
        "outputId": "0e1e9897-9cc3-4494-da95-6124d0a72f5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New Text Predictions:\n",
            "Text: 'I'm really happy with this purchase' - Prediction: Positive\n",
            "Text: 'This product is horrible and disappointing' - Prediction: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load AG News dataset\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "\n",
        "# Prepare data\n",
        "train_texts = dataset[\"train\"][\"text\"][:10000]  # Using subset for speed\n",
        "train_labels = dataset[\"train\"][\"label\"][:10000]\n",
        "test_texts = dataset[\"test\"][\"text\"][:1000]\n",
        "test_labels = dataset[\"test\"][\"label\"][:1000]\n",
        "\n",
        "# Create classification pipeline\n",
        "text_clf = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(stop_words='english')),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Train the classifier\n",
        "text_clf.fit(train_texts, train_labels)\n",
        "\n",
        "# Evaluate\n",
        "predictions = text_clf.predict(test_texts)\n",
        "print(classification_report(test_labels, predictions))\n",
        "\n",
        "# Predict new examples\n",
        "new_texts = [\n",
        "    \"Oil prices rise due to supply concerns\",\n",
        "    \"Scientists discover new species in Amazon rainforest\",\n",
        "    \"New smartphone features advanced camera technology\",\n",
        "    \"Local team wins championship game in overtime\"\n",
        "]\n",
        "predictions = text_clf.predict(new_texts)\n",
        "\n",
        "# Map prediction indices to category names\n",
        "categories = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Science/Tech\"}\n",
        "for text, pred in zip(new_texts, predictions):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Category: {categories[pred]}\\n\")"
      ],
      "metadata": {
        "id": "RArsV9STbLIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "lzOMva2bdpQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NER identifies entities like names, locations, and organizations in text"
      ],
      "metadata": {
        "id": "dcBx31FmdpTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk\n",
        "from nltk.chunk import ne_chunk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import pos_tag\n"
      ],
      "metadata": {
        "id": "uz6CXE4AePr7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker_tab')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gchOsz7WePu1",
        "outputId": "a90d26de-dbaf-4304-81d7-60b2213c446a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text\n",
        "text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California. The company released iPhone 14 in September 2022.\""
      ],
      "metadata": {
        "id": "-pLYLTUCePxi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. NER with NLTK\n",
        "print(\"Named Entity Recognition with NLTK:\")\n",
        "tokens = word_tokenize(text)\n",
        "tagged = pos_tag(tokens)\n",
        "entities = ne_chunk(tagged)\n",
        "print(entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pUSmpfQeP2z",
        "outputId": "4a1b215d-3c92-4f4c-8a39-cf0dbbef24fa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition with NLTK:\n",
            "(S\n",
            "  (PERSON Apple/NNP)\n",
            "  (ORGANIZATION Inc./NNP)\n",
            "  was/VBD\n",
            "  founded/VBN\n",
            "  by/IN\n",
            "  (PERSON Steve/NNP Jobs/NNP)\n",
            "  in/IN\n",
            "  (GPE Cupertino/NNP)\n",
            "  ,/,\n",
            "  (GPE California/NNP)\n",
            "  ./.\n",
            "  The/DT\n",
            "  company/NN\n",
            "  released/VBD\n",
            "  (ORGANIZATION iPhone/NN)\n",
            "  14/CD\n",
            "  in/IN\n",
            "  September/NNP\n",
            "  2022/CD\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. NER with spaCy\n",
        "print(\"\\nNamed Entity Recognition with spaCy:\")\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Display entities\n",
        "    for ent in doc.ents:\n",
        "        print(f\"Entity: {ent.text} - Label: {ent.label_} - Description: {spacy.explain(ent.label_)}\")\n",
        "\n",
        "    # Custom function to display entities in context\n",
        "    def display_entities(text):\n",
        "        doc = nlp(text)\n",
        "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "        print(f\"\\nEntities found in text: {len(entities)}\")\n",
        "        for entity, label in entities:\n",
        "            print(f\"- {entity}: {label}\")\n",
        "\n",
        "        return doc\n",
        "\n",
        "    # Example with different text\n",
        "    business_text = \"Microsoft announced a partnership with OpenAI in New York last week. CEO Satya Nadella said the deal was worth $10 billion.\"\n",
        "    display_entities(business_text)\n",
        "\n",
        "except ImportError:\n",
        "    print(\"To use spaCy, install it with: pip install spacy\")\n",
        "    print(\"Then download the English model: python -m spacy download en_core_web_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FfRTrr6eP6N",
        "outputId": "411e3f8c-34da-49b3-b782-5f8bab27245e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Named Entity Recognition with spaCy:\n",
            "Entity: Apple Inc. - Label: ORG - Description: Companies, agencies, institutions, etc.\n",
            "Entity: Steve Jobs - Label: PERSON - Description: People, including fictional\n",
            "Entity: Cupertino - Label: GPE - Description: Countries, cities, states\n",
            "Entity: California - Label: GPE - Description: Countries, cities, states\n",
            "Entity: 14 - Label: CARDINAL - Description: Numerals that do not fall under another type\n",
            "Entity: September 2022 - Label: DATE - Description: Absolute or relative dates or periods\n",
            "\n",
            "Entities found in text: 6\n",
            "- Microsoft: ORG\n",
            "- OpenAI: ORG\n",
            "- New York: GPE\n",
            "- last week: DATE\n",
            "- Satya Nadella: PERSON\n",
            "- $10 billion: MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "\n",
        "# Create NER pipeline\n",
        "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Sample text\n",
        "text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California.\"\n",
        "entities = ner_pipeline(text)\n",
        "\n",
        "for entity in entities:\n",
        "    print(f\"Entity: {entity['word']}, Type: {entity['entity_group']}, Score: {entity['score']:.4f}\")"
      ],
      "metadata": {
        "id": "LL8C-8jIaUZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Sentiment Analysis"
      ],
      "metadata": {
        "id": "s7ASlSFyfBJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis determines the emotional tone behind text"
      ],
      "metadata": {
        "id": "yM4gYSUHfDrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU775E9xeP_B",
        "outputId": "43df634e-674b-41af-8087-810202c7cccc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNYykbsreQB1",
        "outputId": "e34912b9-312b-4e25-c3cf-81de80a09259"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample customer reviews\n",
        "reviews = [\n",
        "    \"This product is amazing! I absolutely love it.\",\n",
        "    \"Good quality but a bit expensive for what you get.\",\n",
        "    \"Terrible customer service, would not recommend.\",\n",
        "    \"The product was okay, nothing special.\",\n",
        "    \"I hate this product, complete waste of money!\",\n",
        "    \"Decent product but shipping took too long.\",\n",
        "    \"Best purchase I've made this year!\",\n",
        "    \"Not bad, but I expected more features.\"\n",
        "]"
      ],
      "metadata": {
        "id": "oEEY98W0eQD_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. VADER Sentiment Analysis\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "vader_results = []\n",
        "for review in reviews:\n",
        "    sentiment_scores = sia.polarity_scores(review)\n",
        "    compound_score = sentiment_scores['compound']\n",
        "\n",
        "    if compound_score >= 0.05:\n",
        "        sentiment = \"Positive\"\n",
        "    elif compound_score <= -0.05:\n",
        "        sentiment = \"Negative\"\n",
        "    else:\n",
        "        sentiment = \"Neutral\"\n",
        "\n",
        "    vader_results.append({\n",
        "        'review': review,\n",
        "        'compound_score': compound_score,\n",
        "        'sentiment': sentiment\n",
        "    })"
      ],
      "metadata": {
        "id": "C9N6t5LEfYcw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vader_df = pd.DataFrame(vader_results)\n",
        "print(\"VADER Sentiment Analysis:\")\n",
        "print(vader_df[['review', 'compound_score', 'sentiment']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faKEO07ZfYfw",
        "outputId": "b23643d2-b468-4830-aded-13cba202162b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VADER Sentiment Analysis:\n",
            "                                              review  compound_score sentiment\n",
            "0     This product is amazing! I absolutely love it.          0.8620  Positive\n",
            "1  Good quality but a bit expensive for what you ...          0.2382  Positive\n",
            "2    Terrible customer service, would not recommend.         -0.6381  Negative\n",
            "3             The product was okay, nothing special.         -0.0920  Negative\n",
            "4      I hate this product, complete waste of money!         -0.7777  Negative\n",
            "5         Decent product but shipping took too long.          0.0000   Neutral\n",
            "6                 Best purchase I've made this year!          0.6696  Positive\n",
            "7             Not bad, but I expected more features.          0.2323  Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. TextBlob Sentiment Analysis\n",
        "textblob_results = []\n",
        "for review in reviews:\n",
        "    analysis = TextBlob(review)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "\n",
        "    if polarity > 0:\n",
        "        sentiment = \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        sentiment = \"Negative\"\n",
        "    else:\n",
        "        sentiment = \"Neutral\"\n",
        "\n",
        "    textblob_results.append({\n",
        "        'review': review,\n",
        "        'polarity': polarity,\n",
        "        'subjectivity': analysis.sentiment.subjectivity,\n",
        "        'sentiment': sentiment\n",
        "    })"
      ],
      "metadata": {
        "id": "Knp8RfSBff1V"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textblob_df = pd.DataFrame(textblob_results)\n",
        "print(\"\\nTextBlob Sentiment Analysis:\")\n",
        "print(textblob_df[['review', 'polarity', 'subjectivity', 'sentiment']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3XuUyoFff5Q",
        "outputId": "b8dc654f-553c-4f5d-a6fe-cc3c3575921b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TextBlob Sentiment Analysis:\n",
            "                                              review  polarity  subjectivity  \\\n",
            "0     This product is amazing! I absolutely love it.  0.625000      0.750000   \n",
            "1  Good quality but a bit expensive for what you ...  0.100000      0.650000   \n",
            "2    Terrible customer service, would not recommend. -1.000000      1.000000   \n",
            "3             The product was okay, nothing special.  0.428571      0.535714   \n",
            "4      I hate this product, complete waste of money! -0.316667      0.433333   \n",
            "5         Decent product but shipping took too long.  0.058333      0.533333   \n",
            "6                 Best purchase I've made this year!  1.000000      0.300000   \n",
            "7             Not bad, but I expected more features.  0.250000      0.522222   \n",
            "\n",
            "  sentiment  \n",
            "0  Positive  \n",
            "1  Positive  \n",
            "2  Negative  \n",
            "3  Positive  \n",
            "4  Negative  \n",
            "5  Positive  \n",
            "6  Positive  \n",
            "7  Positive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Compare results from both methods\n",
        "comparison = pd.DataFrame({\n",
        "    'review': reviews,\n",
        "    'vader_sentiment': vader_df['sentiment'],\n",
        "    'textblob_sentiment': textblob_df['sentiment']\n",
        "})\n",
        "\n",
        "print(\"\\nComparison of Sentiment Analysis Methods:\")\n",
        "print(comparison)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5RHyvA-fYin",
        "outputId": "35b7bb9e-d772-4700-9949-886fea5f5296"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of Sentiment Analysis Methods:\n",
            "                                              review vader_sentiment  \\\n",
            "0     This product is amazing! I absolutely love it.        Positive   \n",
            "1  Good quality but a bit expensive for what you ...        Positive   \n",
            "2    Terrible customer service, would not recommend.        Negative   \n",
            "3             The product was okay, nothing special.        Negative   \n",
            "4      I hate this product, complete waste of money!        Negative   \n",
            "5         Decent product but shipping took too long.         Neutral   \n",
            "6                 Best purchase I've made this year!        Positive   \n",
            "7             Not bad, but I expected more features.        Positive   \n",
            "\n",
            "  textblob_sentiment  \n",
            "0           Positive  \n",
            "1           Positive  \n",
            "2           Negative  \n",
            "3           Positive  \n",
            "4           Negative  \n",
            "5           Positive  \n",
            "6           Positive  \n",
            "7           Positive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample code for a real-world application - Analyze Twitter data\n",
        "def analyze_tweet_sentiment(tweets):\n",
        "    results = []\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    for tweet in tweets:\n",
        "        sentiment_scores = sia.polarity_scores(tweet)\n",
        "        compound = sentiment_scores['compound']\n",
        "\n",
        "        if compound >= 0.05:\n",
        "            sentiment = \"Positive\"\n",
        "        elif compound <= -0.05:\n",
        "            sentiment = \"Negative\"\n",
        "        else:\n",
        "            sentiment = \"Neutral\"\n",
        "\n",
        "        results.append({\n",
        "            'tweet': tweet,\n",
        "            'compound': compound,\n",
        "            'sentiment': sentiment\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "-XUL2XRIfYlI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sample tweets\n",
        "sample_tweets = [\n",
        "    \"I can't believe how good the new update is! #excited\",\n",
        "    \"Service down again for the third time this week. Frustrating!\",\n",
        "    \"Just received my order, packaging looks nice.\",\n",
        "    \"This company never responds to customer complaints #badservice\"\n",
        "]\n",
        "\n",
        "tweet_analysis = analyze_tweet_sentiment(sample_tweets)\n",
        "print(\"\\nTwitter Sentiment Analysis:\")\n",
        "print(tweet_analysis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cLSUiaeeQGp",
        "outputId": "2a6cad27-3ec5-46ef-a91e-fada6bc28ebb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Twitter Sentiment Analysis:\n",
            "                                               tweet  compound sentiment\n",
            "0  I can't believe how good the new update is! #e...   -0.4015  Negative\n",
            "1  Service down again for the third time this wee...   -0.4926  Negative\n",
            "2      Just received my order, packaging looks nice.    0.4215  Positive\n",
            "3  This company never responds to customer compla...   -0.4019  Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Load IMDb dataset\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"imdb\", split=\"test\").shuffle(seed=42).select(range(100))\n",
        "\n",
        "# Analyze sentiments\n",
        "results = []\n",
        "for review in dataset[\"text\"][:10]:  # Analyze first 10 reviews\n",
        "    truncated_review = review[:512]  # Most models have token limits\n",
        "    sentiment = sentiment_analyzer(truncated_review)[0]\n",
        "    results.append({\n",
        "        \"review_snippet\": truncated_review[:100] + \"...\",\n",
        "        \"sentiment\": sentiment[\"label\"],\n",
        "        \"score\": sentiment[\"score\"]\n",
        "    })\n",
        "\n",
        "# Display results\n",
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "cFuLP4iTamT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Topic Modeling"
      ],
      "metadata": {
        "id": "BDBZKsDnf97C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic modeling discovers abstract topics in document collections"
      ],
      "metadata": {
        "id": "6P9qDOzWf-Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "vbP5F-INgCIv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset of news articles\n",
        "articles = [\n",
        "    \"The stock market reached record highs today. Investors celebrated as tech stocks soared.\",\n",
        "    \"Scientists discover new species in the Amazon rainforest. Biodiversity is crucial for ecosystem health.\",\n",
        "    \"The basketball team won the championship after a close game. Fans celebrated the victory.\",\n",
        "    \"New climate change report warns of rising sea levels. Global temperatures continue to increase.\",\n",
        "    \"Tech company launches new smartphone with advanced AI features. The device will be available next month.\",\n",
        "    \"Soccer match ends in dramatic penalty shootout. The underdog team emerged victorious.\",\n",
        "    \"Study shows deforestation rates increasing in tropical regions. Conservation efforts are urgent.\",\n",
        "    \"Quarterly earnings report exceeds expectations. Company stocks rise by 15 percent.\",\n",
        "    \"New medical research shows promising results for cancer treatment. Clinical trials will begin next year.\",\n",
        "    \"Tennis player wins grand slam tournament. This is her third major victory this year.\"\n",
        "]"
      ],
      "metadata": {
        "id": "jp_E_78KgCLZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create document-term matrix\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "dtm = vectorizer.fit_transform(articles)\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "3klUmgbzgCOP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display top words for each topic\n",
        "def display_topics(model, feature_names, n_top_words):\n",
        "    topics = []\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_words_idx = topic.argsort()[:-n_top_words - 1:-1]\n",
        "        top_words = [feature_names[i] for i in top_words_idx]\n",
        "        topics.append({\n",
        "            'topic': topic_idx,\n",
        "            'top_words': top_words\n",
        "        })\n",
        "    return pd.DataFrame(topics)"
      ],
      "metadata": {
        "id": "r8JOH1cOgCQ3"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Latent Dirichlet Allocation (LDA)\n",
        "n_topics = 3\n",
        "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
        "lda.fit(dtm)\n",
        "\n",
        "print(\"LDA Topic Modeling:\")\n",
        "lda_topics = display_topics(lda, feature_names, 5)\n",
        "print(lda_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IeTCEkQgPSH",
        "outputId": "a226f5ed-a304-4fe9-dd71-3ed38b62fe37"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Topic Modeling:\n",
            "   topic                                    top_words\n",
            "0      0  [report, stocks, increase, rising, climate]\n",
            "1      1          [victory, team, new, company, tech]\n",
            "2      2         [new, shows, year, treatment, begin]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Document-topic distribution\n",
        "lda_document_topics = lda.transform(dtm)\n",
        "lda_doc_topic_df = pd.DataFrame(lda_document_topics)\n",
        "lda_doc_topic_df.columns = [f'Topic {i}' for i in range(n_topics)]\n",
        "lda_doc_topic_df['Dominant Topic'] = lda_doc_topic_df.idxmax(axis=1)\n",
        "lda_doc_topic_df['Article'] = [a[:50] + \"...\" for a in articles]  # First 50 chars of each article\n",
        "\n",
        "print(\"\\nLDA Document-Topic Distribution:\")\n",
        "print(lda_doc_topic_df[['Article', 'Dominant Topic']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Tj7yglgPVH",
        "outputId": "58ee7c82-916f-42e3-b6bf-8591316a6986"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LDA Document-Topic Distribution:\n",
            "                                             Article Dominant Topic\n",
            "0  The stock market reached record highs today. I...        Topic 0\n",
            "1  Scientists discover new species in the Amazon ...        Topic 2\n",
            "2  The basketball team won the championship after...        Topic 1\n",
            "3  New climate change report warns of rising sea ...        Topic 0\n",
            "4  Tech company launches new smartphone with adva...        Topic 1\n",
            "5  Soccer match ends in dramatic penalty shootout...        Topic 2\n",
            "6  Study shows deforestation rates increasing in ...        Topic 2\n",
            "7  Quarterly earnings report exceeds expectations...        Topic 0\n",
            "8  New medical research shows promising results f...        Topic 2\n",
            "9  Tennis player wins grand slam tournament. This...        Topic 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Non-Negative Matrix Factorization (NMF)\n",
        "nmf = NMF(n_components=n_topics, random_state=42)\n",
        "nmf.fit(dtm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "19B90bkvgPYQ",
        "outputId": "a02381cd-3745-452e-dfa1-0f57941242f6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NMF(n_components=3, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NMF(n_components=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>NMF</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.NMF.html\">?<span>Documentation for NMF</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>NMF(n_components=3, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNMF Topic Modeling:\")\n",
        "nmf_topics = display_topics(nmf, feature_names, 5)\n",
        "print(nmf_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFrvHtTugPa0",
        "outputId": "5c9721a0-63d6-4c01-8593-e028bcbe68cd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NMF Topic Modeling:\n",
            "   topic                                    top_words\n",
            "0      0           [new, report, sea, change, levels]\n",
            "1      1  [tech, stocks, celebrated, company, market]\n",
            "2      2         [shows, year, new, treatment, begin]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Document-topic distribution for NMF\n",
        "nmf_document_topics = nmf.transform(dtm)\n",
        "nmf_doc_topic_df = pd.DataFrame(nmf_document_topics)\n",
        "nmf_doc_topic_df.columns = [f'Topic {i}' for i in range(n_topics)]\n",
        "nmf_doc_topic_df['Dominant Topic'] = nmf_doc_topic_df.idxmax(axis=1)\n",
        "nmf_doc_topic_df['Article'] = [a[:50] + \"...\" for a in articles]\n",
        "\n",
        "print(\"\\nNMF Document-Topic Distribution:\")\n",
        "print(nmf_doc_topic_df[['Article', 'Dominant Topic']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JruNy7egPdL",
        "outputId": "c5e8127c-8040-4ce4-ec70-afb769ef3be1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NMF Document-Topic Distribution:\n",
            "                                             Article Dominant Topic\n",
            "0  The stock market reached record highs today. I...        Topic 1\n",
            "1  Scientists discover new species in the Amazon ...        Topic 0\n",
            "2  The basketball team won the championship after...        Topic 1\n",
            "3  New climate change report warns of rising sea ...        Topic 0\n",
            "4  Tech company launches new smartphone with adva...        Topic 1\n",
            "5  Soccer match ends in dramatic penalty shootout...        Topic 1\n",
            "6  Study shows deforestation rates increasing in ...        Topic 2\n",
            "7  Quarterly earnings report exceeds expectations...        Topic 1\n",
            "8  New medical research shows promising results f...        Topic 2\n",
            "9  Tennis player wins grand slam tournament. This...        Topic 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Interpret the topics (example)\n",
        "topic_interpretations = {\n",
        "    \"Topic 0\": \"Finance & Business\",\n",
        "    \"Topic 1\": \"Sports News\",\n",
        "    \"Topic 2\": \"Science & Environment\"\n",
        "}\n",
        "\n",
        "print(\"\\nTopic Interpretations (based on top words):\")\n",
        "for topic, interpretation in topic_interpretations.items():\n",
        "    print(f\"{topic}: {interpretation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUrxX73VgCTX",
        "outputId": "d0356e77-e52d-4fd1-b893-6f9af93dc734"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic Interpretations (based on top words):\n",
            "Topic 0: Finance & Business\n",
            "Topic 1: Sports News\n",
            "Topic 2: Science & Environment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Load 20 Newsgroups dataset\n",
        "newsgroups = fetch_20newsgroups(subset='train',\n",
        "                               remove=('headers', 'footers', 'quotes'),\n",
        "                               categories=['comp.graphics', 'rec.autos', 'sci.med', 'talk.politics.guns'],\n",
        "                               random_state=42)\n",
        "\n",
        "# Extract features with CountVectorizer\n",
        "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english', max_features=1000)\n",
        "tf = vectorizer.fit_transform(newsgroups.data)\n",
        "\n",
        "# Apply LDA\n",
        "lda = LatentDirichletAllocation(n_components=4, random_state=42)\n",
        "lda.fit(tf)\n",
        "\n",
        "# Function to display top words per topic\n",
        "def display_topics(model, feature_names, no_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
        "\n",
        "# Display results\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "display_topics(lda, feature_names, 10)\n"
      ],
      "metadata": {
        "id": "lAkh4rVvai5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.Machine Translation"
      ],
      "metadata": {
        "id": "aUq_HUamhOEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine translation converts text from one language to another"
      ],
      "metadata": {
        "id": "o37YwBUvhOHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import MarianMTModel, MarianTokenizer"
      ],
      "metadata": {
        "id": "0j8fBAsehi8V"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentences in English\n",
        "english_texts = [\n",
        "    \"Hello, how are you doing today?\",\n",
        "    \"Natural language processing is a fascinating field of study.\",\n",
        "    \"The weather is beautiful outside.\"\n",
        "]"
      ],
      "metadata": {
        "id": "5XUn5XLmhi_J"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text(texts, source_lang=\"en\", target_lang=\"fr\"):\n",
        "    \"\"\"\n",
        "    Translate text using Hugging Face's MarianMT models\n",
        "\n",
        "    Args:\n",
        "        texts: List of texts to translate\n",
        "        source_lang: Source language code (e.g., 'en' for English)\n",
        "        target_lang: Target language code (e.g., 'fr' for French)\n",
        "\n",
        "    Returns:\n",
        "        List of translated texts\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load model and tokenizer\n",
        "        model_name = f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n",
        "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "        model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "        # Translate\n",
        "        translated = []\n",
        "        for text in texts:\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "            translation = model.generate(**inputs)\n",
        "            translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
        "            translated.append(translated_text)\n",
        "\n",
        "        return translated\n",
        "\n",
        "    except Exception as e:\n",
        "        return [f\"Translation error: {e}\"] * len(texts)"
      ],
      "metadata": {
        "id": "lzKoG3WhhjBm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show code example without running it (which would require downloading models)\n",
        "print(\"Machine Translation with Hugging Face Transformers:\")\n",
        "print(\"Note: The following code requires installing transformers and downloading models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVMWtb2bhjEH",
        "outputId": "e4603182-7551-4742-d011-6a187024e956"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Translation with Hugging Face Transformers:\n",
            "Note: The following code requires installing transformers and downloading models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulated translations for demonstration\n",
        "translations = {\n",
        "    \"fr\": [\n",
        "        \"Bonjour, comment allez-vous aujourd'hui ?\",\n",
        "        \"Le traitement du langage naturel est un domaine d'étude fascinant.\",\n",
        "        \"Le temps est magnifique dehors.\"\n",
        "    ],\n",
        "    \"es\": [\n",
        "        \"Hola, ¿cómo estás hoy?\",\n",
        "        \"El procesamiento del lenguaje natural es un campo de estudio fascinante.\",\n",
        "        \"El clima está hermoso afuera.\"\n",
        "    ],\n",
        "    \"de\": [\n",
        "        \"Hallo, wie geht es Ihnen heute?\",\n",
        "        \"Natürliche Sprachverarbeitung ist ein faszinierendes Studiengebiet.\",\n",
        "        \"Das Wetter ist wunderschön draußen.\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "QtllMXO8hjGo"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display example translations\n",
        "df = pd.DataFrame({\"English\": english_texts})\n",
        "for lang, trans in translations.items():\n",
        "    df[lang.upper()] = trans\n",
        "\n",
        "print(\"\\nExample Translations:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sfjNtQ8hjJR",
        "outputId": "6ec394c2-b77f-4317-83a6-a26fac9a127a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example Translations:\n",
            "                                             English  \\\n",
            "0                    Hello, how are you doing today?   \n",
            "1  Natural language processing is a fascinating f...   \n",
            "2                  The weather is beautiful outside.   \n",
            "\n",
            "                                                  FR  \\\n",
            "0          Bonjour, comment allez-vous aujourd'hui ?   \n",
            "1  Le traitement du langage naturel est un domain...   \n",
            "2                    Le temps est magnifique dehors.   \n",
            "\n",
            "                                                  ES  \\\n",
            "0                             Hola, ¿cómo estás hoy?   \n",
            "1  El procesamiento del lenguaje natural es un ca...   \n",
            "2                      El clima está hermoso afuera.   \n",
            "\n",
            "                                                  DE  \n",
            "0                    Hallo, wie geht es Ihnen heute?  \n",
            "1  Natürliche Sprachverarbeitung ist ein faszinie...  \n",
            "2                Das Wetter ist wunderschön draußen.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple evaluation of translation quality\n",
        "print(\"\\nTo evaluate translation quality, you would typically use:\")\n",
        "print(\"1. BLEU (Bilingual Evaluation Understudy) score\")\n",
        "print(\"2. METEOR (Metric for Evaluation of Translation with Explicit ORdering)\")\n",
        "print(\"3. Human evaluation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TStsw6vh3rw",
        "outputId": "1799ba0f-21ed-464a-842b-88ce622f9130"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "To evaluate translation quality, you would typically use:\n",
            "1. BLEU (Bilingual Evaluation Understudy) score\n",
            "2. METEOR (Metric for Evaluation of Translation with Explicit ORdering)\n",
            "3. Human evaluation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of using custom datasets\n",
        "print(\"\\nUsing parallel corpus for training:\")\n",
        "print(\"For training custom MT models, you would use parallel datasets like:\")\n",
        "print(\"- WMT datasets (Conference on Machine Translation)\")\n",
        "print(\"- OpenSubtitles (movie subtitles)\")\n",
        "print(\"- TED talks\")\n",
        "print(\"- Europarl (European Parliament proceedings)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuYPuIlMh3uz",
        "outputId": "4d68fa35-e58c-46fb-9a21-0e38d311c509"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using parallel corpus for training:\n",
            "For training custom MT models, you would use parallel datasets like:\n",
            "- WMT datasets (Conference on Machine Translation)\n",
            "- OpenSubtitles (movie subtitles)\n",
            "- TED talks\n",
            "- Europarl (European Parliament proceedings)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.Question Answering Systems"
      ],
      "metadata": {
        "id": "HBDK6-6FiDAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question answering systems extract answers to questions from text"
      ],
      "metadata": {
        "id": "bZlVVTzliDDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "kA-KgLi5iRNf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample context passage\n",
        "context = \"\"\"\n",
        "Natural Language Processing (NLP) is a subfield of artificial intelligence\n",
        "that focuses on the interaction between computers and human language.\n",
        "It involves processing and analyzing large amounts of natural language data.\n",
        "NLP combines computational linguistics, machine learning, and deep learning models\n",
        "to enable computers to understand, interpret, and generate human language in a valuable way.\n",
        "The field began in the 1950s, but has seen significant advances since 2010 with the\n",
        "application of deep learning techniques. Modern NLP applications include machine translation,\n",
        "sentiment analysis, chatbots, and speech recognition. Companies like Google, Microsoft, and\n",
        "Amazon heavily invest in NLP research to improve their products and services.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gqLhtuN-iRQS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample questions\n",
        "questions = [\n",
        "    \"What is NLP?\",\n",
        "    \"When did NLP begin?\",\n",
        "    \"What companies invest in NLP research?\",\n",
        "    \"What techniques improved NLP since 2010?\",\n",
        "    \"What applications use NLP technology?\"\n",
        "]"
      ],
      "metadata": {
        "id": "FVN-2VT1iRTP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_questions(context, questions):\n",
        "    \"\"\"\n",
        "    Use a question answering model to find answers in the context\n",
        "\n",
        "    Args:\n",
        "        context: Text passage containing information\n",
        "        questions: List of questions to answer\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with questions, answers, and confidence scores\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize QA pipeline\n",
        "        qa_pipeline = pipeline(\"question-answering\")\n",
        "\n",
        "        results = []\n",
        "        for question in questions:\n",
        "            # Get answer\n",
        "            answer = qa_pipeline(question=question, context=context)\n",
        "            results.append({\n",
        "                'question': question,\n",
        "                'answer': answer['answer'],\n",
        "                'confidence': answer['score'],\n",
        "                'start': answer['start'],\n",
        "                'end': answer['end']\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Note: This code requires the transformers library and model download.\")\n",
        "\n",
        "        # Simulated results for demonstration\n",
        "        return pd.DataFrame({\n",
        "            'question': questions,\n",
        "            'answer': [\n",
        "                \"a subfield of artificial intelligence that focuses on the interaction between computers and human language\",\n",
        "                \"in the 1950s\",\n",
        "                \"Google, Microsoft, and Amazon\",\n",
        "                \"deep learning\",\n",
        "                \"machine translation, sentiment analysis, chatbots, and speech recognition\"\n",
        "            ],\n",
        "            'confidence': np.random.uniform(0.7, 0.95, len(questions))\n",
        "        })"
      ],
      "metadata": {
        "id": "R9lg8HHPiRVp"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display example without running actual model\n",
        "print(\"Question Answering System:\")\n",
        "print(\"Note: The following example would require downloading models\")\n",
        "print(\"\\nContext passage (excerpt):\")\n",
        "print(context[:150] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crw8XRf9iXAh",
        "outputId": "bba3d0d7-8c90-4386-e047-a785e6b961b8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question Answering System:\n",
            "Note: The following example would require downloading models\n",
            "\n",
            "Context passage (excerpt):\n",
            "\n",
            "Natural Language Processing (NLP) is a subfield of artificial intelligence \n",
            "that focuses on the interaction between computers and human language. \n",
            "It...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get simulated answers\n",
        "answers_df = answer_questions(context, questions)\n",
        "print(\"\\nQuestion-Answer Results:\")\n",
        "print(answers_df[['question', 'answer', 'confidence']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648,
          "referenced_widgets": [
            "fbb4bf1f99dc434798870ab7444fb71e",
            "70c0f927fb03486f87ed270ad3026b90",
            "fa38108993de47eb8f40ef15d05f01b0",
            "5daaa94d5d2845d4ba8746ef6bb27b6a",
            "0f6c9e1a00a7408d8667a3998ecfb9bb",
            "bb590d7ae3fc49e68bee051d5f214fd3",
            "4e7f1cd832e6427d8e7a8c3299ecb329",
            "90926cc37abe404baee5e7098eebfeb0",
            "d4a07251a42848ae908c9d7aef17d915",
            "4dcd8e149df14e958058d3912e9c78ec",
            "fd04b414623d462dbc8b7cedc72fc840",
            "9b20e3f983fb494491c7370cc04726b1",
            "d564f8f27d4c4ff8845cc8f142c26fc5",
            "8a57d613ff9d4a1bbc5b869dac04fc2a",
            "70c2c29434904467857bf0de4d8acbc5",
            "352ac68173ee4c7087197255f5cb0ebc",
            "1fe0d24e0fde4396b5f4c7d11a7d6e8e",
            "4ac02955eed74c6a8e6fe99794aac2e2",
            "ef80e7aa851a47338607d25753ee0661",
            "1aa162dd895e4778ae99d4846171e34c",
            "9e8b6073088d4cb4ab43f8c0b99d26ac",
            "94274e5d5cf040ce855129065cf5fd71",
            "ebb53fe89bf1422cb3a0da9d44fe0043",
            "da368d2353524998a21345ec4f12c776",
            "8a74da7c1699453ca3ed1c0e4d081e50",
            "31465c2b9b2c47aa9ceec31b28a89e89",
            "bbbcd668ecb242889e826de6d7f7e67a",
            "3365f094b08149679131a3491882aa47",
            "c46333cd8dfd48afa30bad458e870f4b",
            "44dc3a96967047d0952927da15d77ddf",
            "eb65ba26b80d404e9781a8df45d82e31",
            "45824032ee61496896c29902b9713c26",
            "aff29b18c5644764bbc3acae980b086e",
            "8f50aea5720247c88034d28906f3870d",
            "070aa753767f4f70860d134e97035a90",
            "51508f7d63b64f299d925f686a0573f2",
            "36e89f96bb434eaeb5e8a856282f4fd9",
            "a52fab7db15e40d68d896c036328854b",
            "c8e9360e9f664e37838597e0067d5236",
            "f49e7a58a9084ebc9da0ac5e2e07c25f",
            "678545fae3184aec95d9873847fd3a76",
            "92f8672f431e49328f3fc474b0ce9338",
            "b8ddc3a276db4e988a82c69f16758b9f",
            "c4d80c1ba14e4dbd98a78547bad6840b",
            "b8dc2fe703134127afdf8c9c8360cd3b",
            "bdb392a9ee394b5ea16e25e0c8528fb8",
            "3cf10dcb6f764d5596dc5481764914f4",
            "5a16cb6928f54c2798ecec5c1ed274f7",
            "606049900c164582b6162a28c134a4d6",
            "41a59c82f0b94b7b98fbefad053accdd",
            "fdeb887762a74ff5b9ad785a8c79eb39",
            "835ea94b83024ccfb7d74637c00456e5",
            "2cc6ff1d757c4775ab1a15cb353632ef",
            "777b0ca5940d4128bd91fc7f1835482d",
            "376c50b33ce044eaa7a11438256895fc"
          ]
        },
        "id": "i4nJFX0liXDp",
        "outputId": "c38fc4a3-d06e-4d49-d180-8af11da42ab4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbb4bf1f99dc434798870ab7444fb71e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b20e3f983fb494491c7370cc04726b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebb53fe89bf1422cb3a0da9d44fe0043"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f50aea5720247c88034d28906f3870d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8dc2fe703134127afdf8c9c8360cd3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question-Answer Results:\n",
            "                                   question  \\\n",
            "0                              What is NLP?   \n",
            "1                       When did NLP begin?   \n",
            "2    What companies invest in NLP research?   \n",
            "3  What techniques improved NLP since 2010?   \n",
            "4     What applications use NLP technology?   \n",
            "\n",
            "                                              answer  confidence  \n",
            "0                        Natural Language Processing    0.831354  \n",
            "1                                              1950s    0.785927  \n",
            "2                    Google, Microsoft, and \\nAmazon    0.951905  \n",
            "3                           deep learning techniques    0.538020  \n",
            "4  machine translation, \\nsentiment analysis, cha...    0.911289  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a simple retrieval-based QA system\n",
        "print(\"\\nBuilding a Simple Retrieval-Based QA System:\")\n",
        "print(\"1. Create a knowledge base with documents\")\n",
        "print(\"2. Index documents for efficient retrieval\")\n",
        "print(\"3. For each question:\")\n",
        "print(\"   a. Retrieve relevant documents\")\n",
        "print(\"   b. Extract answer spans from documents\")\n",
        "print(\"   c. Rank candidate answers\")\n",
        "print(\"   d. Return best answer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VthldlztiXGg",
        "outputId": "72d94709-16d9-46fe-8950-ed71134683f1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building a Simple Retrieval-Based QA System:\n",
            "1. Create a knowledge base with documents\n",
            "2. Index documents for efficient retrieval\n",
            "3. For each question:\n",
            "   a. Retrieve relevant documents\n",
            "   b. Extract answer spans from documents\n",
            "   c. Rank candidate answers\n",
            "   d. Return best answer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example with multiple documents\n",
        "documents = [\n",
        "    \"NLP techniques include tokenization, part-of-speech tagging, named entity recognition, and parsing.\",\n",
        "    \"The Transformer architecture, introduced in 2017, revolutionized NLP with models like BERT and GPT.\",\n",
        "    \"Word embeddings represent words as vectors in high-dimensional space, capturing semantic relationships.\",\n",
        "    \"Transfer learning in NLP involves pre-training models on large text corpora and fine-tuning for specific tasks.\"\n",
        "]\n",
        "\n",
        "print(\"\\nIn a real application, you would combine document retrieval with extractive QA:\")\n",
        "print(\"1. First find relevant documents containing the answer\")\n",
        "print(\"2. Then extract the precise answer span from those documents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI7QyNXviCj4",
        "outputId": "54d7b136-32e8-479c-8ad3-182c8830c059"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "In a real application, you would combine document retrieval with extractive QA:\n",
            "1. First find relevant documents containing the answer\n",
            "2. Then extract the precise answer span from those documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "# Create QA pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Example\n",
        "context = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence\n",
        "that focuses on the interaction between computers and humans through natural language.\n",
        "The ultimate goal of NLP is to enable computers to understand, interpret, and generate\n",
        "human language in a valuable way.\n",
        "\"\"\"\n",
        "\n",
        "question = \"What is the goal of NLP?\"\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "\n",
        "print(f\"Answer: {result['answer']}\")\n",
        "print(f\"Score: {result['score']:.4f}\")\n",
        "print(f\"Start: {result['start']}, End: {result['end']}\")"
      ],
      "metadata": {
        "id": "KzhvbHUWaZAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.Language Generation - check"
      ],
      "metadata": {
        "id": "ZFK6ORSljBPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language generation creates coherent and contextually relevant text.\n"
      ],
      "metadata": {
        "id": "M80rWkKBjBR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from transformers import pipeline, set_seed"
      ],
      "metadata": {
        "id": "LUFWckdGjAq5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "set_seed(42)\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ],
      "metadata": {
        "id": "BbVeVF1IjAtm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Simple Markov Chain Text Generator\n",
        "def train_markov_model(text, n=2):\n",
        "    \"\"\"\n",
        "    Train a simple Markov chain model for text generation\n",
        "\n",
        "    Args:\n",
        "        text: Training text\n",
        "        n: n-gram size (default: 2)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping n-grams to possible next words\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    model = {}\n",
        "\n",
        "    for i in range(len(words) - n):\n",
        "        gram = tuple(words[i:i+n])\n",
        "        next_word = words[i+n]\n",
        "\n",
        "        if gram in model:\n",
        "            model[gram].append(next_word)\n",
        "        else:\n",
        "            model[gram] = [next_word]\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "8mMKjRFaiXKG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_markov(model, start_words, n=2, max_length=50):\n",
        "    \"\"\"\n",
        "    Generate text using a Markov chain model\n",
        "\n",
        "    Args:\n",
        "        model: Trained Markov model\n",
        "        start_words: List of words to start generation\n",
        "        n: n-gram size (default: 2)\n",
        "        max_length: Maximum length of generated text (default: 50)\n",
        "\n",
        "    Returns:\n",
        "        Generated text\n",
        "    \"\"\"\n",
        "    current = tuple(start_words[-n:])\n",
        "    result = list(current)\n",
        "\n",
        "    for _ in range(max_length - n):\n",
        "        if current in model:\n",
        "            next_word = random.choice(model[current])\n",
        "            result.append(next_word)\n",
        "            current = tuple(result[-n:])\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return ' '.join(result)"
      ],
      "metadata": {
        "id": "JB7wBLwIiXME"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text for Markov chain\n",
        "sample_text = \"\"\"\n",
        "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n",
        "concerned with the interactions between computers and human language, in particular how to program computers\n",
        "to process and analyze large amounts of natural language data. The goal is a computer capable of understanding\n",
        "the contents of documents, including the contextual nuances of the language within them. The technology can then\n",
        "accurately extract information and insights contained in the documents as well as categorize and organize the\n",
        "documents themselves.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ny3LfeVAiXPu"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train Markov model\n",
        "print(\"Markov Chain Text Generation:\")\n",
        "markov_model = train_markov_model(sample_text, n=2)\n",
        "generated_text = generate_text_markov(markov_model, [\"Natural\", \"language\"], n=2, max_length=30)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibkStdMgiCmn",
        "outputId": "6bb31004-1bc9-4637-d3dd-c7fb9e60d7a2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Markov Chain Text Generation:\n",
            "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Hugging Face Transformer-based text generation\n",
        "def generate_with_transformers(prompt, max_length=50):\n",
        "    \"\"\"\n",
        "    Generate text using Hugging Face transformer models\n",
        "\n",
        "    Args:\n",
        "        prompt: Initial text prompt\n",
        "        max_length: Maximum length of generated text\n",
        "\n",
        "    Returns:\n",
        "        Generated text\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize text generation pipeline with GPT-2\n",
        "        generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "        # Generate text\n",
        "        result = generator(prompt, max_length=max_length, num_return_sequences=1)\n",
        "        return result[0]['generated_text']\n",
        "\n",
        "    except Exception as e:\n",
        "        # Simulated output for demonstration\n",
        "        print(f\"Note: This would require the transformers library and model download.\")\n",
        "\n",
        "        simulated_outputs = {\n",
        "            \"Write a short paragraph about artificial intelligence.\":\n",
        "                \"Write a short paragraph about artificial intelligence. Artificial intelligence is transforming how we interact with technology and reshaping various industries. AI systems can now perform tasks that traditionally required human intelligence, such as visual perception, speech recognition, and decision-making. As these technologies continue to advance, they promise to solve complex problems but also raise important ethical considerations about privacy, bias, and the future of work.\",\n",
        "\n",
        "            \"Create a product description for a new smartphone.\":\n",
        "                \"Create a product description for a new smartphone. Introducing the NextGen X1, the smartphone that redefines innovation. Featuring a stunning 6.7-inch AMOLED display with ProMotion technology, the X1 delivers breathtaking visuals with vibrant colors and deep contrasts. Powered by our latest A16 processor, it handles everything from everyday tasks to intensive gaming with remarkable efficiency. Capture life's moments in extraordinary detail with the revolutionary 108MP camera system equipped with enhanced night mode and 8K video recording capabilities.\",\n",
        "\n",
        "            \"Write a recipe for chocolate chip cookies.\":\n",
        "                \"Write a recipe for chocolate chip cookies. Classic Chocolate Chip Cookies: Mix 1 cup softened butter with 3/4 cup white sugar and 3/4 cup brown sugar until creamy. Beat in 2 eggs and 2 teaspoons vanilla extract. In another bowl, combine 2 1/4 cups flour, 1 teaspoon baking soda, and 1/2 teaspoon salt. Gradually add dry ingredients to wet mixture. Fold in 2 cups chocolate chips. Drop rounded tablespoons onto ungreased baking sheets. Bake at 375°F for 9-11 minutes until golden brown. Cool on wire racks. Makes about 36 cookies.\"\n",
        "        }\n",
        "\n",
        "        # Return closest match or default text\n",
        "        for key, value in simulated_outputs.items():\n",
        "            if prompt in key:\n",
        "                return value\n",
        "\n",
        "        return prompt + \" AI technology continues to advance rapidly, transforming industries and creating new opportunities. Recent developments in natural language processing have enabled systems to understand and generate human language with impressive accuracy and fluency.\"\n"
      ],
      "metadata": {
        "id": "w6pNukkLh3xi"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example prompts\n",
        "prompts = [\n",
        "    \"Write a short paragraph about artificial intelligence.\",\n",
        "    \"Create a product description for a new smartphone.\",\n",
        "    \"Write a recipe for chocolate chip cookies.\"\n",
        "]\n",
        "\n",
        "# Generate text with transformers (simulated)\n",
        "print(\"\\nTransformer-based Text Generation:\")\n",
        "for prompt in prompts:\n",
        "    print(f\"\\nPrompt: {prompt}\")\n",
        "    generated = generate_with_transformers(prompt)\n",
        "    print(generated)\n",
        "\n",
        "# 3. Practical applications of text generation\n",
        "print(\"\\nPractical Applications of Language Generation:\")\n",
        "print(\"1. Content creation (articles, marketing copy)\")\n",
        "print(\"2. Chatbots and virtual assistants\")\n",
        "print(\"3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "jOHghEKKh32x",
        "outputId": "0a364959-22e2-496e-94b7-18151ffa6957"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 19) (<ipython-input-78-aa87603e75c4>, line 19)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-78-aa87603e75c4>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    print(\"3\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.Word Sense Disambiguation"
      ],
      "metadata": {
        "id": "_jfYCVebjmEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word sense disambiguation determines the meaning of words in different contexts"
      ],
      "metadata": {
        "id": "ijE451eijmIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.wsd import lesk\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fCpQJMJmjpao"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYR8CoSEjpdo",
        "outputId": "498c7424-f980-4727-991a-74d53c2d5414"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentences with ambiguous words\n",
        "sentences = [\n",
        "    \"The bank is closed today.\",\n",
        "    \"He deposited money in the bank.\",\n",
        "    \"The river bank was eroding after the flood.\",\n",
        "    \"They were fishing by the bank of the lake.\",\n",
        "    \"I need to run to catch the bus.\",\n",
        "    \"She runs a successful business.\",\n",
        "    \"The software will run on any computer.\",\n",
        "    \"They went for a morning run in the park.\"\n",
        "]"
      ],
      "metadata": {
        "id": "us6iLnlJjpgf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. WordNet-based Word Sense Disambiguation\n",
        "def get_wordnet_pos(tag):\n",
        "    \"\"\"\n",
        "    Map POS tag to WordNet POS tag\n",
        "    \"\"\"\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "h69CNQyqjpjF"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def disambiguate_word(word, sentence, pos=None):\n",
        "    \"\"\"\n",
        "    Disambiguate a word in a sentence using Lesk algorithm\n",
        "    \"\"\"\n",
        "    # Get synset using simplified Lesk algorithm\n",
        "    synset = lesk(sentence.split(), word, pos)\n",
        "\n",
        "    if synset:\n",
        "        return {\n",
        "            'synset': synset.name(),\n",
        "            'definition': synset.definition(),\n",
        "            'examples': synset.examples()\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'synset': 'Not found',\n",
        "            'definition': 'Not available',\n",
        "            'examples': []\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "8lU57rWwjpo2"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze ambiguous words in the sentences\n",
        "results = []"
      ],
      "metadata": {
        "id": "EysQ7XtpjprU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    # Tokenize and get POS tags\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Focus on ambiguous words\n",
        "    if \"bank\" in tokens:\n",
        "        word = \"bank\"\n",
        "    elif \"run\" in tokens or \"runs\" in tokens:\n",
        "        word = \"run\" if \"run\" in tokens else \"runs\"\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    # Get word index and POS\n",
        "    word_indices = [i for i, token in enumerate(tokens) if token == word or token == \"runs\"]\n",
        "    if not word_indices:\n",
        "        continue\n",
        "\n",
        "    word_index = word_indices[0]\n",
        "    word_pos = pos_tags[word_index][1]\n",
        "    wn_pos = get_wordnet_pos(word_pos)\n",
        "\n",
        "    # Disambiguate\n",
        "    disambiguation = disambiguate_word(tokens[word_index], sentence, wn_pos)\n",
        "\n",
        "    # Add to results\n",
        "    results.append({\n",
        "        'sentence': sentence,\n",
        "        'ambiguous_word': tokens[word_index],\n",
        "        'pos': word_pos,\n",
        "        'synset': disambiguation['synset'],\n",
        "        'definition': disambiguation['definition'],\n",
        "        'examples': ', '.join(disambiguation['examples']) if disambiguation['examples'] else 'N/A'\n",
        "    })"
      ],
      "metadata": {
        "id": "XBeDjVz8jptg"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"Word Sense Disambiguation Results:\")\n",
        "print(df_results[['sentence', 'ambiguous_word', 'synset', 'definition']])\n",
        "\n",
        "# 2. Context-based WSD: Identify sense based on context\n",
        "def simple_context_wsd(word, context, senses):\n",
        "    \"\"\"\n",
        "    Simple context-based word sense disambiguation\n",
        "    \"\"\"\n",
        "    max_overlap = 0\n",
        "    best_sense = None\n",
        "\n",
        "    # Lower case everything for comparison\n",
        "    context_words = set(context.lower().split())\n",
        "\n",
        "    for sense_id, sense_def in senses.items():\n",
        "        # Count overlapping words between context and definition\n",
        "        definition_words = set(sense_def.lower().split())\n",
        "        overlap = len(context_words.intersection(definition_words))\n",
        "\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense_id\n",
        "\n",
        "    return best_sense, max_overlap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9wxxFkCjpwL",
        "outputId": "a3b5b1de-852b-4dea-9537-6f41b27bf7f4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Sense Disambiguation Results:\n",
            "                                      sentence ambiguous_word  \\\n",
            "0                    The bank is closed today.           bank   \n",
            "1              He deposited money in the bank.           bank   \n",
            "2  The river bank was eroding after the flood.           bank   \n",
            "3   They were fishing by the bank of the lake.           bank   \n",
            "4              I need to run to catch the bus.            run   \n",
            "5              She runs a successful business.           runs   \n",
            "6       The software will run on any computer.            run   \n",
            "7     They went for a morning run in the park.            run   \n",
            "\n",
            "              synset                                         definition  \n",
            "0          bank.n.07  a slope in the turn of a road or track; the ou...  \n",
            "1  savings_bank.n.02  a container (usually with a slot in the top) f...  \n",
            "2  savings_bank.n.02  a container (usually with a slot in the top) f...  \n",
            "3          bank.n.09  a building in which the business of banking tr...  \n",
            "4          scat.v.01             flee; take to one's heels; cut and run  \n",
            "5          tend.v.01  have a tendency or disposition to do or be som...  \n",
            "6          scat.v.01             flee; take to one's heels; cut and run  \n",
            "7           run.n.08  the continuous period of time during which som...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example for the word \"bank\"\n",
        "bank_senses = {\n",
        "    \"financial\": \"A financial institution that accepts deposits and channels money into lending activities\",\n",
        "    \"river\": \"The land alongside or sloping down to a river or lake\",\n",
        "    \"rely\": \"To rely on or count on someone or something\",\n",
        "    \"building\": \"A building in which the business of banking is conducted\"\n",
        "}\n",
        "\n",
        "contexts = [\n",
        "    \"I needed to withdraw money so I went to the bank\",\n",
        "    \"The river was flowing rapidly after the heavy rain, overflowing its bank\",\n",
        "    \"You can bank on me to help you with your project\",\n",
        "    \"The bank closed at 5pm so I couldn't cash my check\"\n",
        "]\n",
        "\n",
        "print(\"\\nContext-based Word Sense Disambiguation:\")\n",
        "for context in contexts:\n",
        "    sense, score = simple_context_wsd(\"bank\", context, bank_senses)\n",
        "    print(f\"Context: '{context}'\")\n",
        "    print(f\"Detected sense: {sense} (overlap score: {score})\")\n",
        "    print(f\"Definition: {bank_senses[sense]}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6YTW0Cpjpyw",
        "outputId": "73c32582-17c4-4474-efa1-03e2771ac2c5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context-based Word Sense Disambiguation:\n",
            "Context: 'I needed to withdraw money so I went to the bank'\n",
            "Detected sense: river (overlap score: 2)\n",
            "Definition: The land alongside or sloping down to a river or lake\n",
            "\n",
            "Context: 'The river was flowing rapidly after the heavy rain, overflowing its bank'\n",
            "Detected sense: river (overlap score: 2)\n",
            "Definition: The land alongside or sloping down to a river or lake\n",
            "\n",
            "Context: 'You can bank on me to help you with your project'\n",
            "Detected sense: rely (overlap score: 2)\n",
            "Definition: To rely on or count on someone or something\n",
            "\n",
            "Context: 'The bank closed at 5pm so I couldn't cash my check'\n",
            "Detected sense: river (overlap score: 1)\n",
            "Definition: The land alongside or sloping down to a river or lake\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Practical application: Building a WSD system\n",
        "print(\"Steps to Build a Word Sense Disambiguation System:\")\n",
        "print(\"1. Collect sense inventory (e.g., from WordNet)\")\n",
        "print(\"2. Extract context features:\")\n",
        "print(\"   - Surrounding words\")\n",
        "print(\"   - Part-of-speech tags\")\n",
        "print(\"   - Named entities\")\n",
        "print(\"   - Semantic roles\")\n",
        "print(\"3. Train disambiguation model:\")\n",
        "print(\"   - Knowledge-based (like Lesk)\")\n",
        "print(\"   - Supervised (classifier with labeled examples)\")\n",
        "print(\"   - Neural (BERT, RoBERTa, etc.)\")\n",
        "print(\"4. Evaluate using benchmarks like SemEval\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNC8tEwWjp1b",
        "outputId": "dde3ac02-eaf8-4833-c146-2430e44c770e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps to Build a Word Sense Disambiguation System:\n",
            "1. Collect sense inventory (e.g., from WordNet)\n",
            "2. Extract context features:\n",
            "   - Surrounding words\n",
            "   - Part-of-speech tags\n",
            "   - Named entities\n",
            "   - Semantic roles\n",
            "3. Train disambiguation model:\n",
            "   - Knowledge-based (like Lesk)\n",
            "   - Supervised (classifier with labeled examples)\n",
            "   - Neural (BERT, RoBERTa, etc.)\n",
            "4. Evaluate using benchmarks like SemEval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. WSD with BERT (code example without running)\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "\n",
        "# Function to get contextual embeddings\n",
        "def get_bert_embeddings(sentence, target_word):\n",
        "    # Load model and tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Tokenize and get token IDs for the target word\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    target_token_indices = [i for i, token in enumerate(tokens) if target_word in token]\n",
        "\n",
        "    # Get BERT embeddings\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state[0]\n",
        "\n",
        "    # Get embeddings for target word\n",
        "    target_embeddings = [embeddings[i] for i in target_token_indices]\n",
        "\n",
        "    return target_embeddings\n",
        "\n",
        "# These contextual embeddings would then be used to classify the sense of 'bank'"
      ],
      "metadata": {
        "id": "SPtSpCuKkDCI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "sentence = \"The bank is closed today due to the holiday\"\n",
        "target_word = \"bank\"\n",
        "embeddings = get_bert_embeddings(sentence, target_word)\n",
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhuwCIhNkT24",
        "outputId": "aaeb7cff-360d-466f-d587-2f94dd7dcb45"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 7.6836e-02,  1.2276e-01, -1.9325e-01,  2.0432e-02,  5.5254e-01,\n",
              "          5.5034e-01, -1.7296e-01,  8.6749e-01, -2.6351e-02, -1.0727e-03,\n",
              "         -8.5820e-02, -8.0303e-01,  2.9006e-02,  1.3479e+00, -3.0775e-01,\n",
              "         -4.8827e-02,  5.2482e-01,  3.6622e-02,  8.1655e-02, -2.6390e-01,\n",
              "         -7.2354e-01,  1.2996e-01, -5.3557e-03,  6.9407e-01,  2.8274e-01,\n",
              "         -4.4009e-02, -1.2080e-01,  6.3439e-01, -1.8244e-01, -2.4939e-01,\n",
              "         -1.0432e-01, -3.8516e-01, -4.2460e-01,  4.9058e-01, -2.3124e-01,\n",
              "         -4.5125e-01, -5.6497e-01, -4.1233e-01, -4.9214e-01,  1.8448e-01,\n",
              "          2.9292e-01, -7.0596e-02,  6.4871e-01,  1.3303e-01,  1.9299e-01,\n",
              "         -4.9855e-01,  1.5061e-01, -2.4619e-01, -6.1600e-01, -7.2457e-01,\n",
              "         -3.8282e-01,  1.2247e-01,  1.7121e-01, -2.4562e-01, -2.9531e-03,\n",
              "          8.3056e-01, -1.2080e-01,  5.1864e-01,  5.1258e-01, -6.1010e-02,\n",
              "          2.2625e-01, -2.2943e-01,  4.7527e-01, -3.2192e-01,  1.6663e-01,\n",
              "         -3.9226e-02, -1.6496e-02,  3.9481e-01,  7.9882e-02,  3.8304e-01,\n",
              "         -1.2042e-01, -6.4622e-01,  2.2170e-01, -4.8547e-01, -3.0381e-01,\n",
              "         -5.4878e-01,  2.5312e-01,  4.3356e-01, -3.1781e-01, -7.4913e-02,\n",
              "          6.0271e-01,  2.6394e-01,  6.9462e-03,  1.4513e-01, -1.9813e-01,\n",
              "         -1.0030e-01, -4.9065e-01, -1.8115e-01,  6.3871e-02,  5.5806e-01,\n",
              "         -5.2042e-01,  4.3336e-01, -2.6302e-01, -3.4949e-01, -2.8426e-01,\n",
              "         -6.0879e-01, -3.6010e-01, -1.8419e-01,  1.6310e+00,  4.3973e-01,\n",
              "         -1.6879e-01, -3.1147e-01, -3.2297e-01,  4.8512e-01, -1.0072e-01,\n",
              "         -2.6325e-01, -2.7278e-02,  2.6589e-01, -1.3938e-01, -2.4606e+00,\n",
              "         -5.4903e-01,  2.4403e-01,  3.7145e-01, -1.4174e-01,  4.6646e-02,\n",
              "          6.3785e-01,  4.2882e-01, -2.7925e-01, -3.8519e-01,  6.8306e-01,\n",
              "         -5.0570e-01,  1.1417e+00,  3.3479e-01,  4.6552e-01,  1.6159e-01,\n",
              "          3.1488e-01, -1.7812e-01,  6.8353e-01,  1.8044e-01, -4.8895e-01,\n",
              "          2.7381e-01,  9.8287e-01, -1.0198e-01, -4.1131e-02,  1.8625e-01,\n",
              "          5.2509e-01,  4.2485e-02, -5.2145e-01, -4.5278e-02,  1.9661e-01,\n",
              "          1.8567e-01,  4.2451e-02, -1.5195e+00, -6.2370e-02,  7.9495e-02,\n",
              "          6.3020e-02, -2.0500e-01, -5.7298e-01,  3.1913e-01,  2.4811e-01,\n",
              "          4.1257e-01, -1.3032e-01, -1.9891e-01,  8.9460e-02, -4.3071e-01,\n",
              "          1.0430e-02,  2.2033e-01, -1.9216e-01,  2.2436e-01,  7.3768e-01,\n",
              "          6.0128e-01, -3.8162e-01,  7.6481e-01,  4.1138e-01,  4.2428e-06,\n",
              "         -1.4025e-01, -2.3843e-01,  3.2898e-01,  5.3899e-01, -4.1394e-02,\n",
              "         -5.8089e-01, -6.6077e-01,  7.3767e-01,  1.2763e-01, -2.8428e-01,\n",
              "         -5.1828e-01, -1.5819e-01,  7.1290e-02, -2.5286e-01, -1.8563e-01,\n",
              "         -5.2546e-01,  6.8859e-01, -7.6654e-02,  6.0555e-02,  1.3677e-01,\n",
              "          7.7534e-02,  8.1551e-01, -3.1817e-01,  2.7149e-01, -2.8384e-01,\n",
              "          5.6198e-01, -3.9834e-01, -1.5005e-01, -6.3525e-02,  5.7191e-01,\n",
              "         -4.1182e-01, -6.8189e-01, -1.5314e-01, -2.4327e-02,  1.1576e-01,\n",
              "         -1.8535e-01, -2.1908e-01,  2.6137e-01, -5.4304e-02, -9.6900e-02,\n",
              "          1.6613e+00,  3.3236e-01, -3.5350e-01,  4.2946e-01, -2.4648e-02,\n",
              "          8.3273e-02, -8.0490e-02, -5.4689e-01, -3.9796e-01,  5.7004e-01,\n",
              "         -5.0939e-01, -1.1962e-01, -5.4783e-01,  1.0994e-01, -8.1339e-02,\n",
              "          5.0144e-01,  3.1717e-01,  5.5377e-01,  2.3783e-01, -2.2395e-02,\n",
              "          7.9898e-01,  1.4385e-01,  3.3426e-01, -3.2346e-01,  2.6643e-01,\n",
              "          9.7850e-02, -3.3005e-01,  2.1020e-01,  3.2643e-01, -4.3391e-01,\n",
              "         -2.8721e-01, -6.3333e-01,  3.4913e-01, -2.1158e-01,  6.4907e-01,\n",
              "          1.2464e-01, -6.5058e-01,  3.7753e-01,  6.5684e-01, -1.3546e-01,\n",
              "          6.8451e-01,  2.8898e-02,  4.2709e-02, -5.5089e-01, -3.5428e-01,\n",
              "         -3.6231e-01, -1.1045e+00, -1.1562e-01, -7.6151e-01,  2.3953e-01,\n",
              "         -4.6338e-01,  1.2875e-01,  5.0061e-01, -4.2579e-01,  5.7935e-01,\n",
              "         -9.3616e-01, -2.7738e-01,  2.6557e-02, -2.5084e-01, -5.1314e-01,\n",
              "          1.3932e-02, -2.4256e-01,  3.2588e-01, -2.0994e-01, -1.6534e-02,\n",
              "         -3.2280e-01, -2.7444e-01,  2.9072e-01, -1.9922e+00,  5.4234e-02,\n",
              "         -1.8357e-01,  3.1593e-01, -5.5477e-02,  5.7296e-02,  4.1735e-02,\n",
              "         -2.2240e-02,  6.4249e-01, -3.0331e-01,  2.3215e-01, -2.7176e-01,\n",
              "         -5.3523e-01,  5.2096e-01, -6.2106e-02, -3.4790e-01,  7.3133e-02,\n",
              "         -2.8128e-01,  4.6236e-01, -5.5143e-01, -1.0291e-01, -3.6691e-02,\n",
              "         -3.8671e-01,  1.5823e-01, -1.8135e-01,  4.4942e-01, -2.6761e-01,\n",
              "          4.2540e-03, -1.1764e-01, -1.3588e-01, -2.1230e-01,  3.8640e-01,\n",
              "         -6.7778e-01, -7.8582e-01, -5.3178e-01, -4.7282e+00,  1.1037e-02,\n",
              "         -7.0563e-01, -2.8533e-01,  2.6425e-01, -1.3925e-01, -8.3728e-02,\n",
              "         -5.1464e-02, -3.3695e-01, -2.3027e-01,  1.3333e-01, -4.6450e-01,\n",
              "         -1.8974e-01, -9.2372e-02,  6.1921e-01,  3.6649e-01,  7.8069e-02,\n",
              "         -3.3439e-02,  6.3859e-01,  2.5183e-01,  1.3446e-01, -2.1202e-01,\n",
              "         -3.3985e-01, -3.7509e-01, -2.1733e-01,  5.0950e-01, -9.7424e-02,\n",
              "          1.3220e-01, -3.6645e-01,  1.4287e-01, -4.9595e-01,  3.4734e-01,\n",
              "          1.1452e-01,  2.9848e-01,  1.7428e-01, -1.2114e-01, -3.4822e-01,\n",
              "         -1.6134e-01,  1.8314e-01, -1.6901e-01,  2.0208e-01,  3.6828e-01,\n",
              "          4.6151e-01,  5.0530e-02,  9.4621e-01,  3.1664e-01, -1.5003e-01,\n",
              "         -5.6670e-01, -1.7168e-01,  2.0835e-01,  3.5351e-03, -5.3649e-01,\n",
              "          6.5304e-01,  4.2290e-01,  3.0536e-01, -9.1490e-02, -1.8591e-01,\n",
              "         -4.9631e-01,  4.7728e-01, -1.4303e-01, -3.7947e-01, -1.8586e-01,\n",
              "         -8.0192e-01, -6.7518e-02, -4.3812e-01, -2.5766e-01, -4.1449e-01,\n",
              "         -1.4785e-01,  5.0380e-01,  2.7596e-01, -2.5677e-01, -3.5491e-01,\n",
              "         -2.1758e-01, -1.2158e+00, -5.4076e-01, -4.6236e-01,  5.0172e-01,\n",
              "          1.6891e-01,  3.0438e-01, -3.5589e-01,  4.8343e-03,  1.2865e-01,\n",
              "         -1.8303e-01,  3.2596e-01,  5.3254e-01, -8.9422e-01,  4.7370e-02,\n",
              "          6.5741e-02, -3.9699e-01,  1.3769e-01,  2.9546e-01,  2.0497e-02,\n",
              "         -2.7852e-01,  4.1229e-01, -5.9728e-01,  1.0507e+00,  1.9805e-01,\n",
              "         -1.2860e+00, -4.0464e-01,  4.3510e-01,  1.5079e-01, -2.4906e-01,\n",
              "          5.9294e-01, -5.5518e-01,  2.3684e-01, -3.9628e-01, -2.6288e-01,\n",
              "          3.4122e-01, -4.9734e-01,  6.4793e-02,  7.8652e-02, -5.3826e-01,\n",
              "          9.4905e-02, -5.5009e-01,  1.2644e-01, -1.5062e-01,  1.9833e-02,\n",
              "          1.7814e-01, -3.8679e-01,  2.8931e-01,  7.6751e-01,  3.0996e-01,\n",
              "         -4.2386e-01, -5.2754e-01, -6.9534e-01,  1.0720e-01,  2.1562e-01,\n",
              "         -3.9704e-01, -2.8921e-02,  6.4376e-02, -3.5280e-01, -3.3346e-01,\n",
              "          1.8934e-01, -3.4194e-01,  1.5181e-01,  1.1808e-01, -1.9099e-02,\n",
              "         -1.9176e-01,  1.0919e+00, -3.5652e-01,  4.0650e-01,  2.6366e-01,\n",
              "         -1.5407e-02,  4.1543e-01, -6.0936e-02,  1.6676e-01,  4.0519e-01,\n",
              "         -7.1601e-01,  1.5923e-02, -4.4870e-01, -3.4919e-01, -3.5786e-01,\n",
              "          2.3767e-01,  2.0404e-01,  2.1648e-01, -1.1998e-01,  4.8128e-01,\n",
              "         -4.7522e-01, -3.2973e-01,  5.7021e-01, -8.1721e-01,  7.7695e-02,\n",
              "         -1.1215e-01,  4.2614e-01, -3.9747e-01,  1.6870e-01,  2.8421e-01,\n",
              "          5.8587e-01, -3.9333e-01,  6.1898e-01,  3.3731e-01, -3.0165e-02,\n",
              "         -1.9595e-01, -3.5472e-01, -4.0354e-02,  2.0575e-02, -1.1733e-01,\n",
              "          3.3535e-01,  4.2053e-01,  4.2437e-02, -6.1463e-02,  3.4458e-01,\n",
              "          4.1667e-01,  3.6746e-01,  8.0298e-02,  1.1947e-01, -9.4804e-01,\n",
              "          2.6424e-01,  1.2795e-01,  8.4535e-01,  1.5131e-01,  3.6902e-01,\n",
              "         -3.4244e-01, -3.1869e-01, -4.6597e-01, -2.5335e-02, -4.0811e-01,\n",
              "          1.2195e-01,  2.3127e-01,  7.7416e-01,  5.7413e-01,  2.7734e-01,\n",
              "          1.7243e-01, -2.8405e-01,  8.7935e-02, -3.9574e-01,  9.2645e-01,\n",
              "          3.2611e-01, -1.4867e-01,  5.3948e-01, -6.9217e-01,  4.0751e-02,\n",
              "         -2.2513e-01, -1.5584e-01, -6.4227e-01, -6.4610e-01,  2.2535e-01,\n",
              "          1.0362e-01,  8.2800e-02,  4.4630e-01,  2.6776e-01,  5.4801e-01,\n",
              "         -4.4085e-01,  7.8599e-02,  1.4302e-03,  5.3021e-01,  3.2572e-01,\n",
              "         -7.1199e-01,  4.1782e-02,  1.4722e-01,  1.8673e-02, -6.1502e-01,\n",
              "          1.0573e+00,  3.6444e-01,  4.8209e-01,  2.1359e-01, -1.4362e-01,\n",
              "         -1.3218e-01,  1.7534e-01,  2.0850e-01, -9.0488e-05, -1.9941e-01,\n",
              "         -1.5897e-02, -2.3481e-01, -3.2614e-03, -4.7085e-01,  3.3496e-02,\n",
              "          2.5070e-01, -1.9017e-01,  4.3691e-01,  2.1063e-01,  6.1554e-01,\n",
              "          8.2080e-01, -4.2996e-01, -4.0889e-01,  2.0672e-01,  4.9862e-01,\n",
              "          4.6757e-01,  3.3631e-01,  1.1526e-01,  3.5739e-01, -2.8940e-01,\n",
              "         -2.8482e-01,  2.6122e-01, -7.0528e-01,  3.0300e-01,  1.0529e-01,\n",
              "         -6.6730e-01, -4.3120e-01,  3.6443e-01,  4.4101e-01, -4.9239e-01,\n",
              "          5.0340e-02,  3.4993e-01,  1.1224e-01,  2.1266e-02,  1.7520e-01,\n",
              "          1.6958e-01, -6.2409e-01,  2.8211e-01,  1.3822e+00,  8.9147e-01,\n",
              "          1.2162e-01, -1.1344e-02,  8.3657e-02,  1.2428e-02, -1.3311e-01,\n",
              "          6.1215e-01,  3.0727e-01, -3.1849e-01, -1.3171e-01, -2.5909e-01,\n",
              "          5.5186e-01, -7.2767e-02, -1.7995e-01,  5.7283e-02, -2.5946e-01,\n",
              "         -1.8419e-01, -5.8100e-02, -1.8415e-01, -5.6004e-01, -1.1607e-01,\n",
              "         -1.0330e-01,  7.6671e-01, -5.5345e-01,  9.5112e-02,  1.4286e-01,\n",
              "          4.1302e-02,  8.0160e-03,  1.7666e-01, -5.8712e-01, -4.3989e-01,\n",
              "          2.7236e-01,  1.3614e-01, -3.4588e-02,  1.1628e-01, -5.4764e-01,\n",
              "         -2.9222e-01, -4.8480e-01, -2.1229e-02,  7.4025e-02, -1.7064e-01,\n",
              "         -6.5251e-02, -7.4348e-01, -3.2063e-01,  7.9408e-01, -2.5045e-01,\n",
              "         -4.3326e-02, -2.7442e-01,  4.2187e-01, -7.5725e-02, -8.3795e-02,\n",
              "          5.6551e-02,  1.7986e-01, -2.9386e-02, -1.8559e-01, -2.8354e-01,\n",
              "         -6.8318e-01,  1.0662e-01, -1.9495e-01, -6.4168e-01, -2.8546e-02,\n",
              "          4.4791e-01,  7.6253e-01,  1.8930e-01,  3.6366e-02, -4.4802e-01,\n",
              "          2.9306e-01,  2.8841e-01,  1.7293e-01,  5.6280e-01, -2.7763e-01,\n",
              "         -2.2029e-01, -3.2142e-01,  4.5188e-01,  5.0215e-01,  2.9827e-01,\n",
              "          2.6004e-01,  2.9561e-01, -1.6270e+00,  6.2122e-01,  2.5624e-02,\n",
              "         -6.2163e-02, -3.6371e-01, -1.9977e-01,  8.1885e-01, -1.9054e-02,\n",
              "         -4.5088e-01,  9.9717e-02,  5.4844e-01, -1.6833e-01,  1.0493e-01,\n",
              "          2.5125e-01, -2.9522e-02,  4.0467e-01,  4.1579e-01,  1.3179e-01,\n",
              "         -2.2829e-01,  7.1039e-01, -3.2222e-02,  8.9965e-01,  4.5253e-01,\n",
              "         -6.3231e-01, -6.5836e-01, -6.4224e-02, -1.0682e+00, -2.2123e-01,\n",
              "          3.5991e-01,  5.7416e-01, -5.6064e-01,  4.8323e-01, -3.3521e-01,\n",
              "          6.8277e-01,  3.8201e-02,  7.2080e-02, -5.9788e-01,  7.4990e-03,\n",
              "         -6.2208e-01, -1.4299e-01, -1.4600e-02,  3.9977e-01,  6.1373e-01,\n",
              "         -3.4615e-01, -4.4803e-02,  3.6278e-02,  7.5973e-01, -5.4584e-01,\n",
              "         -2.4616e-02, -2.7819e-01, -4.6087e-02,  8.1219e-01,  2.4545e-01,\n",
              "         -4.4596e-01,  3.1490e-01, -2.0923e-01, -2.1289e-01,  6.6195e-01,\n",
              "          3.6991e-01, -8.0539e-01,  3.1400e-01, -2.3719e-01, -9.0441e-02,\n",
              "          7.8435e-01, -4.7416e-01, -1.4230e-01, -5.2409e-01, -1.1146e-01,\n",
              "          8.6001e-01, -4.0764e-01, -6.6260e-01, -2.2695e-01,  2.5270e-01,\n",
              "          1.0278e+00, -6.9497e-02, -2.1070e-01,  4.2022e-01, -1.9342e-01,\n",
              "         -1.3761e-01,  6.3682e-01, -2.2921e-01, -5.1008e-01,  1.2182e-01,\n",
              "          1.4057e+00,  3.2669e-01, -4.0117e+00, -9.2883e-01,  3.5486e-02,\n",
              "         -5.7655e-01,  4.9357e-01,  3.2157e-01,  4.8208e-01, -4.0596e-01,\n",
              "          7.7488e-01,  5.4977e-02,  2.3971e-01, -2.1400e-01, -7.0534e-01,\n",
              "          8.4572e-02,  8.3492e-01, -3.1974e-01], grad_fn=<SelectBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. Evaluation of WSD systems\n",
        "print(\"\\nEvaluating WSD Systems:\")\n",
        "print(\"1. Precision: Correctly disambiguated instances / Total disambiguated instances\")\n",
        "print(\"2. Recall: Correctly disambiguated instances / Total instances that should be disambiguated\")\n",
        "print(\"3. F1 Score: Harmonic mean of precision and recall\")\n",
        "print(\"4. Accuracy: Correctly disambiguated instances / Total instances\")\n",
        "print(\"5. Benchmarks: SemEval, Senseval, WSD evaluation datasets\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4edfEv7jp3t",
        "outputId": "9bd54e0d-5f14-4cae-fcd2-d02c2b7e8bee"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating WSD Systems:\n",
            "1. Precision: Correctly disambiguated instances / Total disambiguated instances\n",
            "2. Recall: Correctly disambiguated instances / Total instances that should be disambiguated\n",
            "3. F1 Score: Harmonic mean of precision and recall\n",
            "4. Accuracy: Correctly disambiguated instances / Total instances\n",
            "5. Benchmarks: SemEval, Senseval, WSD evaluation datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example sentences with ambiguous words\n",
        "sentences = [\n",
        "    \"I can hear bass sounds\",\n",
        "    \"They caught a large bass in the lake\",\n",
        "    \"The crane lifted the heavy materials\",\n",
        "    \"A crane flew over the wetlands\"\n",
        "]\n",
        "\n",
        "# Disambiguate using Lesk algorithm\n",
        "for sentence in sentences:\n",
        "    ambiguous_word = \"bass\" if \"bass\" in sentence else \"crane\"\n",
        "    tokenized = nltk.word_tokenize(sentence)\n",
        "    synset = lesk(tokenized, ambiguous_word, 'n')\n",
        "\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Ambiguous word: {ambiguous_word}\")\n",
        "    print(f\"Detected meaning: {synset.definition() if synset else 'Not found'}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "8vTWK-bobcWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.Information Extraction"
      ],
      "metadata": {
        "id": "0sXgzUIRkYeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information extraction identifies and extracts structured data from unstructured text"
      ],
      "metadata": {
        "id": "exHGJcGrkYhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk import ne_chunk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IHZ9PLgkDFV",
        "outputId": "08dd119c-14b0-432e-925a-aa6d7046fd4d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Named Entity Recognition\n",
        "def extract_entities(text):\n",
        "    \"\"\"\n",
        "    Extract named entities from text using NLTK\n",
        "    \"\"\"\n",
        "    entities = {\n",
        "        'PERSON': [],\n",
        "        'ORGANIZATION': [],\n",
        "        'GPE': [],  # Geo-Political Entity\n",
        "        'LOCATION': [],\n",
        "        'DATE': [],\n",
        "        'TIME': [],\n",
        "        'MONEY': [],\n",
        "        'PERCENT': [],\n",
        "        'FACILITY': []\n",
        "    }\n",
        "\n",
        "    # Tokenize and tag\n",
        "    sentences = sent_tokenize(text)\n",
        "    for sentence in sentences:\n",
        "        tokens = word_tokenize(sentence)\n",
        "        tagged = pos_tag(tokens)\n",
        "\n",
        "        # Extract named entities\n",
        "        tree = ne_chunk(tagged)\n",
        "\n",
        "        # Process tree\n",
        "        for subtree in tree:\n",
        "            if isinstance(subtree, nltk.Tree):\n",
        "                entity_type = subtree.label()\n",
        "                entity_text = ' '.join([word for word, tag in subtree.leaves()])\n",
        "                if entity_type in entities:\n",
        "                    entities[entity_type].append(entity_text)\n",
        "\n",
        "    # Remove duplicates and return\n",
        "    for entity_type in entities:\n",
        "        entities[entity_type] = list(set(entities[entity_type]))\n",
        "\n",
        "    return entities"
      ],
      "metadata": {
        "id": "T7LrLMtgkDIU"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Relation Extraction\n",
        "def extract_relations(text):\n",
        "    \"\"\"\n",
        "    Simple relation extraction using patterns\n",
        "    \"\"\"\n",
        "    relations = []\n",
        "\n",
        "    # Simple patterns for relation extraction\n",
        "    patterns = [\n",
        "        # Person-Organization patterns (works for)\n",
        "        (r'([A-Z][a-z]+ [A-Z][a-z]+) works for ([A-Z][a-zA-Z]+)', 'WORKS_FOR'),\n",
        "        (r'([A-Z][a-z]+ [A-Z][a-z]+) is employed by ([A-Z][a-zA-Z]+)', 'WORKS_FOR'),\n",
        "        (r'([A-Z][a-z]+ [A-Z][a-z]+) joined ([A-Z][a-zA-Z]+)', 'WORKS_FOR'),\n",
        "\n",
        "        # Person-Person patterns (reports to)\n",
        "        (r'([A-Z][a-z]+ [A-Z][a-z]+) reports to ([A-Z][a-z]+ [A-Z][a-z]+)', 'REPORTS_TO'),\n",
        "\n",
        "        # Organization-Location patterns (based in)\n",
        "        (r'([A-Z][a-zA-Z]+) is based in ([A-Z][a-z]+)', 'BASED_IN'),\n",
        "        (r'([A-Z][a-zA-Z]+) headquarters in ([A-Z][a-z]+)', 'BASED_IN'),\n",
        "\n",
        "        # Person-Role patterns (is a)\n",
        "        (r'([A-Z][a-z]+ [A-Z][a-z]+) is the ([a-zA-Z]+) of ([A-Z][a-zA-Z]+)', 'HAS_ROLE'),\n",
        "        (r'([A-Z][a-z]+ [A-Z][a-z]+), the ([a-zA-Z]+) of ([A-Z][a-zA-Z]+)', 'HAS_ROLE')\n",
        "    ]\n",
        "\n",
        "    # Apply patterns\n",
        "    for sentence in sent_tokenize(text):\n",
        "        for pattern, relation_type in patterns:\n",
        "            matches = re.findall(pattern, sentence)\n",
        "            for match in matches:\n",
        "                if relation_type == 'HAS_ROLE':\n",
        "                    entity1, role, entity2 = match\n",
        "                    relations.append({\n",
        "                        'entity1': entity1,\n",
        "                        'relation': relation_type,\n",
        "                        'entity2': entity2,\n",
        "                        'role': role,\n",
        "                        'sentence': sentence\n",
        "                    })\n",
        "                else:\n",
        "                    entity1, entity2 = match\n",
        "                    relations.append({\n",
        "                        'entity1': entity1,\n",
        "                        'relation': relation_type,\n",
        "                        'entity2': entity2,\n",
        "                        'sentence': sentence\n",
        "                    })\n",
        "\n",
        "    return relations"
      ],
      "metadata": {
        "id": "iG9SRQXMkeoS"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Event Extraction\n",
        "def extract_events(text):\n",
        "    \"\"\"\n",
        "    Extract events using verb phrase patterns\n",
        "    \"\"\"\n",
        "    events = []\n",
        "\n",
        "    # Sample event patterns (based on verb phrases)\n",
        "    event_verbs = ['announced', 'launched', 'acquired', 'released', 'appointed', 'resigned']\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    for sentence in sentences:\n",
        "        tokens = word_tokenize(sentence)\n",
        "        tagged = pos_tag(tokens)\n",
        "\n",
        "        # Look for event trigger verbs\n",
        "        for i, (word, tag) in enumerate(tagged):\n",
        "            if word.lower() in event_verbs:\n",
        "                # Extract surrounding context\n",
        "                start = max(0, i-5)\n",
        "                end = min(len(tagged), i+6)\n",
        "                context = ' '.join([t[0] for t in tagged[start:end]])\n",
        "\n",
        "                # Extract subject (simplistic approach)\n",
        "                subject = \"\"\n",
        "                for j in range(i-1, -1, -1):\n",
        "                    if tagged[j][1].startswith('NN'):\n",
        "                        subject = tagged[j][0]\n",
        "                        break\n",
        "\n",
        "                events.append({\n",
        "                    'event_type': word.upper(),\n",
        "                    'trigger': word,\n",
        "                    'subject': subject,\n",
        "                    'context': context,\n",
        "                    'sentence': sentence\n",
        "                })\n",
        "\n",
        "    return events"
      ],
      "metadata": {
        "id": "MvlImpMCkerj"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample corporate news text\n",
        "sample_text = \"\"\"\n",
        "Apple Inc. is based in Cupertino. The technology giant announced a new iPhone model yesterday.\n",
        "Tim Cook, the CEO of Apple, presented the product during the annual conference.\n",
        "Microsoft headquarters in Seattle and employs over 150,000 people worldwide.\n",
        "Satya Nadella joined Microsoft in 1992 and became CEO in 2014.\n",
        "Google acquired DeepMind for $500 million in 2014.\n",
        "Sundar Pichai reports to Alphabet's board of directors.\n",
        "Facebook released a new virtual reality headset last month.\n",
        "Tesla is planning to build a new factory in Austin, Texas, which will create 5,000 jobs.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O09xVS2kkeuj"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract named entities\n",
        "print(\"Named Entity Recognition:\")\n",
        "entities = extract_entities(sample_text)\n",
        "for entity_type, entity_list in entities.items():\n",
        "    if entity_list:\n",
        "        print(f\"{entity_type}: {', '.join(entity_list)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G08GaEzVkexR",
        "outputId": "0a1e8964-3d09-44ff-d9a6-eae3fa5a820d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entity Recognition:\n",
            "PERSON: Sundar, Satya, Apple, Tim, Microsoft, Facebook, Nadella, Google\n",
            "ORGANIZATION: iPhone, Inc., Pichai, DeepMind, CEO\n",
            "GPE: Tesla, Austin, Seattle, Cook, Apple, Microsoft, Texas, Alphabet, Cupertino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Extract relations\n",
        "print(\"\\nRelation Extraction:\")\n",
        "relations = extract_relations(sample_text)\n",
        "relations_df = pd.DataFrame(relations)\n",
        "if not relations_df.empty:\n",
        "    print(relations_df[['entity1', 'relation', 'entity2']])\n",
        "else:\n",
        "    print(\"No relations extracted with current patterns.\")\n",
        "\n",
        "# Extract events\n",
        "print(\"\\nEvent Extraction:\")\n",
        "events = extract_events(sample_text)\n",
        "events_df = pd.DataFrame(events)\n",
        "if not events_df.empty:\n",
        "    print(events_df[['event_type', 'subject', 'context']])\n",
        "else:\n",
        "    print(\"No events extracted with current patterns.\")\n",
        "\n",
        "# 4. Information Extraction with spaCy (code example)\n",
        "print(\"\\nInformation Extraction with spaCy (example code):\")\n",
        "print(\"\"\"\n",
        "import spacy\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process text\n",
        "doc = nlp(\"Apple Inc. was founded by Steve Jobs in Cupertino, California in 1976.\")\n",
        "\n",
        "# Named Entity Recognition\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Type: {ent.label_}, Description: {spacy.explain(ent.label_)}\")\n",
        "\n",
        "# Dependency Parsing for Relation Extraction\n",
        "for token in doc:\n",
        "    if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
        "        subject = token.text\n",
        "        verb = token.head.text\n",
        "        for child in token.head.children:\n",
        "            if child.dep_ == \"dobj\":\n",
        "                direct_object = child.text\n",
        "                print(f\"Relation: {subject} - {verb} - {direct_object}\")\n",
        "\"\"\")\n",
        "\n",
        "# 5. Applications of Information Extraction\n",
        "print(\"\\nApplications of Information Extraction:\")\n",
        "print(\"1. Knowledge Graph Construction\")\n",
        "print(\"2. Business Intelligence (extracting insights from news, reports)\")\n",
        "print(\"3. Resume Parsing (extracting skills, experience)\")\n",
        "print(\"4. Customer Feedback Analysis\")\n",
        "print(\"5. Medical Records Analysis (extracting symptoms, diagnoses)\")\n",
        "print(\"6. Legal Document Processing (extracting clauses, parties, obligations)\")\n",
        "print(\"7. Competitive Intelligence\")\n",
        "print(\"8. Automated Data Entry\")\n",
        "\n",
        "# 6. Advanced Information Extraction with Transformers\n",
        "print(\"\\nAdvanced Information Extraction with Transformers (example):\")\n",
        "print(\"\"\"\n",
        "from transformers import pipeline\n",
        "\n",
        "# Named Entity Recognition\n",
        "ner_pipeline = pipeline(\"ner\")\n",
        "ner_results = ner_pipeline(\"Tim Cook is the CEO of Apple Inc. which is worth $2 trillion.\")\n",
        "\n",
        "# Group tokens belonging to the same entity\n",
        "grouped_entities = []\n",
        "current_entity = None\n",
        "for entity in ner_results:\n",
        "    if current_entity is None or entity[\"entity\"].startswith(\"B-\"):\n",
        "        if current_entity is not None:\n",
        "            grouped_entities.append(current_entity)\n",
        "        current_entity = {\n",
        "            \"word\": entity[\"word\"],\n",
        "            \"entity_group\": entity[\"entity\"].split(\"-\")[1],\n",
        "            \"score\": entity[\"score\"]\n",
        "        }\n",
        "    else:\n",
        "        current_entity[\"word\"] += entity[\"word\"].replace(\"##\", \"\")\n",
        "        current_entity[\"score\"] = (current_entity[\"score\"] + entity[\"score\"]) / 2\n",
        "\n",
        "if current_entity is not None:\n",
        "    grouped_entities.append(current_entity)\n",
        "\n",
        "for entity in grouped_entities:\n",
        "    print(f\"{entity['word']} - {entity['entity_group']} ({entity['score']:.4f})\")\n",
        "\"\"\")\n",
        "\n",
        "# 7. Evaluation metrics for Information Extraction\n",
        "print(\"\\nEvaluation Metrics for Information Extraction:\")\n",
        "print(\"1. Precision: Correctly extracted information / All extracted information\")\n",
        "print(\"2. Recall: Correctly extracted information / All information that should be extracted\")\n",
        "print(\"3. F1-Score: Harmonic mean of precision and recall\")\n",
        "print(\"4. Slot Error Rate (SER): Combines insertion, deletion, and substitution errors\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VZpHj0BphMXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.Chatbots and Dialogue Systems"
      ],
      "metadata": {
        "id": "1Lv09XI-kvXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbots and dialogue systems enable natural language interaction between humans and computers"
      ],
      "metadata": {
        "id": "yDSE0neRkvZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chatbots and Dialogue Systems Example\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 1. Rule-based Chatbot\n",
        "class RuleBasedChatbot:\n",
        "    def __init__(self):\n",
        "        self.rules = [\n",
        "            {\n",
        "                \"patterns\": [\"hello\", \"hi\", \"hey\", \"greetings\"],\n",
        "                \"responses\": [\"Hello!\", \"Hi there!\", \"Hey! How can I help you?\"]\n",
        "            },\n",
        "            {\n",
        "                \"patterns\": [\"how are you\", \"how are you doing\", \"how's it going\"],\n",
        "                \"responses\": [\"I'm doing well, thanks for asking!\", \"I'm fine, how about you?\"]\n",
        "            },\n",
        "            {\n",
        "                \"patterns\": [\"what is your name\", \"who are you\", \"tell me about yourself\"],\n",
        "                \"responses\": [\"I'm a simple rule-based chatbot.\", \"My name is ChattyBot!\"]\n",
        "            },\n",
        "            {\n",
        "                \"patterns\": [\"bye\", \"goodbye\", \"see you\", \"farewell\"],\n",
        "                \"responses\": [\"Goodbye!\", \"See you later!\", \"Have a nice day!\"]\n",
        "            },\n",
        "            {\n",
        "                \"patterns\": [\"thank you\", \"thanks\"],\n",
        "                \"responses\": [\"You're welcome!\", \"Glad I could help!\"]\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Default response\n",
        "        self.default_responses = [\n",
        "            \"I'm not sure I understand.\",\n",
        "            \"Could you rephrase that?\",\n",
        "            \"I don't have information about that.\"\n",
        "        ]\n",
        "\n",
        "    def match_rule(self, user_message):\n",
        "        user_message = user_message.lower()\n",
        "\n",
        "        for rule in self.rules:\n",
        "            for pattern in rule[\"patterns\"]:\n",
        "                if pattern in user_message:\n",
        "                    return random.choice(rule[\"responses\"])\n",
        "\n",
        "        return random.choice(self.default_responses)\n",
        "\n",
        "    def respond(self, user_message):\n",
        "        return self.match_rule(user_message)\n",
        "\n",
        "# 2. Retrieval-based Chatbot\n",
        "class RetrievalChatbot:\n",
        "    def __init__(self, qa_pairs):\n",
        "        self.qa_pairs = qa_pairs\n",
        "        self.questions = [pair[\"question\"] for pair in qa_pairs]\n",
        "\n",
        "        # Create TF-IDF vectorizer\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.question_vectors = self.vectorizer.fit_transform(self.questions)\n",
        "\n",
        "    def find_best_match(self, user_query, threshold=0.4):\n",
        "        # Vectorize the user query\n",
        "        query_vector = self.vectorizer.transform([user_query])\n",
        "\n",
        "        # Calculate similarities\n",
        "        similarities = cosine_similarity(query_vector, self.question_vectors)[0]\n",
        "\n",
        "        # Find best match\n",
        "        best_match_idx = similarities.argmax()\n",
        "        best_match_score = similarities[best_match_idx]\n",
        "\n",
        "        if best_match_score >= threshold:\n",
        "            return self.qa_pairs[best_match_idx][\"answer\"], best_match_score\n",
        "        else:\n",
        "            return \"I'm not sure how to answer that. Could you rephrase your question?\", 0.0\n",
        "\n",
        "    def respond(self, user_message):\n",
        "        response, confidence = self.find_best_match(user_message)\n",
        "        return response\n",
        "\n",
        "# Sample QA pairs for retrieval-based chatbot\n",
        "qa_pairs = [\n",
        "    {\"question\": \"What is NLP?\", \"answer\": \"Natural Language Processing (NLP) is a field of AI that gives computers the ability to understand text and spoken words in the same way humans can.\"},\n",
        "    {\"question\": \"What are the main tasks in NLP?\", \"answer\": \"The main tasks in NLP include text classification, named entity recognition, sentiment analysis, machine translation, and question answering.\"},\n",
        "    {\"question\": \"How does sentiment analysis work?\", \"answer\": \"Sentiment analysis uses NLP techniques to determine the emotional tone behind text. It can classify text as positive, negative, or neutral.\"},\n",
        "    {\"question\": \"What is machine translation?\", \"answer\": \"Machine translation is the process of automatically translating text from one language to another using AI and NLP techniques.\"},\n",
        "    {\"question\": \"What is tokenization?\", \"answer\": \"Tokenization is the process of breaking text into smaller pieces called tokens, typically words or subwords.\"},\n",
        "    {\"question\": \"What are word embeddings?\", \"answer\": \"Word embeddings are vector representations of words that capture semantic meaning, allowing similar words to have similar vector representations.\"},\n",
        "    {\"question\": \"What is BERT?\", \"answer\": \"BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained language model that has achieved state-of-the-art results on many NLP tasks.\"},\n",
        "    {\"question\": \"How do chatbots work?\", \"answer\": \"Chatbots work by using NLP techniques to understand user input and generate appropriate responses, either through rule-based systems, retrieval-based methods, or generative models.\"}\n",
        "]\n",
        "\n",
        "# 3. Intent Classification\n",
        "def classify_intent(user_message):\n",
        "    \"\"\"\n",
        "    Simple intent classification\n",
        "    \"\"\"\n",
        "    intents = {\n",
        "        \"greeting\": [\"hello\", \"hi\", \"hey\", \"good morning\", \"greetings\"],\n",
        "        \"farewell\": [\"bye\", \"goodbye\", \"see you\", \"farewell\"],\n",
        "        \"information\": [\"what is\", \"how does\", \"explain\", \"tell me about\"],\n",
        "        \"help\": [\"help\", \"assist\", \"support\", \"guide\"],\n",
        "        \"booking\": [\"book\", \"reserve\", \"schedule\", \"appointment\"],\n",
        "        \"complaint\": [\"problem\", \"issue\", \"not working\", \"complaint\", \"dissatisfied\"]\n",
        "    }\n",
        "\n",
        "    user_message = user_message.lower()\n",
        "\n",
        "    # Calculate intent scores\n",
        "    intent_scores = {}\n",
        "    for intent, keywords in intents.items():\n",
        "        score = sum(1 for keyword in keywords if keyword in user_message)\n",
        "        intent_scores[intent] = score\n",
        "\n",
        "    # Get the intent with the highest score\n",
        "    max_score = max(intent_scores.values())\n",
        "    if max_score > 0:\n",
        "        best_intents = [intent for intent, score in intent_scores.items() if score == max_score]\n",
        "        return random.choice(best_intents)\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# 4. Entity Extraction\n",
        "def extract_entities(user_message):\n",
        "    \"\"\"\n",
        "    Simple pattern-based entity extraction\n",
        "    \"\"\"\n",
        "    entities = {}\n",
        "\n",
        "    # Date patterns\n",
        "    date_pattern = r'\\b(?:on\\s+)?(\\d{1,2}(?:st|nd|rd|th)?\\s+(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)|tomorrow|today|(?:next|this)\\s+(?:Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday))\\b'\n",
        "    date_matches = re.findall(date_pattern, user_message, re.IGNORECASE)\n",
        "    if date_matches:\n",
        "        entities['date'] = date_matches[0]\n",
        "\n",
        "    # Time patterns\n",
        "    time_pattern = r'\\b(?:at\\s+)?(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm)?|noon|midnight)\\b'\n",
        "    time_matches = re.findall(time_pattern, user_message, re.IGNORECASE)\n",
        "    if time_matches:\n",
        "        entities['time'] = time_matches[0]\n",
        "\n",
        "    # Location patterns\n",
        "    location_pattern = r'\\b(?:in|at|to)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\b'\n",
        "    location_matches = re.findall(location_pattern, user_message)\n",
        "    if location_matches:\n",
        "        entities['location'] = location_matches[0]\n",
        "\n",
        "    # Numbers\n",
        "    number_pattern = r'\\b(\\d+)\\b'\n",
        "    number_matches = re.findall(number_pattern, user_message)"
      ],
      "metadata": {
        "id": "B1HkWclqkzea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Entity Extraction (continued)\n",
        "    if number_matches:\n",
        "        entities['number'] = number_matches[0]\n",
        "\n",
        "    return entities\n",
        "\n",
        "# 5. Dialogue Management with State Tracking\n",
        "class DialogueManager:\n",
        "    def __init__(self):\n",
        "        self.states = {\n",
        "            \"greeting\": {\n",
        "                \"required_entities\": [],\n",
        "                \"response_templates\": [\n",
        "                    \"Hello! How can I help you today?\",\n",
        "                    \"Hi there! What can I do for you?\"\n",
        "                ],\n",
        "                \"next_states\": [\"booking\", \"information\", \"help\"]\n",
        "            },\n",
        "            \"booking\": {\n",
        "                \"required_entities\": [\"date\", \"time\", \"location\"],\n",
        "                \"response_templates\": [\n",
        "                    \"I'll book your appointment for {date} at {time} in {location}.\",\n",
        "                    \"Your booking is confirmed for {date} at {time} in {location}.\"\n",
        "                ],\n",
        "                \"next_states\": [\"confirmation\", \"farewell\"]\n",
        "            },\n",
        "            \"information\": {\n",
        "                \"required_entities\": [\"subject\"],\n",
        "                \"response_templates\": [\n",
        "                    \"Here's what I know about {subject}: ...\",\n",
        "                    \"Let me tell you about {subject}: ...\"\n",
        "                ],\n",
        "                \"next_states\": [\"more_info\", \"booking\", \"farewell\"]\n",
        "            },\n",
        "            \"confirmation\": {\n",
        "                \"required_entities\": [],\n",
        "                \"response_templates\": [\n",
        "                    \"Is there anything else you need help with?\",\n",
        "                    \"Can I assist you with anything else?\"\n",
        "                ],\n",
        "                \"next_states\": [\"booking\", \"information\", \"farewell\"]\n",
        "            },\n",
        "            \"farewell\": {\n",
        "                \"required_entities\": [],\n",
        "                \"response_templates\": [\n",
        "                    \"Thank you for chatting with me. Have a great day!\",\n",
        "                    \"Goodbye! Feel free to come back if you have more questions.\"\n",
        "                ],\n",
        "                \"next_states\": []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.current_state = \"greeting\"\n",
        "        self.collected_entities = {}\n",
        "\n",
        "    def transition(self, user_message):\n",
        "        # Extract intent\n",
        "        intent = classify_intent(user_message)\n",
        "\n",
        "        # Extract entities\n",
        "        new_entities = extract_entities(user_message)\n",
        "        self.collected_entities.update(new_entities)\n",
        "\n",
        "        # Check if intent matches a valid next state\n",
        "        if intent in self.states[self.current_state][\"next_states\"]:\n",
        "            self.current_state = intent\n",
        "\n",
        "        # Check if we have all required entities for current state\n",
        "        missing_entities = []\n",
        "        for entity in self.states[self.current_state][\"required_entities\"]:\n",
        "            if entity not in self.collected_entities:\n",
        "                missing_entities.append(entity)\n",
        "\n",
        "        # Generate response\n",
        "        if missing_entities:\n",
        "            # Ask for missing entities\n",
        "            entity_to_ask = missing_entities[0]\n",
        "            return f\"Could you please provide the {entity_to_ask}?\"\n",
        "        else:\n",
        "            # Generate response using template\n",
        "            template = random.choice(self.states[self.current_state][\"response_templates\"])\n",
        "            return template.format(**self.collected_entities)\n",
        "\n",
        "# 6. Full Dialogue System Example\n",
        "def simulate_conversation(chatbot_type=\"rule\"):\n",
        "    \"\"\"\n",
        "    Simulate a conversation with a chatbot\n",
        "    \"\"\"\n",
        "    if chatbot_type == \"rule\":\n",
        "        chatbot = RuleBasedChatbot()\n",
        "        print(\"Rule-based Chatbot Initialized\")\n",
        "    elif chatbot_type == \"retrieval\":\n",
        "        chatbot = RetrievalChatbot(qa_pairs)\n",
        "        print(\"Retrieval-based Chatbot Initialized\")\n",
        "    elif chatbot_type == \"dialogue\":\n",
        "        chatbot = DialogueManager()\n",
        "        print(\"Dialogue Manager Initialized\")\n",
        "    else:\n",
        "        print(\"Invalid chatbot type\")\n",
        "        return\n",
        "\n",
        "    print(\"Bot: Hello! Type 'quit' to exit.\")\n",
        "\n",
        "    conversation_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"Bot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if chatbot_type == \"dialogue\":\n",
        "            response = chatbot.transition(user_input)\n",
        "        else:\n",
        "            response = chatbot.respond(user_input)\n",
        "\n",
        "        print(f\"Bot: {response}\")\n",
        "\n",
        "        # Add to conversation history\n",
        "        conversation_history.append({\"user\": user_input, \"bot\": response})\n",
        "\n",
        "    return conversation_history\n",
        "\n",
        "# 7. Intent Classification with ML (example code)\n",
        "print(\"Intent Classification with Machine Learning (example code):\")\n",
        "print(\"\"\"\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Training data\n",
        "training_data = [\n",
        "    (\"Hello there\", \"greeting\"),\n",
        "    (\"Hi, how are you?\", \"greeting\"),\n",
        "    (\"Good morning\", \"greeting\"),\n",
        "    (\"Bye now\", \"farewell\"),\n",
        "    (\"See you later\", \"farewell\"),\n",
        "    (\"Goodbye\", \"farewell\"),\n",
        "    (\"What time do you open?\", \"information\"),\n",
        "    (\"Tell me about your services\", \"information\"),\n",
        "    (\"How much does it cost?\", \"information\"),\n",
        "    (\"I need help with my account\", \"help\"),\n",
        "    (\"Can you assist me?\", \"help\"),\n",
        "    (\"I'm having a problem\", \"help\"),\n",
        "    (\"Book an appointment for tomorrow\", \"booking\"),\n",
        "    (\"I want to schedule a meeting\", \"booking\"),\n",
        "    (\"Reserve a table for two\", \"booking\")\n",
        "]\n",
        "\n",
        "# Split into texts and labels\n",
        "texts, labels = zip(*training_data)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create pipeline with TF-IDF and SVM\n",
        "intent_classifier = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LinearSVC())\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "intent_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "predictions = intent_classifier.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# Predict intent for new text\n",
        "new_text = \"I want to book a table for dinner tonight\"\n",
        "predicted_intent = intent_classifier.predict([new_text])[0]\n",
        "print(f\"Predicted intent: {predicted_intent}\")\n",
        "\"\"\")\n",
        "\n",
        "# 8. Chatbot Evaluation Metrics\n",
        "print(\"\\nChatbot Evaluation Metrics:\")\n",
        "print(\"1. Task Completion Rate: Percentage of tasks successfully completed\")\n",
        "print(\"2. Turn Correctness: Percentage of system turns that are appropriate\")\n",
        "print(\"3. Average Conversation Length: Number of turns to complete a task\")\n",
        "print(\"4. User Satisfaction: User ratings or feedback scores\")\n",
        "print(\"5. Response Appropriateness: Human judgment of response quality\")\n",
        "print(\"6. Domain Coverage: Range of topics the bot can handle\")\n",
        "print(\"7. Error Rate: Percentage of responses with errors\")\n",
        "print(\"8. Recovery Rate: Ability to recover from misunderstandings\")\n",
        "\n",
        "# 9. Building a Production-Ready Chatbot\n",
        "print(\"\\nSteps to Build a Production-Ready Chatbot:\")\n",
        "print(\"1. Define clear user goals and bot capabilities\")\n",
        "print(\"2. Design conversation flows and dialogue states\")\n",
        "print(\"3. Implement intent recognition\")\n",
        "print(\"4. Build entity extraction\")\n",
        "print(\"5. Create dialogue management system\")\n",
        "print(\"6. Develop response generation\")\n",
        "print(\"7. Add context awareness and personalization\")\n",
        "print(\"8. Implement fallback mechanisms and error handling\")\n",
        "print(\"9. Integrate with external systems (databases, APIs)\")\n",
        "print(\"10. Test with real users and continuously improve\")\n",
        "print(\"11. Monitor performance and user satisfaction\")\n",
        "print(\"12. Deploy with scalability in mind\")\n",
        "\n",
        "# 10. Natural Language Generation for Responses\n",
        "def generate_personalized_response(intent, entities, context, user_info):\n",
        "    \"\"\"\n",
        "    Example of personalized response generation\n",
        "    \"\"\"\n",
        "    templates = {\n",
        "        \"greeting\": [\n",
        "            \"Hello {user_name}! Welcome back. How can I help you today?\",\n",
        "            \"Hi {user_name}! Nice to see you again. What can I do for you?\"\n",
        "        ],\n",
        "        \"booking\": [\n",
        "            \"I've booked your {service_type} for {date} at {time}. A confirmation has been sent to {email}.\",\n",
        "            \"Your {service_type} is confirmed for {date} at {time}. We'll send details to {email}.\"\n",
        "        ],\n",
        "        \"information\": [\n",
        "            \"Based on your preferences, here's information about {topic}: ...\",\n",
        "            \"Here's what you should know about {topic}, {user_name}: ...\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Select appropriate template\n",
        "    if intent in templates:\n",
        "        template = random.choice(templates[intent])\n",
        "\n",
        "        # Fill in user info\n",
        "        response = template.format(\n",
        "            user_name=user_info.get(\"name\", \"there\"),\n",
        "            email=user_info.get(\"email\", \"your email\"),\n",
        "            **entities,\n",
        "            **context\n",
        "        )\n",
        "        return response\n",
        "    else:\n",
        "        return \"I'm not sure how to respond to that.\"\n",
        "\n",
        "# Example usage\n",
        "sample_user_info = {\n",
        "    \"name\": \"Alex\",\n",
        "    \"email\": \"alex@example.com\",\n",
        "    \"preferences\": [\"quick responses\", \"casual tone\"]\n",
        "}\n",
        "\n",
        "sample_context = {\n",
        "    \"service_type\": \"dental appointment\",\n",
        "    \"topic\": \"teeth whitening\"\n",
        "}\n",
        "\n",
        "sample_entities = {\n",
        "    \"date\": \"next Monday\",\n",
        "    \"time\": \"2:30pm\"\n",
        "}\n",
        "\n",
        "print(\"\\nPersonalized Response Examples:\")\n",
        "print(f\"Greeting: {generate_personalized_response('greeting', {}, {}, sample_user_info)}\")\n",
        "print(f\"Booking: {generate_personalized_response('booking', sample_entities, sample_context, sample_user_info)}\")\n",
        "print(f\"Information: {generate_personalized_response('information', {}, sample_context, sample_user_info)}\")"
      ],
      "metadata": {
        "id": "NaMwd2R4k5FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.Text Summarization"
      ],
      "metadata": {
        "id": "SUwM4cNWk7Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text summarization condenses text while preserving key information"
      ],
      "metadata": {
        "id": "kHrPXuozk-kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Summarization Example\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# 1. Extractive Summarization with TextRank\n",
        "def extractive_summarize(text, num_sentences=3):\n",
        "    \"\"\"\n",
        "    Summarize text using TextRank algorithm\n",
        "\n",
        "    Args:\n",
        "        text: Text to summarize\n",
        "        num_sentences: Number of sentences in the summary\n",
        "\n",
        "    Returns:\n",
        "        Summary text\n",
        "    \"\"\"\n",
        "    # Preprocessing\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Clean and tokenize sentences\n",
        "    clean_sentences = []\n",
        "    original_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        original_sentences.append(sentence)\n",
        "        words = [word.lower() for word in word_tokenize(sentence) if word.isalnum()]\n",
        "        clean_sentences.append([word for word in words if word not in stop_words])\n",
        "\n",
        "    # Build similarity matrix\n",
        "    sentence_similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences)):\n",
        "            if i != j:\n",
        "                sentence_similarity_matrix[i][j] = sentence_similarity(clean_sentences[i], clean_sentences[j])\n",
        "\n",
        "    # Create graph and apply PageRank\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Sort sentences by score and select top ones\n",
        "    ranked_sentences = sorted(((scores[i], i) for i in range(len(sentences))), reverse=True)\n",
        "\n",
        "    # Get top sentences maintaining original order\n",
        "    top_sentence_indices = [ranked_sentences[i][1] for i in range(min(num_sentences, len(ranked_sentences)))]\n",
        "    top_sentence_indices.sort()\n",
        "\n",
        "    summary = [original_sentences[i] for i in top_sentence_indices]\n",
        "\n",
        "    return ' '.join(summary)\n",
        "\n",
        "def sentence_similarity(sent1, sent2):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between two sentences\n",
        "    \"\"\"\n",
        "    # Create word vectors\n",
        "    all_words = list(set(sent1 + sent2))\n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        "\n",
        "    # Build vectors\n",
        "    for word in sent1:\n",
        "        vector1[all_words.index(word)] += 1\n",
        "\n",
        "    for word in sent2:\n",
        "        vector2[all_words.index(word)] += 1\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    if sum(vector1) == 0 or sum(vector2) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return 1 - cosine_distance(vector1, vector2)\n",
        "\n",
        "# 2. TF-IDF Based Summarization\n",
        "def tfidf_summarize(text, num_sentences=3):\n",
        "    \"\"\"\n",
        "    Summarize text using TF-IDF scoring\n",
        "    \"\"\"\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "    # Tokenize into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Create TF-IDF vectorizer\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "    # If we have only one sentence, return it\n",
        "    if len(sentences) <= num_sentences:\n",
        "        return text\n",
        "\n",
        "    # Generate TF-IDF matrix\n",
        "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "    # Calculate sentence scores based on TF-IDF values\n",
        "    sentence_scores = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        score = np.sum(tfidf_matrix[i].toarray())\n",
        "        sentence_scores.append((score, i))\n",
        "\n",
        "    # Sort sentences by score\n",
        "    sentence_scores.sort(reverse=True)\n",
        "\n",
        "    # Get top sentences maintaining original order\n",
        "    top_sentence_indices = [sentence_scores[i][1] for i in range(min(num_sentences, len(sentence_scores)))]\n",
        "    top_sentence_indices.sort()\n",
        "\n",
        "    # Combine sentences\n",
        "    summary = [sentences[i] for i in top_sentence_indices]\n",
        "    return ' '.join(summary)\n",
        "\n",
        "# Sample text for summarization\n",
        "long_article = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that gives computers the ability to understand text and spoken words in much the same way human beings can. NLP combines computational linguistics—rule-based modeling of human language—with statistical, machine learning, and deep learning models. Together, these technologies enable computers to process human language in the form of text or voice data and to 'understand' its full meaning, complete with the speaker or writer's intent and sentiment.\n",
        "\n",
        "NLP drives computer programs that translate text from one language to another, respond to spoken commands, and summarize large volumes of text rapidly—even in real time. There's a good chance you've interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences. But NLP also plays a growing role in enterprise solutions that help streamline business operations, increase employee productivity, and simplify mission-critical business processes.\n",
        "\n",
        "The field of NLP has been developing since the 1950s, with roots in linguistics and computer science. The term \"Natural Language Processing\" was coined in the early 1960s by researchers focused on machine translation. In the early days, most NLP systems were rule-based, with teams of linguists writing formal rules for processing text. By the 1980s, statistical methods began to emerge, allowing computers to learn patterns from large collections of text. The 2010s saw a revolution in NLP with the rise of deep learning techniques, particularly neural networks.\n",
        "\n",
        "Today, NLP is experiencing unprecedented growth thanks to the development of powerful deep learning models like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), which have dramatically improved the state-of-the-art across many NLP tasks. These models leverage massive amounts of training data and computational power to achieve remarkable results in language understanding and generation.\n",
        "\n",
        "Common NLP tasks include sentiment analysis, which identifies the mood or subjective opinions within large amounts of text, including entire social media platforms. This helps companies understand how customers feel about specific products or brands. Named Entity Recognition identifies proper names of people, organizations, and places in text, while summarization condenses large volumes of text while preserving key information and meaning. Machine translation converts text from one language to another, and speech recognition converts spoken language to text.\n",
        "\n",
        "Despite impressive advances, NLP still faces many challenges. Understanding context, sarcasm, humor, and cultural references remains difficult for machines. Dealing with low-resource languages that have limited available training data is another significant challenge. As NLP systems become more integrated into daily life, concerns about bias in language models, privacy implications, and the ethics of AI-generated content have grown more prominent.\n",
        "\n",
        "The future of NLP promises greater language understanding capabilities, more natural human-computer interactions, and increasingly personalized experiences. As models continue to grow in size and sophistication, and as techniques for training on fewer examples improve, we can expect NLP to become even more pervasive in our technological landscape.\n",
        "\"\"\"\n",
        "\n",
        "# Run extractive summarization\n",
        "print(\"TextRank Extractive Summarization:\")\n",
        "textrank_summary = extractive_summarize(long_article, num_sentences=3)\n",
        "print(textrank_summary)\n",
        "\n",
        "print(\"\\nTF-IDF Based Summarization:\")\n",
        "tfidf_summary = tfidf_summarize(long_article, num_sentences=3)\n",
        "print(tfidf_summary)\n",
        "\n",
        "# 3. Abstractive Summarization (using transformers)\n",
        "def abstractive_summarize(text, max_length=150):\n",
        "    \"\"\"\n",
        "    Abstractive summarization using transformers (code example)\n",
        "    \"\"\"\n",
        "    print(\"\\nAbstractive Summarization with Transformers (code example):\")\n",
        "    print(\"\"\"\n",
        "    from transformers import pipeline\n",
        "\n",
        "    # Initialize summarization pipeline\n",
        "    summarizer = pipeline(\"summarization\")\n",
        "\n",
        "    # Generate summary\n",
        "    summary = summarizer(text, max_length=max_length, min_length=30, do_sample=False)\n",
        "    return summary[0][\"summary_text\"]\n",
        "    \"\"\")\n",
        "\n",
        "    # Simulated output for demonstration\n",
        "    return \"NLP is a field of AI that enables computers to understand human language. It combines linguistics with machine learning models to process text or voice data, understanding meaning and intent. NLP applications include translation, voice commands, and text summarization. Recent advances in deep learning models like BERT and GPT have dramatically improved NLP capabilities.\"\n",
        "\n",
        "# Demonstrate abstractive summarization\n",
        "print(\"\\nAbstractive Summarization (simulated result):\")\n",
        "abstractive_summary = abstractive_summarize(long_article)\n",
        "print(abstractive_summary)\n",
        "\n",
        "# 4. Evaluation Metrics for Summarization\n",
        "print(\"\\nEvaluation Metrics for Text Summarization:\")\n",
        "print(\"1. ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\")\n",
        "print(\"   - ROUGE-N: Measures n-gram overlap\")\n",
        "print(\"   - ROUGE-L: Measures longest common subsequence\")\n",
        "print(\"   - ROUGE-S: Measures skip-bigram similarity\")\n",
        "print(\"2. BLEU (Bilingual Evaluation Understudy)\")\n",
        "print(\"3. BERTScore: Uses BERT embeddings to compute similarity\")\n",
        "print(\"4. Human evaluation\")\n",
        "print(\"   - Coherence: Is the summary well-structured and coherent?\")\n",
        "print(\"   - Informativeness: Does the summary contain the key information?\")\n",
        "print(\"   - Non-redundancy: Is the summary free of repetition?\")\n",
        "print(\"   - Grammaticality: Is the summary grammatically correct?\")\n",
        "\n",
        "# Example ROUGE calculation function (simplified)\n",
        "def calculate_rouge(reference, summary):\n",
        "    \"\"\"\n",
        "    Simplified ROUGE-1 calculation\n",
        "    \"\"\"\n",
        "    # Tokenize\n",
        "    ref_tokens = set(word_tokenize(reference.lower()))\n",
        "    sum_tokens = set(word_tokenize(summary.lower()))\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    ref_tokens = [token for token in ref_tokens if token not in stop_words]\n",
        "    sum_tokens = [token for token in sum_tokens if token not in stop_words]\n",
        "\n",
        "    # Calculate overlap\n",
        "    overlap = set(ref_tokens).intersection(set(sum_tokens))\n",
        "\n",
        "    # Calculate ROUGE-1 Precision, Recall, F1\n",
        "    precision = len(overlap) / len(sum_tokens) if sum_tokens else 0\n",
        "    recall = len(overlap) / len(ref_tokens) if ref_tokens else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Example reference summary\n",
        "reference_summary = \"NLP is an AI field enabling computers to understand human language by combining linguistics with machine learning. It powers translation, voice commands, and text summarization. Deep learning advances with models like BERT and GPT have significantly improved NLP capabilities.\"\n",
        "\n",
        "# Calculate ROUGE scores for our summaries\n",
        "print(\"\\nROUGE-1 Scores:\")\n",
        "print(\"TextRank Summary:\")\n",
        "textrank_rouge = calculate_rouge(reference_summary, textrank_summary)\n",
        "print(f\"Precision: {textrank_rouge['precision']:.4f}, Recall: {textrank_rouge['recall']:.4f}, F1: {textrank_rouge['f1']:.4f}\")\n",
        "\n",
        "print(\"\\nTF-IDF Summary:\")\n",
        "tfidf_rouge = calculate_rouge(reference_summary, tfidf_summary)\n",
        "print(f\"Precision: {tfidf_rouge['precision']:.4f}, Recall: {tfidf_rouge['recall']:.4f}, F1: {tfidf_rouge['f1']:.4f}\")\n",
        "\n",
        "print(\"\\nAbstractive Summary:\")\n",
        "abstractive_rouge = calculate_rouge(reference_summary, abstractive_summary)\n",
        "print(f\"Precision: {abstractive_rouge['precision']:.4f}, Recall: {abstractive_rouge['recall']:.4f}, F1: {abstractive_rouge['f1']:.4f}\")\n",
        "\n",
        "# 5. Applications of Text Summarization\n",
        "print(\"\\nPractical Applications of Text Summarization:\")\n",
        "print(\"1. News headline generation\")\n",
        "print(\"2. Document summarization for legal and medical texts\")\n",
        "print(\"3. Meeting notes summarization\")\n",
        "print(\"4. Research paper abstract generation\")\n",
        "print(\"5. Email summarization\")\n",
        "print(\"6. Product review summarization\")\n",
        "print(\"7. Content curation and recommendation\")"
      ],
      "metadata": {
        "id": "VjurLwJZk9pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Sample article\n",
        "article = \"\"\"\n",
        "Researchers have developed a new method for training language models that significantly reduces\n",
        "computational requirements. The technique, called progressive layer training, gradually unfreezes\n",
        "layers during the training process. This approach has shown to reduce training time by up to 40%\n",
        "while maintaining comparable performance to traditional methods. The research team plans to\n",
        "release their code and trained models to the public next month. This advancement could make\n",
        "large language model training more accessible to organizations with limited computational resources.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary\n",
        "summary = summarizer(article, max_length=100, min_length=30, do_sample=False)\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "id": "tSicPxX5adYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14.Neural Language Models"
      ],
      "metadata": {
        "id": "3ccLz-1GlAWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural language models predict the probability of sequences of words and form the foundation of modern NLP.\n"
      ],
      "metadata": {
        "id": "qANuGnPTlAZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15.Transformers Architecture"
      ],
      "metadata": {
        "id": "CVMvUtx8Z_1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers revolutionized NLP with their self-attention mechanism, enabling parallel processing and better handling of long-range dependencies"
      ],
      "metadata": {
        "id": "iJm4KH-0Z-SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Prepare text input\n",
        "text = \"Transformers have revolutionized NLP.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Get embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Access last hidden states (contextual embeddings)\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "print(f\"Shape of embeddings: {last_hidden_states.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "4a0f51eefb724c2b8d077545a77d531f",
            "8eafe6efba474d71a95704951812b396",
            "c30beb465bfb4119a6ce5ccad6e9f56f",
            "6c5db4199745485b95ad2b7793a73254",
            "178be97ac1ba440896ffe4ab1ec95c88",
            "91997dffee654a5cbfa8771a3ca7fb53",
            "85d9a71da21045d1aaa268bb1d1ba022",
            "9533b6d64b7748249f75e4d2f88016dc",
            "6ca349c1315c4c088399b4d344bbbb94",
            "678387969ac74d6eb61913311b025426",
            "161da51a314b46cda07c7982d44108aa",
            "4d43a9179b0847ad8f2dd07f501e8f5e",
            "3718082557eb4bf3859f570ddb235b29",
            "4296c3dd79d847309e81eaab4dc24504",
            "fe58f32dec6e4b27af4c5ebba61168d2",
            "fb24d3e6d61c4f6baf39dd076a8121f4",
            "6bdce7c39b4b4f11b3450886cd776e29",
            "63d615a7493746b0b5aac49e46a8be76",
            "ec16caab6847428082e18772873fd17b",
            "8bc410e1597241dc93263ba4045720d9",
            "d2e6190c1d17408dab0890d8ad2ec273",
            "baf8615862ad44c582490fb4477e6e6b",
            "651cbb718c8344f58f9e425fe5955d40",
            "ecc8141b6a024e75ac4889a5ac15ddc9",
            "8728c89babcc4c3abed282c25f4a9e9b",
            "9f2f9710a8b74d1daf30b3d6fc6ec43b",
            "518212e1544540018b8d95b194f12b63",
            "9abd754786ec480e97ba6310666cb9b7",
            "2c35adf2993d46cfbda586948eaef451",
            "9d115bdce45b4cdb81478548ba2cee11",
            "9fe53a91ff6b43e783fc5234694abe3c",
            "ece01ea50e64453a9de0b83d0c99ae1f",
            "1a6201620c1e45c484a42dc672a1ec85",
            "55e3c7ca003848b9b0f47533aaf3289c",
            "5aaa2cdbc4bf4c27aa472a0113e416e3",
            "fee13418ef0e44119e98a9b697a94027",
            "efbef76d769d460489c96c24b9a29da8",
            "5064dd90267047d2b4d3530dd01994f5",
            "84bdffa1aa114687ae1821fdf4ca518a",
            "e688d80695704ccaac039498ba9dc0ad",
            "631ddbbacd47431aa46ddd4ec26fb447",
            "cfc2e1a433ea405d9ef6be5a02c7f6cb",
            "0e936cf7942841c49fd99dc37b77d4a0",
            "e7536e59a715467285078e3a2218aa45",
            "cede57e90f4542e181ab6851c7c24a78",
            "885dea78b42c4e70baf727ff9466508d",
            "6e8eb45dc69b4a558dbd5af19efa6d3f",
            "d155f7d556c94f52b95f10b5df73cca5",
            "443e4601b495465ea75ad31077543257",
            "18cb025741164bfdaa4bfc61ffac5bae",
            "45dcb191bfc0452b84e58a1e747fb8c2",
            "1e4bf2ef5c9f4b6397d9205e6704d30c",
            "2577e3bc34554c1b8f4b55dacc1c03d7",
            "447a1a098f5847b28c96e1fc6e674290",
            "9f76c8ef23bc4aa4b98c6e633a949d35"
          ]
        },
        "id": "PjkKA6CUlGNa",
        "outputId": "a5242e7c-5b96-41ac-86f2-5ce8d4ea30d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a0f51eefb724c2b8d077545a77d531f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d43a9179b0847ad8f2dd07f501e8f5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "651cbb718c8344f58f9e425fe5955d40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55e3c7ca003848b9b0f47533aaf3289c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cede57e90f4542e181ab6851c7c24a78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of embeddings: torch.Size([1, 9, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning in NLP"
      ],
      "metadata": {
        "id": "U3JcMbyvaJLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning involves fine-tuning pre-trained models on specific tasks"
      ],
      "metadata": {
        "id": "X7qKGI0caMBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load IMDB dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(5000))\n",
        "test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Load model for sequence classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "# Define metric function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "kVvtIF--aNU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation"
      ],
      "metadata": {
        "id": "L_kkL2FDas7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Generate text\n",
        "prompt = \"Natural language processing is\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=100,\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.7,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "# Decode and print\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "s029InPGavPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Similarity"
      ],
      "metadata": {
        "id": "R9zPh2-HaxOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document similarity measures how closely related two texts are"
      ],
      "metadata": {
        "id": "8nI6rCoRa2F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"Machine learning models learn from data\",\n",
        "    \"Deep learning is a subset of machine learning\",\n",
        "    \"Natural language processing analyzes text\",\n",
        "    \"NLP applications include translation and summarization\",\n",
        "    \"Machine learning algorithms improve with more data\"\n",
        "]\n",
        "\n",
        "# Convert to TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Create a heatmap of similarities\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cosine_sim, annot=True, cmap='YlGnBu', xticklabels=range(1, len(documents)+1),\n",
        "            yticklabels=range(1, len(documents)+1))\n",
        "plt.title('Document Similarity Matrix')\n",
        "plt.xlabel('Document Number')\n",
        "plt.ylabel('Document Number')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1XYZnve7azr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aspect-Based Sentiment Analysis"
      ],
      "metadata": {
        "id": "Kjn3cJ9Aa5MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aspect-based sentiment analysis determines sentiment toward specific aspects in text"
      ],
      "metadata": {
        "id": "8u_Bg2rwa6CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load aspect-based sentiment analysis model\n",
        "absa = pipeline(\"text-classification\", model=\"yangheng/deberta-v3-base-absa-v1.1\")\n",
        "\n",
        "# Sample reviews\n",
        "reviews = [\n",
        "    \"The food was delicious but the service was slow.\",\n",
        "    \"The battery life on this phone is excellent, but the camera quality is disappointing.\",\n",
        "    \"The hotel room was spacious and clean, though the Wi-Fi connection was unstable.\"\n",
        "]\n",
        "\n",
        "# Extract aspects and sentiments\n",
        "def extract_aspect_sentiments(review):\n",
        "    # In real applications, you'd use a more sophisticated aspect extraction\n",
        "    # This is a simplified example\n",
        "    aspects = []\n",
        "    if \"food\" in review.lower():\n",
        "        aspects.append(\"food\")\n",
        "    if \"service\" in review.lower():\n",
        "        aspects.append(\"service\")\n",
        "    if \"battery\" in review.lower():\n",
        "        aspects.append(\"battery\")\n",
        "    if \"camera\" in review.lower():\n",
        "        aspects.append(\"camera\")\n",
        "    if \"room\" in review.lower():\n",
        "        aspects.append(\"room\")\n",
        "    if \"wi-fi\" in review.lower() or \"wifi\" in review.lower():\n",
        "        aspects.append(\"wifi\")\n",
        "\n",
        "    results = []\n",
        "    for aspect in aspects:\n",
        "        # Create targeted input for the aspect\n",
        "        input_text = f\"{review} [ASP] {aspect} [ASP]\"\n",
        "        sentiment = absa(input_text)[0]\n",
        "        results.append({\n",
        "            \"aspect\": aspect,\n",
        "            \"sentiment\": sentiment[\"label\"],\n",
        "            \"confidence\": sentiment[\"score\"]\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Process each review\n",
        "for i, review in enumerate(reviews):\n",
        "    print(f\"Review {i+1}: {review}\")\n",
        "    results = extract_aspect_sentiments(review)\n",
        "    for result in results:\n",
        "        print(f\"  Aspect: {result['aspect']}, Sentiment: {result['sentiment']}, Confidence: {result['confidence']:.4f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "NfV3A98ya6Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contextual Embeddings"
      ],
      "metadata": {
        "id": "MSH7bHs5a-jZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contextual embeddings represent words based on their context in a sentence."
      ],
      "metadata": {
        "id": "9LwM7_vVbRAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Example sentences with polysemous words\n",
        "sentences = [\n",
        "    \"The bank of the river was muddy after the rain.\",\n",
        "    \"I need to go to the bank to deposit my check.\",\n",
        "    \"The pilot had to bank the airplane to avoid the storm.\",\n",
        "    \"I will bank on your support for this project.\"\n",
        "]\n",
        "\n",
        "# Get embeddings\n",
        "embeddings = []\n",
        "for sentence in sentences:\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Use [CLS] token embedding as sentence representation\n",
        "    embeddings.append(outputs.last_hidden_state[0][0].numpy())\n",
        "\n",
        "# Reduce dimensionality for visualization\n",
        "pca = PCA(n_components=2)\n",
        "reduced_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], marker='o', s=100)\n",
        "\n",
        "# Add labels\n",
        "for i, sentence in enumerate(sentences):\n",
        "    plt.annotate(f\"Sentence {i+1}\",\n",
        "                 (reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
        "                 xytext=(5, 5),\n",
        "                 textcoords='offset points')\n",
        "\n",
        "plt.title(\"Contextual Embeddings of 'Bank' in Different Contexts\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xp86Dw0lbRUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependency Parsing"
      ],
      "metadata": {
        "id": "Y55svpCSbj_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependency parsing analyzes the grammatical structure of a sentence based on word dependencies.\n"
      ],
      "metadata": {
        "id": "fz33ISTQbkCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy import displacy\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\n",
        "    \"The cat chased the mouse.\",\n",
        "    \"Students who study regularly pass exams easily.\",\n",
        "    \"Despite the rain, the event was successful.\"\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Extract dependencies\n",
        "    dependencies = []\n",
        "    for token in doc:\n",
        "        dependencies.append({\n",
        "            \"token\": token.text,\n",
        "            \"dependency\": token.dep_,\n",
        "            \"head_token\": token.head.text,\n",
        "            \"children\": [child.text for child in token.children]\n",
        "        })\n",
        "\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    df = pd.DataFrame(dependencies)\n",
        "    print(df)\n",
        "    print()\n",
        "\n",
        "    # Visualize dependency parse tree (in a notebook environment)\n",
        "    # displacy.render(doc, style=\"dep\", jupyter=True)\n",
        "\n",
        "    # For non-notebook environment, you can save as HTML\n",
        "    html = displacy.render(doc, style=\"dep\", page=True)\n",
        "    with open(f\"dependency_parse_{sentences.index(sentence)}.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(html)"
      ],
      "metadata": {
        "id": "ku-i8kMjbmkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coreference Resolution"
      ],
      "metadata": {
        "id": "YFytG_wdbpze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coreference resolution identifies when different expressions refer to the same entity.\n"
      ],
      "metadata": {
        "id": "AEo_AgNDbp4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import neuralcoref\n",
        "import pandas as pd\n",
        "\n",
        "# Load model and add neuralcoref\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "# Example texts\n",
        "texts = [\n",
        "    \"John called Mike yesterday. He wanted to discuss the project.\",\n",
        "    \"The company released its annual report. It showed significant growth.\",\n",
        "    \"Sandra told Mary that she had won the competition.\"\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "    doc = nlp(text)\n",
        "\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Coreferences: {doc._.coref_clusters}\")\n",
        "\n",
        "    # Show resolved text\n",
        "    print(f\"Resolved: {doc._.coref_resolved}\")\n",
        "    print()\n",
        "\n",
        "    # Extract all mentions and their references\n",
        "    if doc._.coref_clusters:\n",
        "        mentions = []\n",
        "        for cluster in doc._.coref_clusters:\n",
        "            main_mention = cluster.main.text\n",
        "            for mention in cluster.mentions:\n",
        "                mentions.append({\n",
        "                    \"mention\": mention.text,\n",
        "                    \"refers_to\": main_mention,\n",
        "                    \"start\": mention.start,\n",
        "                    \"end\": mention.end\n",
        "                })\n",
        "\n",
        "        print(pd.DataFrame(mentions))\n",
        "        print()"
      ],
      "metadata": {
        "id": "KXcxG-XobtYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Readability Analysis"
      ],
      "metadata": {
        "id": "KmHRoLALbvDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text readability analysis evaluates how easy or difficult a text is to read"
      ],
      "metadata": {
        "id": "oagrPBd0bvHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textstat\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example texts of varying complexity\n",
        "texts = [\n",
        "    \"The cat sat on the mat. It was happy.\",\n",
        "    \"The cardiovascular system consists of the heart, blood vessels, and blood. Its primary function is to transport oxygen, nutrients, hormones, and cellular waste products throughout the body.\",\n",
        "    \"Quantum mechanics is a fundamental theory in physics that provides a description of the physical properties of nature at the scale of atoms and subatomic particles. It is the foundation of all quantum physics including quantum chemistry, quantum field theory, quantum technology, and quantum information science.\"\n",
        "]\n",
        "\n",
        "# Calculate readability metrics\n",
        "results = []\n",
        "for i, text in enumerate(texts):\n",
        "    result = {\n",
        "        \"text_id\": i+1,\n",
        "        \"flesch_reading_ease\": textstat.flesch_reading_ease(text),\n",
        "        \"flesch_kincaid_grade\": textstat.flesch_kincaid_grade(text),\n",
        "        \"gunning_fog\": textstat.gunning_fog(text),\n",
        "        \"smog_index\": textstat.smog_index(text),\n",
        "        \"coleman_liau_index\": textstat.coleman_liau_index(text),\n",
        "        \"automated_readability_index\": textstat.automated_readability_index(text),\n",
        "        \"dale_chall_readability_score\": textstat.dale_chall_readability_score(text),\n",
        "        \"syllable_count\": textstat.syllable_count(text),\n",
        "        \"lexicon_count\": textstat.lexicon_count(text),\n",
        "        \"sentence_count\": textstat.sentence_count(text),\n",
        "        \"avg_sentence_length\": textstat.avg_sentence_length(text),\n",
        "        \"avg_syllables_per_word\": textstat.avg_syllables_per_word(text),\n",
        "    }\n",
        "    results.append(result)\n",
        "\n",
        "# Display results\n",
        "df = pd.DataFrame(results)\n",
        "print(df[[\"text_id\", \"flesch_reading_ease\", \"flesch_kincaid_grade\", \"gunning_fog\"]])\n",
        "\n",
        "# Plot readability scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics = [\"flesch_reading_ease\", \"flesch_kincaid_grade\", \"gunning_fog\",\n",
        "           \"smog_index\", \"coleman_liau_index\", \"automated_readability_index\"]\n",
        "\n",
        "for i, text_id in enumerate(df[\"text_id\"]):\n",
        "    plt.plot(metrics, df.loc[df[\"text_id\"] == text_id, metrics].values[0], marker='o', label=f\"Text {text_id}\")\n",
        "\n",
        "plt.xlabel(\"Readability Metrics\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Readability Scores Comparison\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7yczvUIgbzR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Summarization with Extractive Methods"
      ],
      "metadata": {
        "id": "qrQopc6eb1S3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extractive summarization identifies and extracts important sentences from the original text"
      ],
      "metadata": {
        "id": "Phu6IMueb20K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def get_sentence_embeddings(sentences, model, tokenizer):\n",
        "    embeddings = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use mean pooling to get sentence embedding\n",
        "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
        "\n",
        "    return np.array(embeddings)\n",
        "\n",
        "def textrank_summarize(text, num_sentences=3):\n",
        "    # Load models\n",
        "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "    model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    if len(sentences) <= num_sentences:\n",
        "        return text\n",
        "\n",
        "    # Get sentence embeddings\n",
        "    embeddings = get_sentence_embeddings(sentences, model, tokenizer)\n",
        "\n",
        "    # Calculate similarity matrix\n",
        "    sim_matrix = cosine_similarity(embeddings)\n",
        "\n",
        "    # Create graph and apply PageRank\n",
        "    nx_graph = nx.from_numpy_array(sim_matrix)\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "\n",
        "    # Get top sentences\n",
        "    ranked_sentences = sorted(((scores[i], i, s) for i, s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "    # Sort selected sentences by original position\n",
        "    selected_indices = [item[1] for item in ranked_sentences[:num_sentences]]\n",
        "    selected_indices.sort()\n",
        "\n",
        "    # Join selected sentences\n",
        "    summary = ' '.join([sentences[i] for i in selected_indices])\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Example text for summarization\n",
        "article = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
        "The ultimate goal of NLP is to enable computers to understand, interpret, and generate human language in a valuable way.\n",
        "NLP has many applications, including machine translation, sentiment analysis, speech recognition, and question answering systems.\n",
        "Modern NLP techniques rely heavily on machine learning, especially deep learning models like transformers.\n",
        "Transfer learning has revolutionized NLP by allowing researchers to fine-tune pre-trained models for specific tasks.\n",
        "BERT, GPT, and other transformer-based models have achieved state-of-the-art results on various NLP benchmarks.\n",
        "Despite significant progress, NLP still faces challenges such as understanding context, sarcasm, and ambiguity in language.\n",
        "The field continues to evolve rapidly, with new models and techniques being developed to address these challenges.\n",
        "Multimodal learning, which combines text with other data types like images and audio, is an emerging trend in NLP research.\n",
        "As NLP technologies improve, they are becoming increasingly integrated into our daily lives through virtual assistants, chatbots, and other applications.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary\n",
        "summary = textrank_summarize(article, num_sentences=3)\n",
        "print(\"Original article length:\", len(article.split()))\n",
        "print(\"Summary length:\", len(summary.split()))\n",
        "print(\"\\nSummary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "BrJ6HKDUb3Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language Detection"
      ],
      "metadata": {
        "id": "Bap0viR2b9E8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language detection identifies the language of a given text.\n"
      ],
      "metadata": {
        "id": "PiWGHxOMb-ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langdetect import detect, DetectorFactory\n",
        "from langcodes import Language\n",
        "\n",
        "# Set seed for consistent results\n",
        "DetectorFactory.seed = 42\n",
        "\n",
        "# Sample texts in different languages\n",
        "texts = [\n",
        "    \"Natural language processing is a field of artificial intelligence.\",  # English\n",
        "    \"Le traitement du langage naturel est un domaine de l'intelligence artificielle.\",  # French\n",
        "    \"El procesamiento del lenguaje natural es un campo de la inteligencia artificial.\",  # Spanish\n",
        "    \"Die Verarbeitung natürlicher Sprache ist ein Teilgebiet der künstlichen Intelligenz.\",  # German\n",
        "    \"自然言語処理は人工知能の分野です。\",  # Japanese\n",
        "    \"自然语言处理是人工智能的一个领域。\",  # Chinese\n",
        "    \"Обработка естественного языка — это область искусственного интеллекта.\"  # Russian\n",
        "]\n",
        "\n",
        "# Detect languages\n",
        "results = []\n",
        "for text in texts:\n",
        "    try:\n",
        "        lang_code = detect(text)\n",
        "        lang_name = Language.make(language=lang_code).display_name()\n",
        "        confidence = 'N/A'  # langdetect doesn't provide confidence scores directly\n",
        "    except:\n",
        "        lang_code = 'unknown'\n",
        "        lang_name = 'Unknown'\n",
        "        confidence = 'N/A'\n",
        "\n",
        "    results.append({\n",
        "        'text': text[:50] + '...' if len(text) > 50 else text,\n",
        "        'language_code': lang_code,\n",
        "        'language_name': lang_name,\n",
        "        'confidence': confidence\n",
        "    })\n",
        "\n",
        "# Display results\n",
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "gZl8xramb_w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Augmentation"
      ],
      "metadata": {
        "id": "ZWfdGzjgcCcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text augmentation generates variations of existing text data to expand training datasets."
      ],
      "metadata": {
        "id": "UYqjsArXcDE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.char as nac\n",
        "import pandas as pd\n",
        "\n",
        "# Original sentences\n",
        "sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Natural language processing is fascinating.\",\n",
        "    \"Deep learning models require large amounts of data.\"\n",
        "]\n",
        "\n",
        "# Initialize augmenters\n",
        "synonym_aug = naw.SynonymAug(aug_src='wordnet')\n",
        "insert_aug = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action=\"insert\")\n",
        "swap_aug = naw.RandomWordAug(action=\"swap\")\n",
        "delete_aug = naw.RandomWordAug(action=\"delete\")\n",
        "spelling_aug = nac.KeyboardAug()\n",
        "\n",
        "# Apply augmentations\n",
        "results = []\n",
        "for sentence in sentences:\n",
        "    augmented = {\n",
        "        'original': sentence,\n",
        "        'synonym_replace': synonym_aug.augment(sentence)[0],\n",
        "        'word_insert': insert_aug.augment(sentence)[0],\n",
        "        'word_swap': swap_aug.augment(sentence)[0],\n",
        "        'word_delete': delete_aug.augment(sentence)[0],\n",
        "        'spelling_error': spelling_aug.augment(sentence)[0]\n",
        "    }\n",
        "    results.append(augmented)\n",
        "\n",
        "# Display results\n",
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "kUmzBI9ucEmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Label Text Classification"
      ],
      "metadata": {
        "id": "i3HQwGZ7cHVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-label classification assigns multiple categories to a single document"
      ],
      "metadata": {
        "id": "-U-Nj-7tcHz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, hamming_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate sample dataset\n",
        "texts = [\n",
        "    \"The movie had great acting but poor special effects\",\n",
        "    \"The camera and battery life of this phone are excellent\",\n",
        "    \"The hotel had a beautiful view and friendly staff\",\n",
        "    \"The restaurant's food was delicious but the service was terrible\",\n",
        "    \"The laptop has a fast processor but short battery life\",\n",
        "    \"The car has good fuel economy and excellent handling\",\n",
        "    \"The book had an engaging plot but weak character development\",\n",
        "    \"The concert venue had great acoustics but uncomfortable seating\",\n",
        "    \"The smartphone has a stunning display and impressive camera\",\n",
        "    \"The coffee shop has delicious pastries and a cozy atmosphere\",\n",
        "    \"The gym has modern equipment but limited space\",\n",
        "    \"The hiking trail offers beautiful views and challenging terrain\",\n",
        "    \"The app has an intuitive interface but frequent crashes\",\n",
        "    \"The headphones have excellent sound quality but poor comfort\",\n",
        "    \"The smartwatch has accurate fitness tracking and long battery life\"\n",
        "]\n",
        "\n",
        "# Create multi-label dataset with 4 categories: Product, Service, Location, Entertainment\n",
        "# 1 indicates presence of the category\n",
        "labels = np.array([\n",
        "    [0, 1, 0, 1],  # movie: service, entertainment\n",
        "    [1, 0, 0, 0],  # phone: product\n",
        "    [0, 1, 1, 0],  # hotel: service, location\n",
        "    [0, 1, 1, 0],  # restaurant: service, location\n",
        "    [1, 0, 0, 0],  # laptop: product\n",
        "    [1, 0, 0, 0],  # car: product\n",
        "    [0, 0, 0, 1],  # book: entertainment\n",
        "    [0, 0, 1, 1],  # concert venue: location, entertainment\n",
        "    [1, 0, 0, 0],  # smartphone: product\n",
        "    [0, 1, 1, 0],  # coffee shop: service, location\n",
        "    [0, 0, 1, 0],  # gym: location\n",
        "    [0, 0, 1, 0],  # hiking trail: location\n",
        "    [1, 0, 0, 0],  # app: product\n",
        "    [1, 0, 0, 0],  # headphones: product\n",
        "    [1, 0, 0, 0]   # smartwatch: product\n",
        "])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert text to features\n",
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train multi-label classifier\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "multi_target_forest = MultiOutputClassifier(forest)\n",
        "multi_target_forest.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = multi_target_forest.predict(X_test_vec)\n",
        "\n",
        "print(\"Hamming loss:\", hamming_loss(y_test, y_pred))\n",
        "print(\"\\nClassification report:\")\n",
        "\n",
        "# Categories\n",
        "categories = ['Product', 'Service', 'Location', 'Entertainment']\n",
        "\n",
        "# Per-class evaluation\n",
        "for i, category in enumerate(categories):\n",
        "    print(f\"\\nCategory: {category}\")\n",
        "    print(classification_report(y_test[:, i], y_pred[:, i], zero_division=0))\n",
        "\n",
        "# Predict new examples\n",
        "new_texts = [\n",
        "    \"This new tablet has a fast processor and beautiful display\",\n",
        "    \"The resort had amazing views and exceptional dining options\",\n",
        "    \"The movie had an excellent plot and outstanding performances\"\n",
        "]\n",
        "\n",
        "new_X_vec = vectorizer.transform(new_texts)\n",
        "new_predictions = multi_target_forest.predict(new_X_vec)\n",
        "\n",
        "# Display predictions\n",
        "for text, pred in zip(new_texts, new_predictions):\n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(\"Categories:\", [categories[i] for i in range(len(categories)) if pred[i] == 1])"
      ],
      "metadata": {
        "id": "Yj6SWfZ8cJMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keyword Extraction"
      ],
      "metadata": {
        "id": "NXCNlwiZcMu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keyword extraction identifies the most important terms in a document"
      ],
      "metadata": {
        "id": "w2fEXbubcOLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
        "    between computers and humans through natural language. The ultimate goal of NLP is to enable computers\n",
        "    to understand, interpret, and generate human language in a valuable way.\"\"\",\n",
        "\n",
        "    \"\"\"Machine learning is an application of artificial intelligence that provides systems the ability\n",
        "    to automatically learn and improve from experience without being explicitly programmed.\n",
        "    Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.\"\"\",\n",
        "\n",
        "    \"\"\"Computer vision is a field of artificial intelligence that trains computers to interpret and understand\n",
        "    the visual world. Using digital images from cameras and videos and deep learning models,\n",
        "    machines can accurately identify and classify objects and react to what they \"see\".\"\"\"\n",
        "]\n",
        "\n",
        "# Method 1: YAKE\n",
        "def extract_keywords_yake(text, num_keywords=5):\n",
        "    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=2, dedupLim=0.9, dedupFunc='seqm', windowsSize=1, top=num_keywords)\n",
        "    keywords = kw_extractor.extract_keywords(text)\n",
        "    return [(kw[0], round(1-kw[1], 3)) for kw in keywords]  # Convert score for readability\n",
        "\n",
        "# Method 2: TF-IDF\n",
        "def extract_keywords_tfidf(documents, num_keywords=5):\n",
        "    vectorizer = TfidfVectorizer(max_features=500, stop_words='english')\n",
        "    X = vectorizer.fit_transform(documents)\n",
        "\n",
        "    # Get feature names\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    keywords_by_doc = []\n",
        "    for i in range(len(documents)):\n",
        "        # Get TF-IDF scores for this document\n",
        "        tfidf_scores = X[i].toarray()[0]\n",
        "\n",
        "        # Create (word, score) pairs and sort by score\n",
        "        word_scores = [(feature_names[j], tfidf_scores[j]) for j in range(len(feature_names)) if tfidf_scores[j] > 0]\n",
        "        word_scores = sorted(word_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Get top keywords\n",
        "        keywords_by_doc.append(word_scores[:num_keywords])\n",
        "\n",
        "    return keywords_by_doc\n",
        "\n",
        "# Method 3: TextRank-inspired (simplified)\n",
        "def extract_keywords_textrank(text, num_keywords=5):\n",
        "    # Preprocess\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    punctuation = set(string.punctuation)\n",
        "\n",
        "    # Tokenize and filter\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words and word not in punctuation and len(word) > 1]\n",
        "\n",
        "    # Create co-occurrence matrix (window size = 2)\n",
        "    word_index = {word: i for i, word in enumerate(set(filtered_tokens))}\n",
        "    index_word = {i: word for word, i in word_index.items()}\n",
        "    n = len(word_index)\n",
        "    matrix = np.zeros((n, n))\n",
        "\n",
        "    window_size = 2\n",
        "    for i in range(len(filtered_tokens)):\n",
        "        for j in range(i+1, min(i+window_size+1, len(filtered_tokens))):\n",
        "            if filtered_tokens[i] in word_index and filtered_tokens[j] in word_index:\n",
        "                idx1 = word_index[filtered_tokens[i]]\n",
        "                idx2 = word_index[filtered_tokens[j]]\n",
        "                matrix[idx1][idx2] += 1\n",
        "                matrix[idx2][idx1] += 1  # Symmetric\n",
        "\n",
        "    # Apply PageRank\n",
        "    nx_graph = nx.from_numpy_array(matrix)\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "\n",
        "    # Convert scores to (word, score) pairs and sort\n",
        "    word_scores = [(index_word[idx], score) for idx, score in scores.items()]\n",
        "    word_scores = sorted(word_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return word_scores[:num_keywords]\n",
        "\n",
        "# Extract keywords using different methods\n",
        "results = []\n",
        "for i, doc in enumerate(documents):\n",
        "    doc_results = {\n",
        "        \"document_id\": i+1,\n",
        "        \"document_preview\": doc[:100] + \"...\",\n",
        "        \"yake_keywords\": extract_keywords_yake(doc),\n",
        "        \"textrank_keywords\": extract_keywords_textrank(doc)\n",
        "    }\n",
        "    results.append(doc_results)\n",
        "\n",
        "# Add TF-IDF results\n",
        "tfidf_keywords = extract_keywords_tfidf(documents)\n",
        "for i in range(len(results)):\n",
        "    results[i][\"tfidf_keywords\"] = tfidf_keywords[i]\n",
        "\n",
        "# Display results\n",
        "for result in results:\n",
        "    print(f\"Document {result['document_id']}: {result['document_preview']}\")\n",
        "    print(\"YAKE keywords:\", result['yake_keywords'])\n",
        "    print(\"TF-IDF keywords:\", result['tfidf_keywords'])\n",
        "    print(\"TextRank keywords:\", result['textrank_keywords'])\n",
        "    print()"
      ],
      "metadata": {
        "id": "WfrpAgzKcPVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-Lingual Transfer Learning"
      ],
      "metadata": {
        "id": "yLbpRwRKcRQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-lingual transfer learning leverages knowledge from one language to improve performance in another language"
      ],
      "metadata": {
        "id": "jzKz9QaTcTVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load multilingual BERT model and tokenizer\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Load English sentiment dataset for training\n",
        "dataset = load_dataset(\"imdb\", split=\"train\").shuffle(seed=42).select(range(2000))\n",
        "test_dataset = load_dataset(\"imdb\", split=\"test\").shuffle(seed=42).select(range(500))\n",
        "\n",
        "# Tokenize English data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Prepare Spanish test examples (small sample for illustration)\n",
        "spanish_texts = [\n",
        "    \"Esta película fue maravillosa. Me encantó cada momento.\",  # Positive\n",
        "    \"El actor principal fue excelente en su papel.\",  # Positive\n",
        "    \"Esta película fue terrible. No me gustó nada.\",  # Negative\n",
        "    \"La trama fue aburrida y los personajes mal desarrollados.\"  # Negative\n",
        "]\n",
        "spanish_labels = [1, 1, 0, 0]  # 1 for positive, 0 for negative\n",
        "\n",
        "# Tokenize Spanish texts\n",
        "spanish_encodings = tokenizer(spanish_texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "spanish_dataset = {\n",
        "    \"input_ids\": spanish_encodings[\"input_ids\"],\n",
        "    \"attention_mask\": spanish_encodings[\"attention_mask\"],\n",
        "    \"labels\": spanish_labels\n",
        "}\n",
        "\n",
        "# Define evaluation function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Setup training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Fine-tune model on English data\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on English test set\n",
        "english_results = trainer.evaluate()\n",
        "print(\"English evaluation results:\", english_results)\n",
        "\n",
        "# Evaluate on Spanish examples (zero-shot cross-lingual transfer)\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Create Spanish dataset\n",
        "spanish_eval_dataset = SimpleDataset(\n",
        "    {\"input_ids\": spanish_encodings[\"input_ids\"],\n",
        "     \"attention_mask\": spanish_encodings[\"attention_mask\"]},\n",
        "    spanish_labels\n",
        ")\n",
        "\n",
        "# Evaluate on Spanish data\n",
        "spanish_trainer = Trainer(\n",
        "    model=model,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "spanish_results = spanish_trainer.evaluate(spanish_eval_dataset)\n",
        "print(\"Spanish evaluation results (zero-shot transfer):\", spanish_results)"
      ],
      "metadata": {
        "id": "8Hr7j0RAcTh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Style Transfer"
      ],
      "metadata": {
        "id": "X29hOnCYcXkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text style transfer transforms text from one style (formal, informal, etc.) to another while preserving content.\n"
      ],
      "metadata": {
        "id": "WSlUAY5jcZNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "\n",
        "# Example function for simple formality transfer using T5\n",
        "def transfer_formality(text, target_style):\n",
        "    prefix = f\"transfer to {target_style}: \"\n",
        "    input_text = prefix + text\n",
        "\n",
        "    # Tokenize and generate\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_length=150,\n",
        "        num_beams=5,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Decode output\n",
        "    transferred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return transferred_text\n",
        "\n",
        "# Example texts\n",
        "texts = [\n",
        "    \"Hey what's up? Can u help me with this problem?\",\n",
        "    \"I ain't got no time for this stuff!\",\n",
        "    \"Dear Sir/Madam, I am writing to express my sincere gratitude.\",\n",
        "    \"The aforementioned document requires your immediate attention.\"\n",
        "]\n",
        "\n",
        "# Transfer examples\n",
        "results = []\n",
        "for text in texts:\n",
        "    formal = transfer_formality(text, \"formal\")\n",
        "    informal = transfer_formality(text, \"informal\")\n",
        "\n",
        "    results.append({\n",
        "        \"original\": text,\n",
        "        \"to_formal\": formal,\n",
        "        \"to_informal\": informal\n",
        "    })\n",
        "\n",
        "# Display results\n",
        "for result in results:\n",
        "    print(f\"Original: {result['original']}\")\n",
        "    print(f\"Formal: {result['to_formal']}\")\n",
        "    print(f\"Informal: {result['to_informal']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "BQUEpDK9caWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Graphs from Text"
      ],
      "metadata": {
        "id": "tFmT0s0-ccIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge graphs extract structured relationships from unstructured text"
      ],
      "metadata": {
        "id": "mTxqAbYGccse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Example texts about technology companies\n",
        "texts = [\n",
        "    \"Microsoft was founded by Bill Gates and Paul Allen in 1975. The company is headquartered in Redmond, Washington.\",\n",
        "    \"Apple Inc. was established by Steve Jobs, Steve Wozniak, and Ronald Wayne in 1976. Apple is based in Cupertino, California.\",\n",
        "    \"Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.\",\n",
        "    \"Facebook was created by Mark Zuckerberg at Harvard University in 2004. The company is headquartered in Menlo Park, California.\"\n",
        "]\n",
        "\n",
        "# Extract entities and relationships\n",
        "def extract_relations(texts):\n",
        "    relations = []\n",
        "\n",
        "    for text in texts:\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Extract named entities\n",
        "        entities = {ent.text: ent.label_ for ent in doc.ents}\n",
        "\n",
        "        # Extract subject-verb-object triples\n",
        "        for sent in doc.sents:\n",
        "            for token in sent:\n",
        "                if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
        "                    subject = token.text\n",
        "                    verb = token.head.text\n",
        "\n",
        "                    # Find objects of the verb\n",
        "                    for child in token.head.children:\n",
        "                        if child.dep_ in [\"dobj\", \"pobj\", \"attr\"]:\n",
        "                            obj = child.text\n",
        "\n",
        "                            # Add the triple\n",
        "                            relations.append({\n",
        "                                \"subject\": subject,\n",
        "                                \"predicate\": verb,\n",
        "                                \"object\": obj,\n",
        "                                \"sentence\": sent.text\n",
        "                            })\n",
        "\n",
        "        # Extract special relationships like founded_by, based_in\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == \"ORG\":  # Organization\n",
        "                org = ent.text\n",
        "\n",
        "                # Look for founders\n",
        "                if \"found\" in text.lower() or \"establish\" in text.lower() or \"creat\" in text.lower():\n",
        "                    for person_ent in doc.ents:\n",
        "                        if person_ent.label_ == \"PERSON\" and person_ent.text != org:\n",
        "                            relations.append({\n",
        "                                \"subject\": org,\n",
        "                                \"predicate\": \"founded_by\",\n",
        "                                \"object\": person_ent.text,\n",
        "                                \"sentence\": text\n",
        "                            })\n",
        "\n",
        "                # Look for locations (headquarters)\n",
        "                if \"headquarter\" in text.lower() or \"based in\" in text.lower():\n",
        "                    for loc_ent in doc.ents:\n",
        "                        if loc_ent.label_ in [\"GPE\", \"LOC\"] and loc_ent.text != org:\n",
        "                            relations.append({\n",
        "                                \"subject\": org,\n",
        "                                \"predicate\": \"headquartered_in\",\n",
        "                                \"object\": loc_ent.text,\n",
        "                                \"sentence\": text\n",
        "                            })\n",
        "\n",
        "    return relations\n",
        "\n",
        "# Extract relations from texts\n",
        "relations = extract_relations(texts)\n",
        "\n",
        "# Create a knowledge graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add edges to the graph\n",
        "for relation in relations:\n",
        "    G.add_edge(relation[\"subject\"], relation[\"object\"], label=relation[\"predicate\"])\n",
        "\n",
        "# Display the relations\n",
        "df = pd.DataFrame(relations)\n",
        "print(df)\n",
        "\n",
        "# Visualize the knowledge graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "\n",
        "\n",
        "# Draw nodes and edges\n",
        "nx.draw(G, pos, with_labels=True, node_color=\"skyblue\", node_size=2000, font_size=10, font_weight=\"bold\")\n",
        "\n",
        "# Draw edge labels\n",
        "edge_labels = {(u, v): d[\"label\"] for u, v, d in G.edges(data=True)}\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "\n",
        "plt.title(\"Knowledge Graph of Tech Companies\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0QYybwInceSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic Role Labeling"
      ],
      "metadata": {
        "id": "0dfH0xwTcq3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Role Labeling (SRL) identifies the semantic relationships between predicates and arguments in sentences."
      ],
      "metadata": {
        "id": "EOglOYb1csgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import framenet as fn\n",
        "import spacy\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('framenet_v17')\n",
        "\n",
        "# Load AllenNLP SRL predictor\n",
        "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n",
        "\n",
        "# Example sentences\n",
        "sentences = [\n",
        "    \"The chef cooked the pasta for dinner.\",\n",
        "    \"The scientist discovered a new species in the rainforest.\",\n",
        "    \"The company donated $5,000 to the local charity.\"\n",
        "]\n",
        "\n",
        "# Apply SRL to each sentence\n",
        "for sentence in sentences:\n",
        "    result = predictor.predict(sentence=sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "\n",
        "    # Print the verb and its arguments\n",
        "    verbs = result.get(\"verbs\", [])\n",
        "    for verb_info in verbs:\n",
        "        print(f\"Verb: {verb_info['verb']}\")\n",
        "        print(f\"Tagged: {verb_info['description']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "-uFKZP7kcto5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emotion Detection\n"
      ],
      "metadata": {
        "id": "zCWvyrLDcvxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion detection identifies emotional states expressed in text"
      ],
      "metadata": {
        "id": "y4H-AEP7cwVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load emotion classifier\n",
        "emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n",
        "\n",
        "# Example sentences with different emotions\n",
        "sentences = [\n",
        "    \"I'm so happy to see you after all these years!\",\n",
        "    \"I'm completely devastated by the news of the accident.\",\n",
        "    \"The constant delays at the airport made me furious.\",\n",
        "    \"I was terrified when I heard the strange noise at night.\",\n",
        "    \"I'm feeling anxious about the upcoming presentation.\",\n",
        "    \"The movie left me surprised with its unexpected twist.\",\n",
        "    \"I feel disgusted by the way they treated their employees.\"\n",
        "]\n",
        "\n",
        "# Classify emotions\n",
        "results = []\n",
        "for sentence in sentences:\n",
        "    emotion = emotion_classifier(sentence)[0]\n",
        "    results.append({\n",
        "        \"text\": sentence,\n",
        "        \"emotion\": emotion[\"label\"],\n",
        "        \"score\": emotion[\"score\"]\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "print(df)\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = plt.cm.tab10(range(len(sentences)))\n",
        "\n",
        "df_sorted = df.sort_values(\"score\", ascending=False)\n",
        "plt.barh(df_sorted[\"text\"], df_sorted[\"score\"], color=colors)\n",
        "plt.xlabel(\"Confidence Score\")\n",
        "plt.ylabel(\"Text\")\n",
        "plt.title(\"Emotion Detection Results\")\n",
        "\n",
        "# Add emotion labels to bars\n",
        "for i, emotion in enumerate(df_sorted[\"emotion\"]):\n",
        "    plt.text(0.01, i, f\" {emotion}\", va=\"center\", fontweight=\"bold\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fy-r7xb7cxgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aspect-Based Sentiment Analysis with Fine-Tuning\n"
      ],
      "metadata": {
        "id": "FDUOiwUoc0Qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how to fine-tune a model for aspect-based sentiment analysis"
      ],
      "metadata": {
        "id": "0R6Gi9Lhc0vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "# Create synthetic dataset for aspect-based sentiment analysis\n",
        "data = [\n",
        "    {\"text\": \"The food was delicious but the service was slow.\",\n",
        "     \"aspect\": \"food\", \"sentiment\": \"positive\"},\n",
        "    {\"text\": \"The food was delicious but the service was slow.\",\n",
        "     \"aspect\": \"service\", \"sentiment\": \"negative\"},\n",
        "    {\"text\": \"The camera quality is excellent but the battery life is terrible.\",\n",
        "     \"aspect\": \"camera\", \"sentiment\": \"positive\"},\n",
        "    {\"text\": \"The camera quality is excellent but the battery life is terrible.\",\n",
        "     \"aspect\": \"battery\", \"sentiment\": \"negative\"},\n",
        "    {\"text\": \"The room was spacious but the Wi-Fi connection was unstable.\",\n",
        "     \"aspect\": \"room\", \"sentiment\": \"positive\"},\n",
        "    {\"text\": \"The room was spacious but the Wi-Fi connection was unstable.\",\n",
        "     \"aspect\": \"Wi-Fi\", \"sentiment\": \"negative\"},\n",
        "    # Add more examples here\n",
        "]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create labels\n",
        "sentiment_map = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
        "df[\"label\"] = df[\"sentiment\"].map(sentiment_map)\n",
        "\n",
        "# Prepare input format: \"text [SEP] aspect\"\n",
        "df[\"input_text\"] = df[\"text\"] + \" [SEP] \" + df[\"aspect\"]\n",
        "\n",
        "# Split data\n",
        "train_df, eval_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "eval_dataset = Dataset.from_pandas(eval_df)\n",
        "\n",
        "# Load tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize datasets\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"input_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n",
        "# Define metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = (predictions == labels).mean()\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./absa_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Fine-tune model\n",
        "trainer.train()\n",
        "\n",
        "# Test on new examples\n",
        "new_examples = [\n",
        "    {\"text\": \"The screen resolution is amazing but the price is too high.\", \"aspect\": \"screen\"},\n",
        "    {\"text\": \"The screen resolution is amazing but the price is too high.\", \"aspect\": \"price\"},\n",
        "    {\"text\": \"The hotel location was perfect for sightseeing but the breakfast was mediocre.\", \"aspect\": \"location\"},\n",
        "    {\"text\": \"The hotel location was perfect for sightseeing but the breakfast was mediocre.\", \"aspect\": \"breakfast\"}\n",
        "]\n",
        "\n",
        "# Process new examples\n",
        "for ex in new_examples:\n",
        "    input_text = ex[\"text\"] + \" [SEP] \" + ex[\"aspect\"]\n",
        "    encoded_input = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_input)\n",
        "        predictions = torch.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "\n",
        "    sentiment_labels = {0: \"positive\", 1: \"neutral\", 2: \"negative\"}\n",
        "    print(f\"Text: {ex['text']}\")\n",
        "    print(f\"Aspect: {ex['aspect']}\")\n",
        "    print(f\"Predicted sentiment: {sentiment_labels[predicted_class]}\")\n",
        "    print(f\"Confidence: {predictions[0][predicted_class].item():.4f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "myC_OjX8c2MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Clustering"
      ],
      "metadata": {
        "id": "iPKJsgOSc9IG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text clustering groups similar documents together based on their content"
      ],
      "metadata": {
        "id": "Rp9cs1TJdBI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example document collection\n",
        "documents = [\n",
        "    # Technology\n",
        "    \"Machine learning models require large amounts of training data.\",\n",
        "    \"Neural networks have revolutionized computer vision tasks.\",\n",
        "    \"Cloud computing enables scalable and flexible IT infrastructure.\",\n",
        "    \"Quantum computing promises to solve complex problems efficiently.\",\n",
        "    \"Blockchain technology ensures transparent and secure transactions.\",\n",
        "\n",
        "    # Health\n",
        "    \"Regular exercise reduces the risk of cardiovascular disease.\",\n",
        "    \"A balanced diet is essential for maintaining good health.\",\n",
        "    \"Adequate sleep is crucial for mental and physical wellbeing.\",\n",
        "    \"Vaccines help prevent the spread of infectious diseases.\",\n",
        "    \"Stress management techniques improve overall health outcomes.\",\n",
        "\n",
        "    # Environment\n",
        "    \"Renewable energy sources reduce carbon emissions significantly.\",\n",
        "    \"Climate change poses serious threats to global ecosystems.\",\n",
        "    \"Sustainable agriculture practices preserve soil quality.\",\n",
        "    \"Ocean pollution endangers marine biodiversity worldwide.\",\n",
        "    \"Deforestation contributes to habitat loss and species extinction.\"\n",
        "]\n",
        "\n",
        "# Extract features using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Apply K-Means clustering\n",
        "n_clusters = 3\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans_labels = kmeans.fit_predict(X)\n",
        "\n",
        "# Apply DBSCAN clustering\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
        "dbscan_labels = dbscan.fit_predict(X)\n",
        "\n",
        "# Dimensionality reduction for visualization\n",
        "pca = PCA(n_components=2)\n",
        "X_dense = X.toarray()\n",
        "X_pca = pca.fit_transform(X_dense)\n",
        "\n",
        "# t-SNE for better visualization\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "X_tsne = tsne.fit_transform(X_dense)\n",
        "\n",
        "# Create DataFrame with results\n",
        "df = pd.DataFrame({\n",
        "    'document': documents,\n",
        "    'kmeans_cluster': kmeans_labels,\n",
        "    'dbscan_cluster': dbscan_labels,\n",
        "    'pca_x': X_pca[:, 0],\n",
        "    'pca_y': X_pca[:, 1],\n",
        "    'tsne_x': X_tsne[:, 0],\n",
        "    'tsne_y': X_tsne[:, 1]\n",
        "})\n",
        "\n",
        "# Print cluster assignments\n",
        "print(\"K-Means Clustering Results:\")\n",
        "for cluster in range(n_clusters):\n",
        "    print(f\"\\nCluster {cluster}:\")\n",
        "    cluster_docs = df[df['kmeans_cluster'] == cluster]['document'].values\n",
        "    for doc in cluster_docs:\n",
        "        print(f\"- {doc}\")\n",
        "\n",
        "# Visualize clusters with PCA\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# K-Means with PCA\n",
        "plt.subplot(1, 2, 1)\n",
        "for cluster in range(n_clusters):\n",
        "    cluster_data = df[df['kmeans_cluster'] == cluster]\n",
        "    plt.scatter(cluster_data['pca_x'], cluster_data['pca_y'], label=f'Cluster {cluster}')\n",
        "\n",
        "plt.title('Document Clustering with K-Means and PCA')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "\n",
        "# K-Means with t-SNE\n",
        "plt.subplot(1, 2, 2)\n",
        "for cluster in range(n_clusters):\n",
        "    cluster_data = df[df['kmeans_cluster'] == cluster]\n",
        "    plt.scatter(cluster_data['tsne_x'], cluster_data['tsne_y'], label=f'Cluster {cluster}')\n",
        "\n",
        "plt.title('Document Clustering with K-Means and t-SNE')\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "czF-oKT1dCI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Coherence Evaluation"
      ],
      "metadata": {
        "id": "zrGV6B92dEQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text coherence evaluation assesses how well the sentences in a text connect and flow together.\n"
      ],
      "metadata": {
        "id": "FRDwmR5PdEtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Example texts with different coherence levels\n",
        "texts = [\n",
        "    # High coherence\n",
        "    \"\"\"Climate change is a major global challenge. Rising temperatures are causing ice caps to melt.\n",
        "    This melting leads to rising sea levels, which threaten coastal communities worldwide.\n",
        "    Scientists agree that reducing carbon emissions is essential to address this issue.\"\"\",\n",
        "\n",
        "    # Medium coherence\n",
        "    \"\"\"Climate change is a major global challenge. Many species of birds migrate south for winter.\n",
        "    Rising sea levels threaten coastal communities worldwide.\n",
        "    Scientists agree that reducing carbon emissions is essential.\"\"\",\n",
        "\n",
        "    # Low coherence\n",
        "    \"\"\"Climate change is a major global challenge. The new restaurant opened downtown last week.\n",
        "    The basketball team won the championship.\n",
        "    Scientists agree that reducing carbon emissions is essential.\"\"\"\n",
        "]\n",
        "\n",
        "def evaluate_coherence(text):\n",
        "    # Parse text\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Split into sentences\n",
        "    sentences = list(doc.sents)\n",
        "\n",
        "    if len(sentences) < 2:\n",
        "        return {\"coherence_score\": 1.0, \"sentence_similarities\": []}\n",
        "\n",
        "    # Get sentence embeddings\n",
        "    embeddings = [sent.vector for sent in sentences]\n",
        "\n",
        "    # Calculate pairwise similarities between adjacent sentences\n",
        "    similarities = []\n",
        "    for i in range(len(embeddings) - 1):\n",
        "        sim = cosine_similarity([embeddings[i]], [embeddings[i+1]])[0][0]\n",
        "        similarities.append(sim)\n",
        "\n",
        "    # Calculate overall coherence score (average of similarities)\n",
        "    coherence_score = np.mean(similarities)\n",
        "\n",
        "    return {\n",
        "        \"coherence_score\": coherence_score,\n",
        "        \"sentence_similarities\": similarities\n",
        "    }\n",
        "\n",
        "# Evaluate each text\n",
        "results = []\n",
        "for i, text in enumerate(texts):\n",
        "    coherence_data = evaluate_coherence(text)\n",
        "\n",
        "    # Add to results\n",
        "    results.append({\n",
        "        \"text_id\": i+1,\n",
        "        \"coherence_level\": [\"Low\", \"Medium\", \"High\"][i],  # For demonstration purposes\n",
        "        \"text_preview\": text[:50] + \"...\",\n",
        "        \"coherence_score\": coherence_data[\"coherence_score\"],\n",
        "        \"sentence_similarities\": coherence_data[\"sentence_similarities\"]\n",
        "    })\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "print(df[[\"text_id\", \"coherence_level\", \"text_preview\", \"coherence_score\"]])\n",
        "\n",
        "# Visualize coherence scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(df[\"coherence_level\"], df[\"coherence_score\"], color=[\"red\", \"yellow\", \"green\"])\n",
        "plt.title(\"Text Coherence Scores\")\n",
        "plt.xlabel(\"Coherence Level\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "for i, score in enumerate(df[\"coherence_score\"]):\n",
        "    plt.text(i, score + 0.05, f\"{score:.2f}\", ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xcwynEumdF_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explainable NLP with LIME"
      ],
      "metadata": {
        "id": "rpD2flfXdHnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LIME (Local Interpretable Model-agnostic Explanations) to explain text classification decisions:"
      ],
      "metadata": {
        "id": "_UlK5iqsdLIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "categories = ['alt.atheism', 'soc.religion.christian']\n",
        "train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "# Train classifier\n",
        "pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=1000),\n",
        "    LogisticRegression(random_state=42)\n",
        ")\n",
        "pipeline.fit(train.data, train.target)\n",
        "\n",
        "# Create explainer\n",
        "explainer = LimeTextExplainer(class_names=categories)\n",
        "\n",
        "# Get test instance\n",
        "idx = 1\n",
        "test_instance = test.data[idx]\n",
        "true_class = test.target[idx]\n",
        "true_class_name = categories[true_class]\n",
        "\n",
        "# Make prediction\n",
        "pred_probas = pipeline.predict_proba([test_instance])[0]\n",
        "pred_class = np.argmax(pred_probas)\n",
        "pred_class_name = categories[pred_class]\n",
        "confidence = pred_probas[pred_class]\n",
        "\n",
        "print(f\"Document: {test_instance[:300]}...\")\n",
        "print(f\"True class: {true_class_name}\")\n",
        "print(f\"Predicted class: {pred_class_name} with confidence {confidence:.4f}\")\n",
        "\n",
        "# Explain prediction\n",
        "exp = explainer.explain_instance(test_instance, pipeline.predict_proba, num_features=10)\n",
        "\n",
        "# Display explanation\n",
        "print(\"\\nExplanation:\")\n",
        "for feature, weight in exp.as_list():\n",
        "    print(f\"{feature}: {weight:.4f}\")\n",
        "\n",
        "# Plot explanation\n",
        "plt.figure(figsize=(10, 6))\n",
        "exp.as_pyplot_figure()\n",
        "plt.title(f\"LIME Explanation\\nPrediction: {pred_class_name} (conf: {confidence:.2f})\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BhAtwJ8EdLid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Similarity with Sentence Transformers"
      ],
      "metadata": {
        "id": "KQDqm9gFdN44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Sentence Transformers for robust document similarity"
      ],
      "metadata": {
        "id": "HDqiPcMydOUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Load model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    # Technology\n",
        "    \"Machine learning models require large amounts of training data.\",\n",
        "    \"Neural networks have revolutionized computer vision tasks.\",\n",
        "    \"Deep learning algorithms use multiple layers of neural networks.\",\n",
        "\n",
        "    # Health\n",
        "    \"Regular exercise reduces the risk of cardiovascular disease.\",\n",
        "    \"A balanced diet is essential for maintaining good health.\",\n",
        "    \"Physical activity improves overall health and wellbeing.\",\n",
        "\n",
        "    # Finance\n",
        "    \"Stock market investors analyze company performance and trends.\",\n",
        "    \"Investment portfolios should be diversified to reduce risk.\",\n",
        "    \"Financial planning involves budgeting and saving for future goals.\"\n",
        "]\n",
        "\n",
        "# Calculate embeddings\n",
        "embeddings = model.encode(documents)\n",
        "\n",
        "# Calculate similarity matrix\n",
        "similarity_matrix = util.cos_sim(embeddings, embeddings)\n",
        "\n",
        "# Convert to numpy array for easier manipulation\n",
        "similarity_matrix = similarity_matrix.numpy()\n",
        "\n",
        "# Create DataFrame for visualization\n",
        "df_similarity = pd.DataFrame(similarity_matrix,\n",
        "                             index=[f\"Doc {i+1}\" for i in range(len(documents))],\n",
        "                             columns=[f\"Doc {i+1}\" for i in range(len(documents))])\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df_similarity, annot=True, cmap='YlGnBu', vmin=0, vmax=1)\n",
        "plt.title('Document Similarity Matrix (Sentence Transformers)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find most similar document pairs\n",
        "np.fill_diagonal(similarity_matrix, 0)  # Exclude self-similarity\n",
        "for i in range(len(documents)):\n",
        "    max_sim_idx = np.argmax(similarity_matrix[i])\n",
        "    if i < max_sim_idx:  # Avoid duplicate pairs\n",
        "        print(f\"Similar pair found:\")\n",
        "        print(f\"Document {i+1}: {documents[i]}\")\n",
        "        print(f\"Document {max_sim_idx+1}: {documents[max_sim_idx]}\")\n",
        "        print(f\"Similarity: {similarity_matrix[i][max_sim_idx]:.4f}\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "YNYQ0J_mdPvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bias Detection in NLP Models"
      ],
      "metadata": {
        "id": "UAAqeOIcdRLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detecting and measuring bias in NLP models"
      ],
      "metadata": {
        "id": "CahrtTfjdU1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "\n",
        "# Template sentences with masked tokens\n",
        "templates = [\n",
        "    \"The {gender} works as a {profession}.\",\n",
        "    \"{gender} are known to be {trait}.\",\n",
        "    \"The {gender} enjoys {activity} in their free time.\"\n",
        "]\n",
        "\n",
        "# Word pairs to test\n",
        "gender_terms = [(\"man\", \"woman\"), (\"boy\", \"girl\"), (\"father\", \"mother\"), (\"he\", \"she\")]\n",
        "professions = [\"doctor\", \"nurse\", \"engineer\", \"teacher\", \"scientist\", \"assistant\"]\n",
        "traits = [\"intelligent\", \"emotional\", \"rational\", \"ambitious\", \"caring\", \"aggressive\"]\n",
        "activities = [\"sports\", \"shopping\", \"reading\", \"cooking\", \"gaming\", \"art\"]\n",
        "\n",
        "def get_mask_predictions(template, replacements):\n",
        "    results = []\n",
        "\n",
        "    for gender_pair in gender_terms:\n",
        "        row = {\"gender_pair\": f\"{gender_pair[0]}/{gender_pair[1]}\"}\n",
        "\n",
        "        for term in replacements:\n",
        "            # Create sentences with mask token\n",
        "            male_sent = template.format(gender=gender_pair[0], **{template.split(\"{\")[2].split(\"}\")[0]: \"[MASK]\"})\n",
        "            female_sent = template.format(gender=gender_pair[1], **{template.split(\"{\")[2].split(\"}\")[0]: \"[MASK]\"})\n",
        "\n",
        "            # Replace the term placeholder with [MASK]\n",
        "            male_sent = male_sent.replace(\"[MASK]\", term)\n",
        "            female_sent = female_sent.replace(\"[MASK]\", term)\n",
        "\n",
        "            # Get token IDs for male sentence\n",
        "            male_inputs = tokenizer(male_sent, return_tensors=\"pt\")\n",
        "            male_token_ids = male_inputs[\"input_ids\"]\n",
        "            male_outputs = model(**male_inputs)\n",
        "            male_predictions = male_outputs.logits\n",
        "\n",
        "            # Get token IDs for female sentence\n",
        "            female_inputs = tokenizer(female_sent, return_tensors=\"pt\")\n",
        "            female_token_ids = female_inputs[\"input_ids\"]\n",
        "            female_outputs = model(**female_inputs)\n",
        "            female_predictions = female_outputs.logits\n",
        "\n",
        "            # Get probabilities\n",
        "            male_probs = torch.softmax(male_predictions[0], dim=-1)\n",
        "            female_probs = torch.softmax(female_predictions[0], dim=-1)\n",
        "\n",
        "            # Get probability for the target term\n",
        "            term_id = tokenizer.encode(term, add_special_tokens=False)[0]\n",
        "            male_prob = male_probs[male_token_ids[0] == term_id, term_id].item()\n",
        "            female_prob = female_probs[female_token_ids[0] == term_id, term_id].item()\n",
        "\n",
        "            # Calculate bias score (difference in probabilities)\n",
        "            bias_score = male_prob - female_prob\n",
        "\n",
        "            # Add to results\n",
        "            row[term] = bias_score\n",
        "\n",
        "        results.append(row)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Analyze profession bias\n",
        "template = templates[0]\n",
        "profession_bias = get_mask_predictions(template, professions)\n",
        "print(\"Profession Bias:\")\n",
        "print(profession_bias)\n",
        "\n",
        "# Analyze trait bias\n",
        "template = templates[1]\n",
        "trait_bias = get_mask_predictions(template, traits)\n",
        "print(\"\\nTrait Bias:\")\n",
        "print(trait_bias)\n",
        "\n",
        "# Visualize profession bias\n",
        "plt.figure(figsize=(12, 8))\n",
        "data = profession_bias.melt(id_vars=[\"gender_pair\"], var_name=\"profession\", value_name=\"bias\")\n",
        "sns.barplot(x=\"profession\", y=\"bias\", hue=\"gender_pair\", data=data)\n",
        "plt.title(\"Gender Bias in Profession Associations\")\n",
        "plt.xlabel(\"Profession\")\n",
        "plt.ylabel(\"Bias Score (positive = male bias, negative = female bias)\")\n",
        "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BjsC6MUpdVnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Generation"
      ],
      "metadata": {
        "id": "SJyr4H9FdZAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automatically generating questions from text passages"
      ],
      "metadata": {
        "id": "pTT-WqVRdZiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"mrm8488/t5-base-finetuned-question-generation-ap\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Sample passages\n",
        "passages = [\n",
        "    \"\"\"Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction\n",
        "    between computers and humans through natural language. The ultimate goal of NLP is to enable computers\n",
        "    to understand, interpret and generate human language in a valuable way.\"\"\",\n",
        "    \n",
        "    \"\"\"The solar system consists of the Sun and everything that orbits around it, including planets,\n",
        "    moons, asteroids, comets and meteoroids. There are eight planets in our solar system: Mercury, Venus,\n",
        "    Earth, Mars, Jupiter, Saturn, Uranus and Neptune.\"\"\"\n",
        "]\n",
        "\n",
        "def generate_questions(passage, num_questions=3):\n",
        "    # Split into sentences\n",
        "    sentences = sent_tokenize(passage)\n",
        "    \n",
        "    questions = []\n",
        "    for sentence in sentences[:num_questions]:  # Limit to avoid too many questions\n",
        "        # Prepare input for T5\n",
        "        input_text = f\"generate question: {sentence}\"\n",
        "        \n",
        "        # Tokenize input\n",
        "        encoding = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        \n",
        "        # Generate question\n",
        "        outputs = model.generate(\n",
        "            encoding.input_ids,\n",
        "            max_length=64,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        \n",
        "        # Decode output\n",
        "        question = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        \n",
        "        questions.append({\n",
        "            \"context\": sentence,\n",
        "            \"generated_question\": question\n",
        "        })\n",
        "    \n",
        "    return questions\n",
        "\n",
        "# Generate questions for each passage\n",
        "all_questions = []\n",
        "for i, passage in enumerate(passages):\n",
        "    print(f\"\\nPassage {i+1}:\")\n",
        "    print(passage)\n",
        "    print(\"\\nGenerated Questions:\")\n",
        "    \n",
        "    questions = generate_questions(passage)\n",
        "    for q in questions:\n",
        "        print(f\"Context: {q['context']}\")\n",
        "        print(f\"Question: {q['generated_question']}\")\n",
        "        print()\n",
        "        \n",
        "        # Add to collection\n",
        "        q[\"passage_id\"] = i + 1\n",
        "        all_questions.append(q)\n",
        "\n",
        "# Display as DataFrame\n",
        "df_questions = pd.DataFrame(all_questions)\n",
        "print(df_questions)"
      ],
      "metadata": {
        "id": "Nw1xfrUcdb6j"
      }
    }
  ]
}