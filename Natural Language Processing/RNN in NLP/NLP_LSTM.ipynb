{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KobUlfYr6FWx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Create a Simple Synthetic Dataset ---\n",
        "# Input sentences and corresponding tags (O for other, ACTION for action word)\n",
        "sentences = [\n",
        "    \"I am walking home\",\n",
        "    \"She is reading a book\",\n",
        "    \"They are playing soccer\",\n",
        "    \"We like to eat pizza\",\n",
        "    \"He loves to sing\",\n",
        "    \"Birds are flying high\",\n",
        "    \"Fish can swim fast\",\n",
        "    \"Dogs love to run\",\n",
        "    \"Cats like to sleep\",\n",
        "    \"The sun is shining\"\n",
        "]"
      ],
      "metadata": {
        "id": "ivMrVzZL6HWG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corresponding tag sequences (one tag per word)\n",
        "tags = [\n",
        "    [\"O\", \"O\", \"ACTION\", \"O\"],\n",
        "    [\"O\", \"O\", \"ACTION\", \"O\", \"O\"],\n",
        "    [\"O\", \"O\", \"ACTION\", \"O\"],\n",
        "    [\"O\", \"O\", \"O\", \"ACTION\", \"O\"],\n",
        "    [\"O\", \"ACTION\", \"O\", \"ACTION\"],\n",
        "    [\"O\", \"O\", \"ACTION\", \"O\"],\n",
        "    [\"O\", \"O\", \"ACTION\", \"O\", \"O\"],\n",
        "    [\"O\", \"ACTION\", \"O\", \"ACTION\"],\n",
        "    [\"O\", \"ACTION\", \"O\", \"ACTION\"],\n",
        "    [\"O\", \"O\", \"O\", \"ACTION\"]\n",
        "]"
      ],
      "metadata": {
        "id": "VyXfto4g6HZF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Preprocess Data: Tokenization and Padding ---\n",
        "\n",
        "# Tokenize words in sentences\n",
        "word_tokenizer = Tokenizer(oov_token=\"<OOV>\") # Handle out-of-vocabulary words\n",
        "word_tokenizer.fit_on_texts(sentences)\n",
        "word_sequences = word_tokenizer.texts_to_sequences(sentences)\n"
      ],
      "metadata": {
        "id": "QeACUQhZ6Hb2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenizer, word_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkcVhHeq8vuE",
        "outputId": "eb661dc0-debd-4bda-81a1-51e8dead2690"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<keras.src.legacy.preprocessing.text.Tokenizer at 0x7c337e5a5490>,\n",
              " [[6, 7, 8, 9],\n",
              "  [10, 3, 11, 12, 13],\n",
              "  [14, 4, 15, 16],\n",
              "  [17, 5, 2, 18, 19],\n",
              "  [20, 21, 2, 22],\n",
              "  [23, 4, 24, 25],\n",
              "  [26, 27, 28, 29],\n",
              "  [30, 31, 2, 32],\n",
              "  [33, 5, 2, 34],\n",
              "  [35, 36, 3, 37]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize tags\n",
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(tags)\n",
        "tag_sequences = tag_tokenizer.texts_to_sequences(tags)"
      ],
      "metadata": {
        "id": "NK6UR4036HeV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-nNFPEe89Ze",
        "outputId": "33ff4b95-519a-4657-fbcc-c6232aa1d7e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 2, 1],\n",
              " [1, 1, 2, 1, 1],\n",
              " [1, 1, 2, 1],\n",
              " [1, 1, 1, 2, 1],\n",
              " [1, 2, 1, 2],\n",
              " [1, 1, 2, 1],\n",
              " [1, 1, 2, 1, 1],\n",
              " [1, 2, 1, 2],\n",
              " [1, 2, 1, 2],\n",
              " [1, 1, 1, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_XFpHuL9GlN",
        "outputId": "203a7bc0-9d96-4243-a179-958d09668605"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'to': 2,\n",
              " 'is': 3,\n",
              " 'are': 4,\n",
              " 'like': 5,\n",
              " 'i': 6,\n",
              " 'am': 7,\n",
              " 'walking': 8,\n",
              " 'home': 9,\n",
              " 'she': 10,\n",
              " 'reading': 11,\n",
              " 'a': 12,\n",
              " 'book': 13,\n",
              " 'they': 14,\n",
              " 'playing': 15,\n",
              " 'soccer': 16,\n",
              " 'we': 17,\n",
              " 'eat': 18,\n",
              " 'pizza': 19,\n",
              " 'he': 20,\n",
              " 'loves': 21,\n",
              " 'sing': 22,\n",
              " 'birds': 23,\n",
              " 'flying': 24,\n",
              " 'high': 25,\n",
              " 'fish': 26,\n",
              " 'can': 27,\n",
              " 'swim': 28,\n",
              " 'fast': 29,\n",
              " 'dogs': 30,\n",
              " 'love': 31,\n",
              " 'run': 32,\n",
              " 'cats': 33,\n",
              " 'sleep': 34,\n",
              " 'the': 35,\n",
              " 'sun': 36,\n",
              " 'shining': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get vocabulary sizes and index mappings\n",
        "word_vocab_size = len(word_tokenizer.word_index) + 1 # +1 for padding token 0\n",
        "tag_vocab_size = len(tag_tokenizer.word_index) + 1   # +1 for padding token 0\n"
      ],
      "metadata": {
        "id": "GX_Cp-k96Hgu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = word_tokenizer.word_index\n",
        "tag_index = tag_tokenizer.word_index\n",
        "index_to_tag = {v: k for k, v in tag_index.items()} # Mapping back from index to tag name\n"
      ],
      "metadata": {
        "id": "OnW59OXo6HmH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-L_4Rcz8PLl",
        "outputId": "35c91d77-8c0d-41b0-bc6b-55c01a5755de"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'to': 2,\n",
              " 'is': 3,\n",
              " 'are': 4,\n",
              " 'like': 5,\n",
              " 'i': 6,\n",
              " 'am': 7,\n",
              " 'walking': 8,\n",
              " 'home': 9,\n",
              " 'she': 10,\n",
              " 'reading': 11,\n",
              " 'a': 12,\n",
              " 'book': 13,\n",
              " 'they': 14,\n",
              " 'playing': 15,\n",
              " 'soccer': 16,\n",
              " 'we': 17,\n",
              " 'eat': 18,\n",
              " 'pizza': 19,\n",
              " 'he': 20,\n",
              " 'loves': 21,\n",
              " 'sing': 22,\n",
              " 'birds': 23,\n",
              " 'flying': 24,\n",
              " 'high': 25,\n",
              " 'fish': 26,\n",
              " 'can': 27,\n",
              " 'swim': 28,\n",
              " 'fast': 29,\n",
              " 'dogs': 30,\n",
              " 'love': 31,\n",
              " 'run': 32,\n",
              " 'cats': 33,\n",
              " 'sleep': 34,\n",
              " 'the': 35,\n",
              " 'sun': 36,\n",
              " 'shining': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaJ6rkvA8TyE",
        "outputId": "882ec7de-f677-4938-e708-ce9f293f96a3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'o': 1, 'action': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Word vocabulary size: {word_vocab_size}\")\n",
        "print(f\"Tag vocabulary size: {tag_vocab_size}\")\n",
        "print(f\"Word index: {word_index}\")\n",
        "print(f\"Tag index: {tag_index}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbTcEL8r6Hr4",
        "outputId": "8c64f12a-1e41-46f0-e1c0-5f9cad1a78f9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word vocabulary size: 38\n",
            "Tag vocabulary size: 3\n",
            "Word index: {'<OOV>': 1, 'to': 2, 'is': 3, 'are': 4, 'like': 5, 'i': 6, 'am': 7, 'walking': 8, 'home': 9, 'she': 10, 'reading': 11, 'a': 12, 'book': 13, 'they': 14, 'playing': 15, 'soccer': 16, 'we': 17, 'eat': 18, 'pizza': 19, 'he': 20, 'loves': 21, 'sing': 22, 'birds': 23, 'flying': 24, 'high': 25, 'fish': 26, 'can': 27, 'swim': 28, 'fast': 29, 'dogs': 30, 'love': 31, 'run': 32, 'cats': 33, 'sleep': 34, 'the': 35, 'sun': 36, 'shining': 37}\n",
            "Tag index: {'o': 1, 'action': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine max sequence length for padding\n",
        "max_len = max(len(seq) for seq in word_sequences)\n",
        "print(f\"Max sequence length: {max_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7cLdwDd6HtI",
        "outputId": "636bf51c-267d-4765-dbb0-05f894ec2966"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sequence length: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences (both input words and output tags)\n",
        "X = pad_sequences(word_sequences, maxlen=max_len, padding='post') # Pad with 0 after the sequence\n",
        "y = pad_sequences(tag_sequences, maxlen=max_len, padding='post') # Pad target sequences too\n"
      ],
      "metadata": {
        "id": "f8f_wcUB66nW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Padded X_train shape: {X_train.shape}\")\n",
        "print(f\"Padded y_train shape: {y_train.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqj12rcb66wW",
        "outputId": "2a894edd-1996-4ad2-dcb7-026196f07a84"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded X_train shape: (7, 5)\n",
            "Padded y_train shape: (7, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Build the LSTM Model for Sequence Tagging ---\n",
        "\n",
        "embedding_dim = 16 # Size of the word embedding vectors\n",
        "lstm_units = 32    # Number of units in the LSTM layer\n",
        "\n",
        "model = Sequential()\n",
        "# Embedding layer: Maps word indices to dense vectors\n",
        "model.add(Embedding(input_dim=word_vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
        "\n",
        "# LSTM layer: Processes the sequence, returning a sequence of hidden states\n",
        "# return_sequences=True is essential for sequence tagging tasks\n",
        "model.add(LSTM(units=lstm_units, return_sequences=True))\n",
        "\n",
        "# TimeDistributed Dense layer: Applies a Dense layer independently to each time step\n",
        "# This allows the model to predict a tag for each word in the sequence\n",
        "model.add(TimeDistributed(Dense(units=tag_vocab_size, activation='softmax'))) # Output probability distribution over tags for each step\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "R5nRG7p-66zF",
        "outputId": "71579c30-4fa7-4bb7-c34a-eedacbc49843"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed_1              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Compile the Model ---\n",
        "\n",
        "# Use sparse_categorical_crossentropy because our targets (y) are integer indices\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "87_DKvZ9661n"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Train the Model ---\n",
        "\n",
        "print(\"\\nTraining model...\")\n",
        "batch_size = 4 # Small batch size for this tiny dataset\n",
        "epochs = 50  # Train for more epochs due to small data\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2, # Use 20% of training data for validation\n",
        "                    verbose=0) # Suppress verbose output for tiny data\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn0l9rgt664U",
        "outputId": "7b99eb8c-0b4e-4f92-87c0-09fd22adc6ab"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model...\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Evaluate the Model ---\n",
        "\n",
        "print(\"\\nEvaluating model...\")\n",
        "# Note: Evaluation on padded sequences might not be perfectly representative\n",
        "# if accuracy includes predictions on padding tokens. A masked loss/metric is better\n",
        "# for real tasks, but sparse_categorical_crossentropy often handles padding=0 implicitly.\n",
        "loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
        "\n",
        "print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\") # This is per-token accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SecV3KI_666t",
        "outputId": "2be32aa1-18a3-495e-897f-75cb49d19340"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model...\n",
            "\n",
            "Test Loss: 0.8136\n",
            "Test Accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Make and Display a Prediction ---\n",
        "\n",
        "print(\"\\nExample Prediction:\")\n",
        "test_sentence_raw = \"Fish are swimming fast\"\n",
        "test_sequence = word_tokenizer.texts_to_sequences([test_sentence_raw])\n",
        "test_sequence_padded = pad_sequences(test_sequence, maxlen=max_len, padding='post')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nHxTURU7M-s",
        "outputId": "c2110845-df7a-4f7e-e796-bd7e5c4ca465"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example Prediction:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict probabilities for each tag at each time step\n",
        "predictions = model.predict(test_sequence_padded) # Shape: (1, max_len, tag_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgOUDCzx7NCP",
        "outputId": "ba60e32b-8038-4c5e-d401-44fd32be94df"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index of the tag with the highest probability for each word\n",
        "predicted_tags_indices = np.argmax(predictions, axis=-1) # Shape: (1, max_len)"
      ],
      "metadata": {
        "id": "HnrRLqOA7KdW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert indices back to tag names, ignoring padding\n",
        "predicted_tags = [index_to_tag[idx] for idx in predicted_tags_indices[0] if idx != 0] # Exclude padding tag index 0"
      ],
      "metadata": {
        "id": "ksVyTiDJ669X"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original sentence: {test_sentence_raw}\")\n",
        "# Split the raw sentence into words to pair with tags (handle potential tokenizer differences)\n",
        "original_words = test_sentence_raw.split()\n",
        "# Only print tags for the actual words, up to the length of the original sentence\n",
        "print(f\"Predicted tags:    {predicted_tags[:len(original_words)]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN1UsYTE7Rcl",
        "outputId": "e570830f-bb9b-4dca-c689-1b9448daaef2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: Fish are swimming fast\n",
            "Predicted tags:    ['o', 'o', 'o', 'o']\n"
          ]
        }
      ]
    }
  ]
}