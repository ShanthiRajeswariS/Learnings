{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H5YU_455Ubi_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris # Import the Iris dataset loader\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold # KFold cross-validation split generator\n",
        "from sklearn.metrics import accuracy_score # Metric for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "K_FOLDS = 5 # Number of folds for K-Fold Cross-Validation"
      ],
      "metadata": {
        "id": "4skcIx1FVJ4y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Dataset ---\n",
        "print(\"Loading Iris dataset...\")\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target # X are features, y are labels\n",
        "N_TOTAL_SAMPLES = len(X)\n",
        "N_FEATURES = X.shape[1]\n",
        "N_CLASSES = len(np.unique(y))\n",
        "\n",
        "print(f\"Total samples in Iris dataset: {N_TOTAL_SAMPLES}\")\n",
        "print(f\"Number of features: {N_FEATURES}\")\n",
        "print(f\"Number of classes: {N_CLASSES}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brXthw3XVJ77",
        "outputId": "d86bac45-79ba-4ee9-a6f2-1c3583edf01c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Iris dataset...\n",
            "Total samples in Iris dataset: 150\n",
            "Number of features: 4\n",
            "Number of classes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initialize ML Model ---\n",
        "# We use Logistic Regression, a simple model suitable for this classification task.\n",
        "# solver='liblinear' is good for small datasets, max_iter increases robustness.\n",
        "model = LogisticRegression(solver='liblinear', max_iter=1000)"
      ],
      "metadata": {
        "id": "vNi3RK9wVJ-7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Perform K-Fold Cross-Validation ---\n",
        "print(f\"\\nPerforming {K_FOLDS}-Fold Cross-Validation on the entire dataset...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofiojfJbVKGm",
        "outputId": "b5133c78-8915-4a28-92d9-c48330e03e91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing 5-Fold Cross-Validation on the entire dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KFold cross-validator\n",
        "# n_splits: how many folds to create (K)\n",
        "# shuffle=True: randomly shuffles the data before splitting (recommended)\n",
        "# random_state: seed for shuffling for reproducibility\n",
        "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "XtPR4EO1VgE7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_accuracies = [] # List to store the accuracy score from each fold"
      ],
      "metadata": {
        "id": "wfIQjbpIVgIN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The kf.split(X, y) method generates the indices for the train and validation sets for each fold\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
        "    print(f\"\\n--- Processing Fold {fold + 1}/{K_FOLDS} ---\")\n",
        "\n",
        "    # Split the data into training and validation sets for this specific fold using the generated indices\n",
        "    print(train_index, val_index)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Train the model using the training data for this fold\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the trained model using the validation data for this fold\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # Calculate the accuracy for this fold\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "    print(f\"  Fold {fold + 1} Training samples: {len(X_train)}\")\n",
        "    print(f\"  Fold {fold + 1} Validation samples: {len(X_val)}\")\n",
        "    print(f\"  Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Store the accuracy\n",
        "    fold_accuracies.append(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kRskYMAVgLF",
        "outputId": "6626e9f4-0aae-441d-f33f-455370c29fb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Processing Fold 1/5 ---\n",
            "[  0   1   2   3   4   5   6   7   8  10  11  13  14  15  16  17  20  21\n",
            "  22  23  24  25  27  28  32  33  34  35  37  38  39  40  41  42  43  44\n",
            "  46  47  48  49  50  51  52  53  54  57  58  59  60  61  62  63  65  66\n",
            "  67  70  71  72  74  75  77  79  80  81  83  84  85  86  87  88  89  90\n",
            "  91  92  93  94  95  96  97  98  99 100 101 102 103 105 106 107 109 111\n",
            " 112 113 114 115 116 117 119 120 121 122 123 124 125 126 129 130 133 134\n",
            " 135 136 137 138 139 140 142 144 146 147 148 149] [  9  12  18  19  26  29  30  31  36  45  55  56  64  68  69  73  76  78\n",
            "  82 104 108 110 118 127 128 131 132 141 143 145]\n",
            "  Fold 1 Training samples: 120\n",
            "  Fold 1 Validation samples: 30\n",
            "  Fold 1 Accuracy: 1.0000\n",
            "\n",
            "--- Processing Fold 2/5 ---\n",
            "[  1   2   3   5   6   7   8   9  12  13  14  17  18  19  20  21  23  24\n",
            "  25  26  29  30  31  33  34  35  36  37  38  39  41  43  45  46  47  48\n",
            "  49  50  52  53  54  55  56  57  58  59  61  62  63  64  68  69  70  71\n",
            "  72  73  74  76  77  78  79  80  82  83  84  87  88  89  90  91  92  93\n",
            "  94  95  97  98  99 100 101 102 103 104 106 107 108 110 111 112 113 114\n",
            " 115 116 117 118 119 120 121 123 124 125 126 127 128 129 130 131 132 134\n",
            " 135 136 138 139 140 141 143 144 145 147 148 149] [  0   4  10  11  15  16  22  27  28  32  40  42  44  51  60  65  66  67\n",
            "  75  81  85  86  96 105 109 122 133 137 142 146]\n",
            "  Fold 2 Training samples: 120\n",
            "  Fold 2 Validation samples: 30\n",
            "  Fold 2 Accuracy: 0.9333\n",
            "\n",
            "--- Processing Fold 3/5 ---\n",
            "[  0   1   2   3   4   6   8   9  10  11  12  13  14  15  16  17  18  19\n",
            "  20  21  22  26  27  28  29  30  31  32  36  37  38  40  41  42  44  45\n",
            "  46  48  50  51  52  54  55  56  57  58  59  60  61  63  64  65  66  67\n",
            "  68  69  71  72  73  74  75  76  78  79  81  82  83  85  86  87  88  89\n",
            "  90  91  92  96  98  99 100 102 103 104 105 106 107 108 109 110 112 115\n",
            " 116 118 119 120 121 122 124 125 126 127 128 129 130 131 132 133 134 135\n",
            " 136 137 139 140 141 142 143 144 145 146 147 149] [  5   7  23  24  25  33  34  35  39  43  47  49  53  62  70  77  80  84\n",
            "  93  94  95  97 101 111 113 114 117 123 138 148]\n",
            "  Fold 3 Training samples: 120\n",
            "  Fold 3 Validation samples: 30\n",
            "  Fold 3 Accuracy: 0.9333\n",
            "\n",
            "--- Processing Fold 4/5 ---\n",
            "[  0   1   4   5   7   9  10  11  12  14  15  16  18  19  20  21  22  23\n",
            "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  39  40  41  42\n",
            "  43  44  45  47  48  49  51  52  53  55  56  57  58  60  62  64  65  66\n",
            "  67  68  69  70  71  73  74  75  76  77  78  80  81  82  84  85  86  87\n",
            "  88  90  91  92  93  94  95  96  97  99 101 102 103 104 105 106 107 108\n",
            " 109 110 111 113 114 116 117 118 121 122 123 124 127 128 129 130 131 132\n",
            " 133 137 138 140 141 142 143 144 145 146 148 149] [  2   3   6   8  13  17  38  46  50  54  59  61  63  72  79  83  89  98\n",
            " 100 112 115 119 120 125 126 134 135 136 139 147]\n",
            "  Fold 4 Training samples: 120\n",
            "  Fold 4 Validation samples: 30\n",
            "  Fold 4 Accuracy: 0.9667\n",
            "\n",
            "--- Processing Fold 5/5 ---\n",
            "[  0   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  19\n",
            "  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38  39  40\n",
            "  42  43  44  45  46  47  49  50  51  53  54  55  56  59  60  61  62  63\n",
            "  64  65  66  67  68  69  70  72  73  75  76  77  78  79  80  81  82  83\n",
            "  84  85  86  89  93  94  95  96  97  98 100 101 104 105 108 109 110 111\n",
            " 112 113 114 115 117 118 119 120 122 123 125 126 127 128 131 132 133 134\n",
            " 135 136 137 138 139 141 142 143 145 146 147 148] [  1  14  20  21  37  41  48  52  57  58  71  74  87  88  90  91  92  99\n",
            " 102 103 106 107 116 121 124 129 130 140 144 149]\n",
            "  Fold 5 Training samples: 120\n",
            "  Fold 5 Validation samples: 30\n",
            "  Fold 5 Accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Report Results ---\n",
        "# Calculate the average accuracy across all folds\n",
        "avg_accuracy = np.mean(fold_accuracies)\n",
        "print(f\"\\n--- Average {K_FOLDS}-Fold Cross-Validation Accuracy: {avg_accuracy:.4f} ---\")\n",
        "print(\"\\nCross-validation finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE_8nevtVKLM",
        "outputId": "878435d1-b239-4024-de55-467e7722aa4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Iris dataset...\n",
            "Total samples in Iris dataset: 150\n",
            "Number of features: 4\n",
            "Number of classes: 3\n",
            "\n",
            "Performing 5-Fold Cross-Validation on the entire dataset...\n",
            "\n",
            "--- Processing Fold 1/5 ---\n",
            "  Fold 1 Training samples: 120\n",
            "  Fold 1 Validation samples: 30\n",
            "  Fold 1 Accuracy: 1.0000\n",
            "\n",
            "--- Processing Fold 2/5 ---\n",
            "  Fold 2 Training samples: 120\n",
            "  Fold 2 Validation samples: 30\n",
            "  Fold 2 Accuracy: 0.9333\n",
            "\n",
            "--- Processing Fold 3/5 ---\n",
            "  Fold 3 Training samples: 120\n",
            "  Fold 3 Validation samples: 30\n",
            "  Fold 3 Accuracy: 0.9333\n",
            "\n",
            "--- Processing Fold 4/5 ---\n",
            "  Fold 4 Training samples: 120\n",
            "  Fold 4 Validation samples: 30\n",
            "  Fold 4 Accuracy: 0.9667\n",
            "\n",
            "--- Processing Fold 5/5 ---\n",
            "  Fold 5 Training samples: 120\n",
            "  Fold 5 Validation samples: 30\n",
            "  Fold 5 Accuracy: 0.9667\n",
            "\n",
            "--- Average 5-Fold Cross-Validation Accuracy: 0.9600 ---\n",
            "\n",
            "Cross-validation finished.\n"
          ]
        }
      ]
    }
  ]
}