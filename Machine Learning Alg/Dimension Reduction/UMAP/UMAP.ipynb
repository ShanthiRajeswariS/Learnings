{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# UMAP - Uniform Manifold Approximation and Projection"
      ],
      "metadata": {
        "id": "QkIKSC8N0G4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- UMAP (Uniform Manifold Approximation and Projection) is a dimensionality reduction technique widely used in machine learning for visualizing high-dimensional data and as a preliminary step for other machine learning tasks.\n",
        "\n",
        "- Developed by Leland McInnes, John Healy, and James Melville, UMAP is based on principles from **Riemannian geometry and algebraic topology**, offering a theoretically grounded approach to manifold learning.\n",
        "\n",
        "- The primary goal of UMAP is to **project data from a high-dimensional space into a lower-dimensional space**, typically two or three dimensions for visualization, while preserving the **essential structural properties of the data**.\n",
        "\n",
        "- Unlike linear methods such as Principal Component Analysis (PCA), UMAP is **particularly effective at capturing non-linear relationships and the underlying manifold structure of complex datasets.**"
      ],
      "metadata": {
        "id": "yfK3PlD90G6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How UMAP Works:**"
      ],
      "metadata": {
        "id": "4IfpfOwF0G9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The UMAP algorithm can be broadly divided into two main stages:\n",
        "\n",
        "1.  **High-Dimensional Graph Construction:**\n",
        "    * UMAP begins by building a **high-dimensional graph representing the data's structure**. It identifies the **nearest neighbors for each data point**, often using **efficient approximate nearest neighbor search algorithms**.\n",
        "    * Based on these **neighbor relationships and local distance scales**, UMAP constructs a **\"fuzzy simplicial set.\"** This can be thought of as a **weighted graph** where the **edge weights represent the probability or confidence that two points are connected in the high-dimensional space**. The concept of a fuzzy simplicial set allows UMAP to represent the **topological structure of the data**.\n",
        "\n",
        "2.  **Low-Dimensional Embedding Optimization:**\n",
        "    * Once the high-dimensional graph is constructed, UMAP optimizes a **low-dimensional representation (embedding) of the data.**\n",
        "    * This optimization process aims to find a **low-dimensional graph whose structure is as similar as possible to the high-dimensional graph**.\n",
        "    * This is typically achieved **by minimizing a cost function** (often based on cross-entropy) that measures the difference between the fuzzy simplicial sets in the high-dimensional and low-dimensional spaces. Stochastic gradient descent is commonly used for this optimization.\n"
      ],
      "metadata": {
        "id": "xygQubxG0G_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Key Hyperparameters:**"
      ],
      "metadata": {
        "id": "Z0yepvQ60HB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two important hyperparameters in UMAP are:\n",
        "\n",
        "* `n_neighbors`: This parameter **controls the number of neighbors considered** for each point in the high-dimensional graph construction. Smaller values emphasize local structure, potentially leading to more tightly clustered embeddings. Larger values consider more distant points, preserving more of the global structure but potentially losing fine-grained local details. preferrable range 0 to 100\n",
        "* `min_dist`: This parameter controls how tightly points are packed together in the low-dimensional embedding. **Smaller values allow for denser clusters**, while larger values push points further apart, resulting in a more dispersed layout. Ranges between 0 and 1"
      ],
      "metadata": {
        "id": "jFAFybY50HEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applications in Machine Learning:**"
      ],
      "metadata": {
        "id": "vwr26PNQ0HHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UMAP is a versatile tool with various applications in machine learning, including:\n",
        "\n",
        "* **Data Visualization:** This is one of the most common uses of UMAP, allowing for the visual exploration of complex datasets and identification of clusters or patterns that might not be apparent in the raw high-dimensional data.\n",
        "* **Exploratory Data Analysis:** UMAP helps in understanding the underlying structure and relationships within data before applying other machine learning algorithms.\n",
        "* **Feature Engineering:** The low-dimensional embedding produced by UMAP can be used as a new set of features for downstream tasks, potentially improving the performance of models by capturing non-linear relationships.\n",
        "* **Clustering:** Visualizing data with UMAP can aid in identifying potential clusters, and the UMAP embedding can also be used as input for clustering algorithms like HDBSCAN.\n",
        "* **Anomaly Detection:** Outliers in the high-dimensional space often appear as isolated points or small, distinct clusters in the UMAP embedding."
      ],
      "metadata": {
        "id": "2kHXKq300HJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UMAP vs. t-SNE:**"
      ],
      "metadata": {
        "id": "2063gpGOGgs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "UMAP is often compared to t-SNE (t-distributed Stochastic Neighbor Embedding), another popular dimensionality reduction technique for visualization. While both aim to preserve local structure and reveal clusters, UMAP offers several advantages:\n",
        "\n",
        "* **Speed and Scalability:** UMAP is generally significantly faster and scales better to larger datasets and higher dimensions compared to t-SNE.\n",
        "* **Preservation of Global Structure:** UMAP is often cited as preserving more of the global structure of the data in addition to local structure, which can lead to embeddings where the distances between clusters are more meaningful than in t-SNE.\n",
        "* **Computational Efficiency:** UMAP's algorithm, based on graph optimization, can be more computationally efficient.\n",
        "* **Manifold Approximation:** UMAP's theoretical foundation in manifold approximation provides a slightly different perspective and can sometimes lead to more robust embeddings.\n",
        "\n",
        "In summary, UMAP is a powerful and efficient dimensionality reduction technique grounded in topological data analysis. It is widely used for visualizing high-dimensional data and as a valuable preprocessing step in various machine learning workflows, offering advantages in speed, scalability, and global structure preservation compared to methods like t-SNE."
      ],
      "metadata": {
        "id": "ecdkFb1u0HNA"
      }
    }
  ]
}