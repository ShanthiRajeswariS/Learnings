{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DNN - Hyperparameter Tuning - KerasTuner**"
      ],
      "metadata": {
        "id": "B-C8EgI1vGXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyperparameter tuning is a crucial step in building effective Deep Neural Networks.\n",
        "\n",
        "- It involves finding the best set of hyperparameters (parameters that are not learned from the data but are set before the training process begins) for your model and dataset.\n",
        "\n",
        "- Examples of hyperparameters include the learning rate, the number of layers, the number of neurons in each layer, the type and strength of regularization, and the batch size.\n",
        "\n",
        "- Manually searching for the best combination of hyperparameters can be very time-consuming. Libraries like KerasTuner are designed to automate this search process."
      ],
      "metadata": {
        "id": "dK2t-LpyvGpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agLNt54G6sXH",
        "outputId": "ec1d3bfe-1210-4575-881c-4e5e40a11ecc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras_tuner as kt # Import KerasTuner\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "V4bdJRBP6NwP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values from 0-255 to 0-1\n",
        "x_train = x_train.reshape(-1, 28 * 28).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28 * 28).astype('float32') / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMWqoiY56Ny9",
        "outputId": "22a60a82-eaa6-49be-961b-5417fc57ebf1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding\n",
        "num_classes = 10\n",
        "y_train_one_hot = to_categorical(y_train, num_classes)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "PSSBWdnc6N1u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training data shape: {x_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train_one_hot.shape}\")\n",
        "print(f\"Testing data shape: {x_test.shape}\")\n",
        "print(f\"Testing labels shape: {y_test_one_hot.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEs9kOrK6N4e",
        "outputId": "eb24003a-5a5c-4c31-86cc-d5bf99d4bb1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 784)\n",
            "Training labels shape: (60000, 10)\n",
            "Testing data shape: (10000, 784)\n",
            "Testing labels shape: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define a function that builds the model with tunable hyperparameters\n",
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28 * 28,)),\n",
        "    ])\n",
        "\n",
        "    # Tune the number of neurons in the first Dense layer\n",
        "    # Choose an optimal value between 32 and 128\n",
        "    hp_units1 = hp.Int('units1', min_value=32, max_value=128, step=32)\n",
        "    model.add(Dense(units=hp_units1, activation='relu'))\n",
        "\n",
        "    # Tune the number of neurons in the second Dense layer\n",
        "    # Choose an optimal value between 32 and 64\n",
        "    hp_units2 = hp.Int('units2', min_value=32, max_value=64, step=16)\n",
        "    model.add(Dense(units=hp_units2, activation='relu'))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "    # Choose an optimal value from a list of options\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5xRTF-776N6_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Instantiate a Tuner (e.g., RandomSearch)\n",
        "# RandomSearch randomly tries different combinations of hyperparameters.\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model, # The model-building function\n",
        "    objective='val_accuracy', # The metric to optimize (maximize validation accuracy)\n",
        "    max_trials=10, # The total number of hyperparameter combinations to try\n",
        "    executions_per_trial=2, # The number of models to train for each combination\n",
        "    overwrite=True, # Overwrite previous results\n",
        "    directory='my_mnist_kt_dir', # Directory to store results\n",
        "    project_name='mnist_hyperparameter_tuning' # Project name\n",
        ")\n",
        "\n",
        "# Display the search space\n",
        "tuner.search_space_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQl_sCFw7Ndm",
        "outputId": "075ace03-5a08-478e-a459-c6d9dd0ec649"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 3\n",
            "units1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "units2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 64, 'step': 16, 'sampling': 'linear'}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Run the hyperparameter search\n",
        "print(\"\\nRunning hyperparameter search...\")\n",
        "# The search process trains models with different hyperparameters\n",
        "# and evaluates them on the validation data (using x_test, y_test here for simplicity).\n",
        "tuner.search(x_train, y_train_one_hot, epochs=10, validation_data=(x_test, y_test_one_hot))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STEDygMA7Nlf",
        "outputId": "a6b14602-e55d-4fa3-dde0-220c4dba24fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 9 Complete [00h 03m 02s]\n",
            "val_accuracy: 0.9492999911308289\n",
            "\n",
            "Best val_accuracy So Far: 0.9773000180721283\n",
            "Total elapsed time: 00h 29m 08s\n",
            "\n",
            "Search: Running Trial #10\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "64                |96                |units1\n",
            "64                |48                |units2\n",
            "0.01              |0.001             |learning_rate\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.3836 - val_accuracy: 0.9395 - val_loss: 0.2131\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1857 - val_accuracy: 0.9552 - val_loss: 0.1651\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9562 - loss: 0.1585 - val_accuracy: 0.9578 - val_loss: 0.1605\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9617 - loss: 0.1441 - val_accuracy: 0.9524 - val_loss: 0.1933\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1304 - val_accuracy: 0.9588 - val_loss: 0.1747\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.1196 - val_accuracy: 0.9601 - val_loss: 0.1561\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1138 - val_accuracy: 0.9522 - val_loss: 0.1898\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1134 - val_accuracy: 0.9630 - val_loss: 0.1626\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.1082 - val_accuracy: 0.9563 - val_loss: 0.1927\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.1081 - val_accuracy: 0.9590 - val_loss: 0.1821\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.3880 - val_accuracy: 0.9494 - val_loss: 0.1833\n",
            "Epoch 2/10\n",
            "\u001b[1m 908/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1694"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Get the best hyperparameters and the best model\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] # Get the top 1 best hyperparameters\n",
        "best_model = tuner.get_best_models(num_models=1)[0] # Get the top 1 best model\n",
        "\n",
        "print(f\"\\nBest hyperparameters found:\")\n",
        "print(f\"Number of units in first dense layer: {best_hps.get('units1')}\")\n",
        "print(f\"Number of units in second dense layer: {best_hps.get('units2')}\")\n",
        "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx4zarBE7NoW",
        "outputId": "ed8c0f13-4fce-4f2a-9e25-e675be432226"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best hyperparameters found:\n",
            "Number of units in first dense layer: 96\n",
            "Number of units in second dense layer: 48\n",
            "Learning rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Evaluate the best model on the test set\n",
        "print(\"\\nEvaluating the best model found by the tuner:\")\n",
        "loss, accuracy = best_model.evaluate(x_test, y_test_one_hot, verbose=0)\n",
        "\n",
        "print(f\"Test Loss of best model: {loss:.4f}\")\n",
        "print(f\"Test Accuracy of best model: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoRUZ2f_7jf2",
        "outputId": "839b6bff-2bca-470c-aefd-7a918ca7138b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating the best model found by the tuner:\n",
            "Test Loss of best model: 0.0881\n",
            "Test Accuracy of best model: 0.9786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Train the best model for more epochs on the full training data\n",
        "\n",
        "print(\"\\nTraining the best model for more epochs:\")\n",
        "history_best_model = best_model.fit(x_train, y_train_one_hot, epochs=50, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRgLskRw7jt_",
        "outputId": "d56c00b2-c5da-4926-c0e1-f8ac4bdd6c96"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the best model for more epochs:\n",
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0207 - val_accuracy: 0.9914 - val_loss: 0.0258\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0163 - val_accuracy: 0.9915 - val_loss: 0.0242\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0130 - val_accuracy: 0.9898 - val_loss: 0.0320\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0123 - val_accuracy: 0.9889 - val_loss: 0.0350\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0096 - val_accuracy: 0.9877 - val_loss: 0.0375\n",
            "Epoch 6/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0115 - val_accuracy: 0.9888 - val_loss: 0.0359\n",
            "Epoch 7/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9866 - val_loss: 0.0477\n",
            "Epoch 8/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.9843 - val_loss: 0.0583\n",
            "Epoch 9/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0092 - val_accuracy: 0.9863 - val_loss: 0.0516\n",
            "Epoch 10/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0119 - val_accuracy: 0.9887 - val_loss: 0.0496\n",
            "Epoch 11/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0108 - val_accuracy: 0.9841 - val_loss: 0.0697\n",
            "Epoch 12/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.9860 - val_loss: 0.0585\n",
            "Epoch 13/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0104 - val_accuracy: 0.9817 - val_loss: 0.0871\n",
            "Epoch 14/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0127 - val_accuracy: 0.9818 - val_loss: 0.0770\n",
            "Epoch 15/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0063 - val_accuracy: 0.9833 - val_loss: 0.0724\n",
            "Epoch 16/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0076 - val_accuracy: 0.9807 - val_loss: 0.0915\n",
            "Epoch 17/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 0.0093 - val_accuracy: 0.9852 - val_loss: 0.0734\n",
            "Epoch 18/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0101 - val_accuracy: 0.9838 - val_loss: 0.0808\n",
            "Epoch 19/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0084 - val_accuracy: 0.9846 - val_loss: 0.0821\n",
            "Epoch 20/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9813 - val_loss: 0.0953\n",
            "Epoch 21/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0089 - val_accuracy: 0.9844 - val_loss: 0.0817\n",
            "Epoch 22/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.9854 - val_loss: 0.0781\n",
            "Epoch 23/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9837 - val_loss: 0.0848\n",
            "Epoch 24/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0068 - val_accuracy: 0.9847 - val_loss: 0.0808\n",
            "Epoch 25/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9821 - val_loss: 0.1099\n",
            "Epoch 26/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0064 - val_accuracy: 0.9828 - val_loss: 0.1129\n",
            "Epoch 27/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9855 - val_loss: 0.0899\n",
            "Epoch 28/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9828 - val_loss: 0.1036\n",
            "Epoch 29/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9846 - val_loss: 0.0946\n",
            "Epoch 30/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 0.9853 - val_loss: 0.0973\n",
            "Epoch 31/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9833 - val_loss: 0.0976\n",
            "Epoch 32/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0066 - val_accuracy: 0.9808 - val_loss: 0.1334\n",
            "Epoch 33/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.9809 - val_loss: 0.1355\n",
            "Epoch 34/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0040 - val_accuracy: 0.9785 - val_loss: 0.1437\n",
            "Epoch 35/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.9830 - val_loss: 0.1154\n",
            "Epoch 36/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9769 - val_loss: 0.1735\n",
            "Epoch 37/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0132 - val_accuracy: 0.9820 - val_loss: 0.1250\n",
            "Epoch 38/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.9832 - val_loss: 0.1114\n",
            "Epoch 39/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9838 - val_loss: 0.1087\n",
            "Epoch 40/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9847 - val_loss: 0.1123\n",
            "Epoch 41/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0051 - val_accuracy: 0.9847 - val_loss: 0.1202\n",
            "Epoch 42/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9796 - val_loss: 0.1435\n",
            "Epoch 43/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0082 - val_accuracy: 0.9844 - val_loss: 0.1255\n",
            "Epoch 44/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9787 - val_loss: 0.1663\n",
            "Epoch 45/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.9810 - val_loss: 0.1656\n",
            "Epoch 46/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0092 - val_accuracy: 0.9799 - val_loss: 0.1688\n",
            "Epoch 47/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0074 - val_accuracy: 0.9834 - val_loss: 0.1388\n",
            "Epoch 48/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9822 - val_loss: 0.1325\n",
            "Epoch 49/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9812 - val_loss: 0.1463\n",
            "Epoch 50/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9799 - val_loss: 0.1673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Explanation of the Code:**\n",
        "\n",
        "1.  **Import KerasTuner:** We import the `keras_tuner` library as `kt`. You'll need to install it (`pip install keras-tuner`).\n",
        "2.  **`build_model(hp)` function:** This function is crucial for KerasTuner. It takes a `HyperParameters` object (`hp`) as input. Inside this function, you define your model architecture, and for the hyperparameters that want to tune, use methods provided by the `hp` object (e.g., `hp.Int()` for integer values within a range, `hp.Choice()` for selecting from a list of values).\n",
        "3.  **Instantiate a Tuner:** We create an instance of a tuner. `kt.RandomSearch` is a simple choice that randomly samples hyperparameter combinations. Other tuners like `kt.Hyperband` are also available and can be more efficient.\n",
        "    * `hypermodel=build_model`: We pass our model-building function.\n",
        "    * `objective='val_accuracy'`: We tell the tuner to maximize the validation accuracy.\n",
        "    * `max_trials`: The total number of different hyperparameter combinations to try.\n",
        "    * `executions_per_trial`: How many times to train a model with the same hyperparameter combination to account for variability.\n",
        "4.  **Run the Search:** The `tuner.search()` method starts the hyperparameter tuning process. It takes your training data and labels, the number of epochs to train each candidate model for, and validation data. KerasTuner will call your `build_model` function with different `hp` values, train the resulting models, and evaluate them on the validation data.\n",
        "5.  **Get Best Hyperparameters and Model:** After the search is complete, `tuner.get_best_hyperparameters()` and `tuner.get_best_models()` allow you to retrieve the best performing hyperparameter combination and the corresponding model.\n",
        "6.  **Evaluate Best Model:** You can then evaluate the best model on your test set to get an unbiased estimate of its performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "Dvtbh6M4vHKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2 # Import L2 for potential regularization tuning\n"
      ],
      "metadata": {
        "id": "17p40-fB-HnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that builds the model with more tunable hyperparameters\n",
        "def build_model_extended(hp):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28 * 28,)),\n",
        "    ])\n",
        "\n",
        "    # Tune the number of hidden layers\n",
        "    hp_num_layers = hp.Int('num_layers', min_value=1, max_value=3, step=1)\n",
        "\n",
        "    for i in range(hp_num_layers):\n",
        "        # Tune the number of neurons in each hidden layer\n",
        "        hp_units = hp.Int(f'units_{i}', min_value=32, max_value=128, step=32)\n",
        "        model.add(Dense(units=hp_units, activation='relu'))\n",
        "\n",
        "        # Optionally add dropout after each hidden layer\n",
        "        # Tune the dropout rate\n",
        "        if hp.Boolean(f'dropout_{i}'): # Decide whether to add dropout for this layer\n",
        "             hp_dropout_rate = hp.Float(f'dropout_rate_{i}', min_value=0.1, max_value=0.5, step=0.1)\n",
        "             model.add(Dropout(rate=hp_dropout_rate))\n",
        "\n",
        "        # Optional: Tune L2 kernel regularization for dense layers\n",
        "        # hp_l2 = hp.Float(f'l2_{i}', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "        # model.add(Dense(units=hp_units, activation='relu', kernel_regularizer=l2(hp_l2)))\n",
        "        # if hp.Boolean(f'dropout_{i}'):\n",
        "        #      hp_dropout_rate = hp.Float(f'dropout_rate_{i}', min_value=0.1, max_value=0.5, step=0.1)\n",
        "        #      model.add(Dropout(rate=hp_dropout_rate))\n",
        "\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Tune the optimizer\n",
        "    hp_optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop'])\n",
        "\n",
        "    # Tune the learning rate (can be made conditional on the optimizer if needed)\n",
        "    hp_learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "\n",
        "\n",
        "    if hp_optimizer == 'adam':\n",
        "        optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
        "    elif hp_optimizer == 'sgd':\n",
        "        optimizer = keras.optimizers.SGD(learning_rate=hp_learning_rate)\n",
        "    else: # rmsprop\n",
        "        optimizer = keras.optimizers.RMSprop(learning_rate=hp_learning_rate)\n",
        "\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "wDma2WIY9sw1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a Tuner (e.g., Hyperband for potentially better efficiency)\n",
        "# Hyperband is often more efficient than RandomSearch for larger search spaces.\n",
        "tuner_extended = kt.Hyperband(\n",
        "    hypermodel=build_model_extended, # The extended model-building function\n",
        "    objective='val_accuracy',       # The metric to optimize\n",
        "    max_epochs=10,                  # Maximum number of epochs to train a model\n",
        "    factor=3,                       # Factor by which to reduce the number of models and epochs\n",
        "    hyperband_iterations=2,         # Number of iterations of Hyperband\n",
        "    overwrite=True,                 # Overwrite previous results\n",
        "    directory='my_mnist_kt_extended_dir', # Directory to store results\n",
        "    project_name='mnist_hyperparameter_tuning_extended' # Project name\n",
        ")\n",
        "\n",
        "# Display the extended search space\n",
        "tuner_extended.search_space_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd4raRaD9vRt",
        "outputId": "f26cb02a-3b5d-4edc-f93b-9270c4233b83"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "dropout_0 (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "optimizer (Choice)\n",
            "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'rmsprop'], 'ordered': False}\n",
            "learning_rate (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the hyperparameter search\n",
        "print(\"\\nRunning extended hyperparameter search...\")\n",
        "tuner_extended.search(x_train, y_train_one_hot, epochs=50, validation_data=(x_test, y_test_one_hot))\n",
        "# Note: The 'epochs' here is the total epochs for the *entire* search process per trial,\n",
        "# not the max_epochs for a single model in Hyperband.\n",
        "\n",
        "# Get the best hyperparameters and the best model\n",
        "best_hps_extended = tuner_extended.get_best_hyperparameters(num_trials=1)[0]\n",
        "best_model_extended = tuner_extended.get_best_models(num_models=1)[0]\n",
        "\n",
        "print(f\"\\nBest hyperparameters found:\")\n",
        "print(f\"Number of hidden layers: {best_hps_extended.get('num_layers')}\")\n",
        "for i in range(best_hps_extended.get('num_layers')):\n",
        "    print(f\"Units in layer {i}: {best_hps_extended.get(f'units_{i}')}\")\n",
        "    if best_hps_extended.get(f'dropout_{i}'):\n",
        "         print(f\"Dropout rate after layer {i}: {best_hps_extended.get(f'dropout_rate_{i}')}\")\n",
        "\n",
        "print(f\"Optimizer: {best_hps_extended.get('optimizer')}\")\n",
        "print(f\"Learning rate: {best_hps_extended.get('learning_rate')}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaLeCdyJ9x9W",
        "outputId": "d3d00052-0fb9-414a-d2b8-a6d205d6eec9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 60 Complete [00h 01m 40s]\n",
            "val_accuracy: 0.9757999777793884\n",
            "\n",
            "Best val_accuracy So Far: 0.9807999730110168\n",
            "Total elapsed time: 00h 44m 03s\n",
            "\n",
            "Best hyperparameters found:\n",
            "Number of hidden layers: 3\n",
            "Units in layer 0: 128\n",
            "Dropout rate after layer 0: 0.1\n",
            "Units in layer 1: 96\n",
            "Units in layer 2: 32\n",
            "Optimizer: adam\n",
            "Learning rate: 0.0002677699795927549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the best model on the test set\n",
        "print(\"\\nEvaluating the best model found by the tuner:\")\n",
        "loss_extended, accuracy_extended = best_model_extended.evaluate(x_test, y_test_one_hot, verbose=0)\n",
        "\n",
        "print(f\"Test Loss of best model: {loss_extended:.4f}\")\n",
        "print(f\"Test Accuracy of best model: {accuracy_extended:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oKi4Ttm9yDW",
        "outputId": "b84cc926-de69-4270-bc72-5a895b0b5967"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating the best model found by the tuner:\n",
            "Test Loss of best model: 0.0652\n",
            "Test Accuracy of best model: 0.9808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model for more epochs\n",
        "print(\"\\nTraining the best model for more epochs:\")\n",
        "history_best_model_extended = best_model_extended.fit(x_train, y_train_one_hot, epochs=50, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oUbha1R9yGI",
        "outputId": "505fdfa5-a2ee-4a88-90f6-966dcb50e5a9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the best model for more epochs:\n",
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0343 - val_accuracy: 0.9929 - val_loss: 0.0228\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0278 - val_accuracy: 0.9908 - val_loss: 0.0270\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0267 - val_accuracy: 0.9907 - val_loss: 0.0284\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0246 - val_accuracy: 0.9898 - val_loss: 0.0295\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0233 - val_accuracy: 0.9869 - val_loss: 0.0380\n",
            "Epoch 6/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0208 - val_accuracy: 0.9879 - val_loss: 0.0362\n",
            "Epoch 7/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0189 - val_accuracy: 0.9882 - val_loss: 0.0378\n",
            "Epoch 8/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0192 - val_accuracy: 0.9885 - val_loss: 0.0360\n",
            "Epoch 9/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0181 - val_accuracy: 0.9877 - val_loss: 0.0377\n",
            "Epoch 10/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0149 - val_accuracy: 0.9862 - val_loss: 0.0471\n",
            "Epoch 11/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0150 - val_accuracy: 0.9870 - val_loss: 0.0446\n",
            "Epoch 12/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.9870 - val_loss: 0.0445\n",
            "Epoch 13/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0126 - val_accuracy: 0.9845 - val_loss: 0.0508\n",
            "Epoch 14/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0134 - val_accuracy: 0.9866 - val_loss: 0.0502\n",
            "Epoch 15/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0122 - val_accuracy: 0.9879 - val_loss: 0.0508\n",
            "Epoch 16/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0133 - val_accuracy: 0.9864 - val_loss: 0.0477\n",
            "Epoch 17/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0109 - val_accuracy: 0.9863 - val_loss: 0.0493\n",
            "Epoch 18/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.9855 - val_loss: 0.0524\n",
            "Epoch 19/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0083 - val_accuracy: 0.9845 - val_loss: 0.0659\n",
            "Epoch 20/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0102 - val_accuracy: 0.9831 - val_loss: 0.0639\n",
            "Epoch 21/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0097 - val_accuracy: 0.9848 - val_loss: 0.0596\n",
            "Epoch 22/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0101 - val_accuracy: 0.9861 - val_loss: 0.0550\n",
            "Epoch 23/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.9865 - val_loss: 0.0562\n",
            "Epoch 24/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9856 - val_loss: 0.0587\n",
            "Epoch 25/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0094 - val_accuracy: 0.9855 - val_loss: 0.0638\n",
            "Epoch 26/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0077 - val_accuracy: 0.9858 - val_loss: 0.0572\n",
            "Epoch 27/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9851 - val_loss: 0.0614\n",
            "Epoch 28/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0084 - val_accuracy: 0.9851 - val_loss: 0.0626\n",
            "Epoch 29/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9837 - val_loss: 0.0682\n",
            "Epoch 30/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0086 - val_accuracy: 0.9849 - val_loss: 0.0637\n",
            "Epoch 31/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9852 - val_loss: 0.0667\n",
            "Epoch 32/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 0.9846 - val_loss: 0.0700\n",
            "Epoch 33/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.9849 - val_loss: 0.0712\n",
            "Epoch 34/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0076 - val_accuracy: 0.9843 - val_loss: 0.0748\n",
            "Epoch 35/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.9837 - val_loss: 0.0743\n",
            "Epoch 36/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.9833 - val_loss: 0.0791\n",
            "Epoch 37/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9822 - val_loss: 0.0821\n",
            "Epoch 38/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9851 - val_loss: 0.0766\n",
            "Epoch 39/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9843 - val_loss: 0.0742\n",
            "Epoch 40/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0070 - val_accuracy: 0.9845 - val_loss: 0.0723\n",
            "Epoch 41/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.9842 - val_loss: 0.0770\n",
            "Epoch 42/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0062 - val_accuracy: 0.9846 - val_loss: 0.0787\n",
            "Epoch 43/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0080 - val_accuracy: 0.9831 - val_loss: 0.0853\n",
            "Epoch 44/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9841 - val_loss: 0.0777\n",
            "Epoch 45/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9835 - val_loss: 0.0825\n",
            "Epoch 46/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9827 - val_loss: 0.0867\n",
            "Epoch 47/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0052 - val_accuracy: 0.9842 - val_loss: 0.0778\n",
            "Epoch 48/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9837 - val_loss: 0.0858\n",
            "Epoch 49/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9845 - val_loss: 0.0815\n",
            "Epoch 50/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9839 - val_loss: 0.0775\n"
          ]
        }
      ]
    }
  ]
}